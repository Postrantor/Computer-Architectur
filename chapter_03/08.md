## Exploiting ILP Using Dynamic Scheduling, Multiple Issue, and Speculation

So far we have seen how the individual mechanisms of dynamic scheduling, multiple issue, and speculation work. In this section, we put all three together, which yields a microarchitecture quite similar to those in modern microprocessors. For simplicity we consider only an issue rate of two instructions per clock, but the concepts are no different from modern processors that issue three or more instructions per clock.

> 到目前为止，我们已经看到了动态调度，多重问题和投机工作的单个机制。在本节中，我们将所有三个都放在一起，这与现代微处理器中的微观结构非常相似。为简单起见，我们仅考虑每个时钟两个指令的发行率，但是这些概念与每个时钟发出三个或更多说明的现代处理器没有什么不同。

Let’s assume we want to extend Tomasulo’s algorithm to support multipleissue superscalar pipeline with separate integer, load/store, and floating-point units (both FP multiply and FP add), each of which can initiate an operation on every clock. We do not want to issue instructions to the reservation stations out of order because this could lead to a violation of the program semantics. To gain the full advantage of dynamic scheduling, we will allow the pipeline to issue any combination of two instructions in a clock, using the scheduling hardware to actually assign operations to the integer and floating-point unit. Because the interaction of the integer and floating-point instructions is crucial, we also extend Tomasulo’s scheme to deal with both the integer and floating-point functional units and registers, as well as incorporating speculative execution. As [Figure 3.21](#_bookmark123) shows, the basic organization is similar to that of a processor with speculation with one issue per clock, except that the issue and completion logic must be enhanced to allow multiple instructions to be processed per clock.

> 假设我们要扩展 tomasulo 的算法，以支持具有单独的整数，负载/存储和浮点单元(FP Multiply 和 FP 添加)的多 issusue Superscalar 管道，每个单元都可以在每个时钟上启动操作。我们不想向预订站发布指示，因为这可能导致违反程序语义。为了获得动态调度的全部优势，我们将允许管道在时钟中发出两个指令的任何组合，并使用调度硬件实际将操作分配给整数和浮点单元。由于整数和浮点指令的相互作用至关重要，因此我们还扩展了 Tomasulo 的方案，以处理整数和浮点功能单元和寄存器，并合并投机执行。如[图 3.21](#_bookmark123) 所示，基本组织类似于每个时钟的投机的处理器，除了必须增强问题和完成逻辑以允许每个时钟处理多个指令。

Issuing multiple instructions per clock in a dynamically scheduled processor (with or without speculation) is very complex for the simple reason that the multiple instructions may depend on one another. Because of this, the tables must be updated for the instructions in parallel; otherwise, the tables will be incorrect or the dependence may be lost.

> 在动态计划的处理器(有或没有推测)中，每个时钟发出多个指令非常复杂，其简单原因是多个指令可能相互取决于彼此。因此，必须并行更新表格；否则，表将不正确或依赖性可能会丢失。

Two different approaches have been used to issue multiple instructions per clock in a dynamically scheduled processor, and both rely on the observation that the key is assigning a reservation station and updating the pipeline control tables. One approach is to run this step in half a clock cycle so that two instructions can be processed in one clock cycle; this approach cannot be easily extended to handle four instructions per clock, unfortunately.

> 已经使用两种不同的方法在动态计划的处理器中每个时钟发出多个指令，并且都依赖于钥匙分配预订站并更新管道控制表的观察结果。一种方法是将此步骤运行半个时钟周期，以便可以在一个时钟周期中处理两个指令。不幸的是，这种方法不能轻易扩展到每个时钟处理四个说明。

![](../media/image206.png)

Figure 3.21 The basic organization of a multiple issue processor with speculation. In this case, the organization could allow a FP multiply, FP add, integer, and load/store to all issues simultaneously (assuming one issue per clock per functional unit). Note that several datapaths must be widened to support multiple issues: the CDB, the operand buses, and, critically, the instruction issue logic, which is not shown in this figure. The last is a difficult problem, as we discuss in the text.

> 图 3.21 具有投机性的多重问题处理器的基本组织。在这种情况下，组织可以同时允许 FP 乘以乘以乘以乘以添加，整数和加载/存储到所有问题(假设每个函数单位每个时钟都有一个问题)。请注意，必须扩大几个数据检查以支持多个问题：CDB，操作数总线以及批判性的指令问题逻辑，该逻辑未显示在此图中。正如我们在文本中讨论的那样，最后一个是一个困难的问题。

A second alternative is to build the logic necessary to handle two or more instructions at once, including any possible dependences between the instructions. Modern superscalar processors that issue four or more instructions per clock may include both approaches: They both pipeline and widen the issue logic. A key observation is that we cannot simply pipeline away the problem. By making instruction issues take multiple clocks because new instructions are issuing every clock cycle, we must be able to assign the reservation station and to update the pipeline tables so that a dependent instruction issuing on the next clock can use the updated information.

> 第二种选择是建立一次处理两个或多个指令所需的逻辑，包括指令之间的任何可能依赖。每个时钟发出四个或更多说明的现代超量表处理器可能包括两种方法：它们既可以管道和扩大问题逻辑。一个关键的观察是，我们不能简单地管开问题。通过使指令问题进行多个时钟，因为新说明正在发出每个时钟周期，我们必须能够分配预订站并更新管道表，以便在下一个时钟上发出的依赖指令可以使用更新的信息。

This issue step is one of the most fundamental bottlenecks in dynamically scheduled superscalars. To illustrate the complexity of this process, [Figure 3.22](#_bookmark124) shows the issue logic for one case: issuing a load followed by a dependent FP operation. The logic is based on that in [Figure 3.18](#_bookmark118) on page 197, but represents only one case. In a modern superscalar, every possible combination of dependent instructions that is allowed to issue in the same clock cycle must be considered. Because the number of possibilities climbs as the square of the number of instructions that can be issued in a clock, the issue step is a likely bottleneck for attempts to go beyond four instructions per clock.

> 这个问题步骤是动态计划超级量表中最基本的瓶颈之一。为了说明此过程的复杂性，[图 3.22](#_bookmark124) 显示了一个情况的问题逻辑：发出负载，然后是依赖的 FP 操作。该逻辑基于第 197 页的[图 3.18](#_bookmark118) 中的逻辑，但仅代表一种情况。在现代超级标准中，必须考虑在同一时钟周期中允许发出的依赖指令的每种可能组合。由于可能性的数量是可以在时钟中发出的指令数量的平方，因此问题步骤可能是尝试超出每个时钟四个说明的瓶颈。

We can generalize the detail of [Figure 3.22](#_bookmark124) to describe the basic strategy for updating the issue logic and the reservation tables in a dynamically scheduled superscalar with up to _n_ issues per clock as follows:

> 我们可以概括[图 3.22](#_bookmark124) 的详细信息，以描述在动态计划的 superscalar 中更新问题逻辑和预订表的基本策略，每个时钟最多 *n* 问题如下：

1. Assign a reservation station and a reorder buffer for _every_ instruction that _might_ be issued in the next issue bundle. This assignment can be done before the instruction types are known simply by preallocating the reorder buffer entries sequentially to the instructions in the packet using _n_ available reorder buffer entries and by ensuring that enough reservation stations are available to issue the whole bundle, independent of what it contains. By limiting the number of instructions of a given class (say, one FP, one integer, one load, one store), the necessary reservation stations can be preallocated. Should sufficient reservation stations not be available (such as when the next few instructions in the program are all of one instruction type), the bundle is broken, and only a subset of the instructions, in the original program order, is issued. The remainder of the instructions in the bundle can be placed in the next bundle for potential issue.

> 1. 为 *every* 指令分配一个预订站和重新订购缓冲区，即在下一期捆绑包中发出* -Might*。可以在使用 *n* 可用的重新订购缓冲区条目中顺序将重新订购缓冲区条目预先依次到数据包中的指令，并确保可以确保有足够的预订站来发布整个捆绑包，与它独立于该内容，请与该指令中的指示进行顺序依次，与该指令中的指示进行顺序依次，与该指令中的指示序列，可以完成此任务。包含。通过限制给定类的指令数量(例如，一个 FP，一个整数，一个负载，一个存储)，可以将必要的预订站进行预订。如果没有足够的预订站(例如，程序中的下几个说明都是一个指令类型)，则捆绑包被打破，并且只发出了原始程序顺序中的指令子集。捆绑包中的其余说明可以放在下一个捆绑包中，以解决潜在问题。

2. Analyze all the dependences among the instructions in the issue bundle.

> 2. 分析问题捆绑包中指令之间的所有依赖。

3. If an instruction in the bundle depends on an earlier instruction in the bundle, use the assigned reorder buffer number to update the reservation table for the dependent instruction. Otherwise, use the existing reservation table and reorder buffer information to update the reservation table entries for the issuing instruction.

> 3. 如果捆绑包中的指令取决于捆绑包中的较早指令，请使用分配的重新排序缓冲区编号来更新依赖指令的预订表。否则，请使用现有的预订表和重新排序缓冲区信息来更新发布指令的预订表条目。

Of course, what makes the preceding very complicated is that it is all done in parallel in a single clock cycle!

> 当然，使前面非常复杂的是，它在单个时钟周期中并行完成！

At the back-end of the pipeline, we must be able to complete and commit multiple instructions per clock. These steps are somewhat easier than the issue problems because multiple instructions that can actually commit in the same clock cycle must have already dealt with and resolved any dependences. As we will see, designers have figured out how to handle this complexity: The Intel i7, which we examine in [Section 3.12](#putting-it-all-together-the-intel-core-i7-6700-and-arm-cortex-a53), uses essentially the scheme we have described for speculative multiple issue, including a large number of reservation stations, a reorder buffer, and a load and store buffer that is also used to handle nonblocking cache misses.

> 在管道的后端，我们必须能够每个时钟完成并提交多个说明。这些步骤比问题问题要容易得多，因为在同一时钟周期中实际上可以提交的多个指令必须已经处理并解决了任何依赖。正如我们将看到的那样，设计师已经弄清楚了如何处理这种复杂性：我们在[3.12](＃putting-it-it-all-the-the-the-the-Intel-the-Intel-core-i7-6700 and-arm and-arm)中进行了研究。-cortex-a53)，本质上使用了我们为投机性多重问题所描述的方案，包括大量预订站，重新排序缓冲区以及负载和存储缓冲区，该缓冲区也用于处理非封锁缓存失误。

From a performance viewpoint, we can show how the concepts fit together with an example.

> 从性能的角度来看，我们可以展示概念如何与示例结合在一起。

Updating the reservation tables for the load instruction, which has a single source operand. Because this is the first instruction in this issue bundle, it looks no different than what would normally happen for a load.

> 更新具有单个源操作数的负载指令的预订表。因为这是本期捆绑包中的第一个指令，所以它看起来与负载通常发生的情况没有什么不同。

operand of the FP operation is from the load, this step simply updates the reservation station to point to the load. Notice that the dependence must be analyzed on the fly and the ROB entries must be allocated during this issue step so that the reservation tables can be correctly updated.

> FP 操作的操作数来自负载，此步骤简单地更新预订站以指向负载。请注意，必须在此问题步骤中触发依赖性，并且必须分配 ROB 条目，以便可以正确更新预订表。

Because we assumed that the second operand of the FP instruction was from a prior issue bundle, this step looks like it would in the single-issue case. Of course, if this instruction were dependent on something in the same issue bundle, the tables would need to be updated using the assigned reservation buffer.

> 因为我们假设 FP 指令的第二操作数是从前一个问题捆绑包中的，所以此步骤看起来像是在单发案例中。当然，如果此指令取决于同一问题捆绑中的某些内容，则需要使用分配的预订缓冲区来更新表。

This section simply updates the tables for the FP operation and is independent of the load. Of course, if further instructions in this issue bundle depended on the FP operation (as could happen with a four-issue superscalar), the updates to the reservation tables for those instructions would be effected by this instruction.

> 本节只需更新 FP 操作的表，就独立于负载。当然，如果本期捆绑包的进一步说明取决于 FP 操作(四级超量表可能发生)，则该说明将对这些说明进行预订表的更新。

Figure 3.22 The issue steps for a pair of dependent instructions (called 1 and 2), where instruction 1 is FP load and instruction 2 is an FP operation whose first operand is the result of the load instruction; x1 and x2 are the assigned reservation stations for the instructions; and b1 and b2 are the assigned reorder buffer entries. For the issuing instructions, rd1 and rd2 are the destinations; rs1, rs2, and rt2 are the sources (the load has only one source); x1 and x2 are the reservation stations allocated; and b1 and b2 are the assigned ROB entries. RS is the reservation station data structure. RegisterStat is the register data structure, Regs represents the actual registers, and ROB is the reorder buffer data structure. Notice that we need to have assigned reorder buffer entries for this logic to operate properly, and recall that all these updates happen in a single clock cycle in parallel, not sequentially.

> 图 3.22 一对依赖指令(称为 1 和 2)的问题步骤，其中指令 1 是 FP 负载，指令 2 是 FP 操作，其第一操作是负载指令的结果；X1 和 X2 是指令的指定预订站；和 B1 和 B2 是分配的重新排序缓冲区条目。对于发行说明，RD1 和 RD2 是目的地；RS1，RS2 和 RT2 是来源(负载只有一个源)；X1 和 X2 是分配的预订站；B1 和 B2 是指定的 Rob 条目。RS 是预订站数据结构。RegisterStat 是寄存器数据结构，REGS 代表实际寄存器，ROB 是重新排序缓冲区数据结构。请注意，我们需要为此逻辑分配重新排序的缓冲区条目以正确操作，并回想起所有这些更新都在单个时钟周期中并行而不是顺序地发生。

Example Consider the execution of the following loop, which increments each element of an integer array, on a two-issue processor, once without speculation and once with speculation:

> 示例考虑执行以下循环，该循环会在两条评估处理器上递增整数数组的每个元素，一次无需推测，并且一次猜测：

Assume that there are separate integer functional units for effective address calculation, for ALU operations, and for branch condition evaluation. Create a table for the first three iterations of this loop for both processors. Assume that up to two instructions of any type can commit per clock.

> 假设有单独的整数功能单元用于有效地址计算，用于 ALU 操作以及分支条件评估。为两个处理器的前三个迭代创建一个表。假设最多两个类型的指令每个时钟都可以提交。

_Answer_ [Figures 3.23](#_bookmark125) and [3.24](#_bookmark126) show the performance for a two-issue, dynamically scheduled processor, without and with speculation. In this case, where a branch

> _answer_ [图 3.23](#_bookmark125) 和 [3.24](#_bookmark126) 在没有猜测的情况下显示了两个问题，动态安排的处理器的性能。在这种情况下，分支机构

Figure 3.23 The time of issue, execution, and writing result for a dual-issue version of our pipeline _without_ speculation. Note that the ld following the bne cannot start execution earlier because it must wait until the branch outcome is determined. This type of program, with data-dependent branches that cannot be resolved earlier, shows the strength of speculation. Separate functional units for address calculation, ALU operations, and branch-condition evaluation allow multiple instructions to execute in the same cycle. [Figure 3.24](#_bookmark126) shows this example with speculation.

> 图 3.23 我们的管道的双发版本 *WITHOUT* 投机的问题，执行和写作结果的时间。请注意，BNE 之后的 LD 无法更早开始执行，因为它必须等到确定分支结果。这种类型的程序，与数据相关的分支无法较早解决，显示了投机的强度。单独的功能单元用于地址计算，ALU 操作和分支条件评估允许在同一周期中执行多个指令。[图 3.24](#_bookmark126) 用投机显示了此示例。

Figure 3.24 The time of issue, execution, and writing result for a dual-issue version of our pipeline _with_ speculation. Note that the ld following the bne can start execution early because it is speculative.

> 图 3.24 我们的管道的双发版本 *WITH* 猜测的发行时间，执行和写作结果。请注意，BNE 之后的 LD 可以提早开始执行，因为它具有投机性。

can be a critical performance limiter, speculation helps significantly. The third branch in the speculative processor executes in clock cycle 13, whereas it executes in clock cycle 19 on the nonspeculative pipeline. Because the completion rate on the nonspeculative pipeline is falling behind the issue rate rapidly, the nonspeculative pipeline will stall when a few more iterations are issued. The performance of the nonspeculative processor could be improved by allowing load instructions to complete effective address calculation before a branch is decided, but unless speculative memory accesses are allowed, this improvement will gain only 1 clock per iteration.

> 可能是一个关键的绩效限制者，投机有很大帮助。投机处理器中的第三个分支在时钟周期 13 中执行，而它在非负责管道上的时钟周期 19 中执行。由于非负责管道的完成率正在迅速落后于发行率，因此当发出几次迭代时，非负责管道将停滞不前。可以通过允许加载指令在确定分支机构之前完成有效的地址计算来提高非负责处理器的性能，但是除非允许投机性内存访问权限，否则此改进将仅获得 1 个时钟。

This example clearly shows how speculation can be advantageous when there are data-dependent branches, which otherwise would limit performance. This advantage depends, however, on accurate branch prediction. Incorrect speculation does not improve performance; in fact, it typically harms performance and, as we shall see, dramatically lowers energy efficiency.

> 该示例清楚地显示了当存在数据依赖于数据的分支时，投机如何有利，否则会限制性能。但是，此优势取决于准确的分支预测。不正确的投机不会改善绩效；实际上，它通常会损害性能，并且正如我们将看到的那样，大大降低了能源效率。
