> [!note]
> 现在做的实时性的研究，是在操作系统层面的，即使是 linux kernel 也一样，是一个较为宏观的层面
> 在 CPU 内部有自己的一套 pipeline 逻辑，通过上次技术分享，可以观察到，这两位对着一块也是不熟悉的
> 看过这些文章之后，考虑了解 CPU 内部缓存，pipeline ，分支预测等这些机制的调用，应该对系统的实时调度有很大的借鉴意义

## How Is Pipelining Implemented?

Before we proceed to basic pipelining, we need to review a simple implementation of an unpipelined version of RISC V.

> 在进行基本管道上之前，我们需要回顾 RISC V 版本的简单实现。

### A Simple Implementation of RISC V

In this section we follow the style of [Section C.1](#introduction-8), showing first a simple unpipe- lined implementation and then the pipelined implementation. This time, however, our example is specific to the RISC V architecture.

> 在本节中，我们遵循 [C.1](%EF%BC%83resopity-8) 的样式，首先显示一个简单的拆开实现，然后显示管道实现。但是，这次我们的示例特定于 RISC V 架构。

In this subsection, we focus on a pipeline for an integer subset of RISC V that con- sists of load-store word, branch equal, and integer ALU operations. Later in this appendix we will incorporate the basic floating-point operations. Although we discuss only a subset of RISC V, the basic principles can be extended to handle all the instruc- tions; for example, adding store involves some additional computing of the immediate field. We initially used a less aggressive implementation of a branch instruction. We show how to implement the more aggressive version at the end of this section.

> 在本小节中，我们专注于 RISC V 整数子集的管道，该管道由负载商店，分支相等和整数 Alu 操作组成。在本附录的后面，我们将合并基本的浮点操作。尽管我们仅讨论 RISC V 的一部分，但可以扩展基本原则以处理所有指导。例如，添加存储涉及对直接字段的一些其他计算。我们最初使用分支指令的不太积极的实现。我们展示了如何在本节末尾实现更具侵略性的版本。

Every RISC V instruction can be implemented in, at most, 5 clock cycles. The 5 clock cycles are as follows:

> 每个 RISC V 指令最多都可以在 5 个时钟周期中实现。5 个时钟周期如下：

_Operation_—Send out the PC and fetch the instruction from memory into the instruction register (IR); increment the PC by 4 to address the next sequential instruction. The IR is used to hold the instruction that will be needed on subsequent clock cycles; likewise, the register NPC is used to hold the next sequential PC.

> _operation _-列出 PC 并从内存中获取指令到指令寄存器(IR)；将 PC 递增 4，以解决下一个顺序指令。IR 用于保留随后的时钟周期所需的指令；同样，寄存器 NPC 用于保存下一个顺序 PC。

_Operation_—Decode the instruction and access the register file to read the reg- isters (rs1 and rs2 are the register specifiers). The outputs of the general-purpose registers are read into two temporary registers (A and B) for use in later clock cycles. The lower 16 bits of the IR are also sign extended and stored into the temporary register Imm, for use in the next cycle.

> _operation _-对指令进行删除并访问寄存器文件以读取 registers(RS1 和 RS2 是寄存器指定器)。通用寄存器的输出被读取为两个临时寄存器(A 和 B)，以用于以后的时钟周期。IR 的下部 16 位也被扩展并存储到临时寄存器 INM 中，以在下一个周期中使用。

Decoding is done in parallel with reading registers, which is possible because these fields are at a fixed location in the RISC V instruction format. Because the immediate portion of a load and an ALU immediate is located in an identical place in every RISC V instruction, the sign-extended immediate is also calculated during this cycle in case it is needed in the next cycle. For stores, a separate sign-extension is needed, because the immediate field is split in two pieces.

> 解码与阅读寄存器并行进行，这是可能的，因为这些字段在 RISC V 指令格式的固定位置。由于负载的直接部分和 ALU 即时位于每个 RISC V 指令中的相同位置，因此在此周期中还计算了签名伸展的即时，以防下一个周期需要。对于商店，需要单独的签名扩展，因为直接字段分为两部分。

_Operation_—The ALU adds the NPC to the sign-extended immediate value in Imm, which is shifted left by 2 bits to create a word offset, to compute the address of the branch target. Register A, which has been read in the prior cycle, is checked to determine whether the branch is taken, by comparison with Reg- ister B, because we consider only branch equal.

> _operation_ - ALU 将 NPC 添加到 IMM 中的签名伸展的即时值，该值左移 2 位以创建一个单词偏移，以计算分支目标的地址。通过与 Reg-Ister B 进行比较，检查了在先前周期中已读取的寄存器 A，以确定是否采取分支，因为我们仅考虑分支相等。

The load-store architecture of RISC V means that effective address and execution cycles can be combined into a single clock cycle, because no instruc- tion needs to simultaneously calculate a data address, calculate an instruction target address, and perform an operation on the data. The other integer instruc- tions not included herein are jumps of various forms, which are similar to branches.

> RISC V 的负载商店体系结构意味着可以将有效的地址和执行周期组合到单个时钟周期中，因为无需同时计算数据地址，计算指令目标地址并对数据执行操作。本文不包括的其他整数指标是各种形式的跳跃，类似于分支。

_Operation_—Access memory if needed. If the instruction is a load, data return from memory and are placed in the LMD (load memory data) register; if it is a store, then the data from the B register are written into memory. In either case, the address used is the one computed during the prior cycle and stored in the register ALUOutput.

> _operation_ - 如果需要，请记忆。如果指令是负载，则数据从内存返回并放置在 LMD(负载存储器数据)寄存器中；如果是商店，则将 B 寄存器的数据写入内存中。无论哪种情况，使用的地址都是在先前周期中计算出的地址，并存储在寄存器 aluoutput 中。

_Operation_—Write the result into the register file, whether it comes from the memory system (which is in LMD) or from the ALU (which is in ALUOutput) with rd designating the register.

> _operation_-将结果写入寄存器文件中，无论是来自内存系统(在 LMD 中)还是来自 rd 指定寄存器的 ALU(在 AluOutput 中)。

[Figure C.18](#_bookmark503) shows how an instruction flows through the data path. At the end of each clock cycle, every value computed during that clock cycle and required on a later clock cycle (whether for this instruction or the next) is written into a storage device, which may be memory, a general-purpose register, the PC, or a temporary register (i.e., LMD, Imm, A, B, IR, NPC, ALUOutput, or Cond). The temporary registers hold values between clock cycles for one instruction, while the other stor- age elements are visible parts of the state and hold values between successive instructions.

> [图 C.18](#_bookmark503) 显示了指令如何流过数据路径。在每个时钟周期结束时，在该时钟周期中计算出的每个值，并在以后的时钟周期中(无论是本指令还是下一个)都写入存储设备，这可能是内存，通用寄存器，PC 或临时寄存器(即 LMD，IMM，A，B，IR，NPC，AluOutput 或 Cond)。临时寄存器在一个指令之间保持时钟周期之间的值，而另一个存储元素是状态的可见部分，并在连续指令之间保持值。

Although all processors today are pipelined, this multicycle implementation is a reasonable approximation of how most processors would have been implemented in earlier times. A simple finite-state machine could be used to implement the control following the five-cycle structure shown herein. For a much more complex proces- sor, microcode control could be used. In either event, an instruction sequence like the one described in this section would determine the structure of the control.

> 尽管今天的所有处理器都是管道的，但这种多环形实现是对大多数处理器在早期的实施方式的合理近似。一个简单的有限状态机可以用于在本文显示的五周期结构之后实现控件。对于更复杂的过程，可以使用微码控制。在这两种情况下，本节中描述的指令序列都将确定控件的结构。

There are some hardware redundancies that could be eliminated in this multi- cycle implementation. For example, there are two ALUs: one to increment the PC and one used for effective address and ALU computation. Because they are not needed on the same clock cycle, we could merge them by adding additional mul- tiplexers and sharing the same ALU. Likewise, instructions and data could be stored in the same memory, because the data and instruction accesses happen on different clock cycles.

> 在此多周期实现中，可以消除一些硬件冗余。例如，有两个 Alus：一个用于递增 PC，一个用于有效地址和 ALU 计算。因为在同一时钟周期中不需要它们，所以我们可以通过添加其他 mul-tiplexers 并共享同一 ALU 来合并它们。同样，指令和数据可以存储在相同的内存中，因为数据和指令访问发生在不同的时钟周期上。

Rather than optimize this simple implementation, we will leave the design as it is in [Figure C.18](#_bookmark503), because this provides us with a better base for the pipelined implementation.

> 我们将不像[图 C.18](#_bookmark503) 那样保留设计的简单实现，而是将设计留下，因为这为我们提供了更好的管道实现基础。

![](../media/image575.png)

Figure C.18 The implementation of the RISC V data path allows every instruction to be executed in 4 or 5 clock cycles. Although the PC is shown in the portion of the data path that is used in instruction fetch and the registers are shown in the portion of the data path that is used in instruction decode/register fetch, both of these functional units are read as well as written by an instruction. Although we show these functional units in the cycle corresponding to where they are read, the PC is written during the memory access clock cycle and the registers are written during the write-back clock cycle. In both cases, the writes in later pipe stages are indicated by the multiplexer output (in mem- ory access or write-back), which carries a value back to the PC or registers. These backward-flowing signals introduce much of the complexity of pipelining, because they indicate the possibility of hazards.

> 图 C.18 RISC V 数据路径的实现允许在 4 或 5 个时钟周期中执行所有指令。尽管 PC 显示在指令获取中使用的数据路径的一部分中，并且寄存器显示在指令解码/寄存器中使用的数据路径的部分中由指令写。尽管我们在周期中显示了与它们所读取的位置相对应的这些功能单元，但 PC 是在内存访问时钟周期中编写的，并且寄存器是在写入后的时钟周期中编写的。在这两种情况下，以后的管道阶段的写作都由多路复用器输出(Mem-Ory 访问或写入)表示，该输出将值带回 PC 或寄存器。这些向后流动的信号引入了管道上的许多复杂性，因为它们表明了危险的可能性。

### A Basic Pipeline for RISC V

As before, we can pipeline the data path of [Figure C.18](#_bookmark503) with almost no changes by starting a new instruction on each clock cycle. Because every pipe stage is active on every clock cycle, all operations in a pipe stage must complete in 1 clock cycle and any combination of operations must be able to occur at once. Furthermore, pipelining the data path requires that values passed from one pipe stage to the next must be placed in registers. [Figure C.19](#_bookmark504) shows the RISC V pipeline with the appro- priate registers, called _pipeline registers_ or _pipeline latches_, between each pipeline stage. The registers are labeled with the names of the stages they connect.

> 和以前一样，我们可以将[图 C.18](#_bookmark503) 的数据路径输送，几乎没有通过在每个时钟周期开始新的指令来更改。由于每个管道阶段在每个时钟周期中都处于活动状态，因此管道阶段中的所有操作都必须在 1 时钟周期中完成，并且任何操作的组合都必须能够立即发生。此外，管道数据路径要求从一个管道阶段传递到下一个的值必须放在寄存器中。[图 C.19](#_bookmark504) 在每个管道阶段之间显示了带有适当寄存器的 RISC V 管道，称为 *PIPELINE 寄存器*或 *pipeline latches*。寄存器标记为它们连接的阶段的名称。

Figure C.19 The data path is pipelined by adding a set of registers, one between each pair of pipe stages. The registers serve to convey values and control information from one stage to the next. We can also think of the PC as a pipeline register, which sits before the IF stage of the pipeline, leading to one pipeline register for each pipe stage. Recall that the PC is an edge-triggered register written at the end of the clock cycle; hence, there is no race condition in writing the PC. The selection multiplexer for the PC has been moved so that the PC is written in exactly one stage (IF). If we didn’t move it, there would be a conflict when a branch occurred, because two instructions would try to write different values into the PC. Most of the data paths flow from left to right, which is from earlier in time to later. The paths flowing from right to left (which carry the register write-back information and PC information on a branch) introduce complications into our pipeline.

> 图 C.19 数据路径是通过添加一组寄存器来管道的，每对管道阶段之间一组。寄存器用于传达价值和控制信息从一个阶段到另一个阶段。我们还可以将 PC 视为管道寄存器，该管道寄存器位于管道的 IF 阶段之前，导致每个管道阶段的一个管道寄存器。回想一下，PC 是在时钟周期结束时编写的边缘触发寄存器；因此，编写 PC 没有种族条件。PC 的选择多路复用器已移动，以便 PC 精确地写入一个阶段(如果)。如果我们不移动它，则在分支机构发生时会发生冲突，因为两个说明将尝试将不同的值写入 PC。大多数数据路径从左到右流动，这是从早期到更晚的。从右到左流的路径(带有寄存器写入信息和分支上的 PC 信息)将并发症引入我们的管道中。

[Figure C.19](#_bookmark504) is drawn so that connections through the pipeline registers from one stage to another are clear.

> [图 C.19](#_bookmark504) 被绘制，以便从一个阶段到另一个阶段通过管道寄存器进行连接。

All of the registers needed to hold values temporarily between clock cycles within one instruction are subsumed into these pipeline registers. The fields of the instruction register (IR), which is part of the IF/ID register, are labeled when they are used to supply register names. The pipeline registers carry both data and control from one pipeline stage to the next. Any value needed on a later pipeline stage must be placed in such a register and copied from one pipeline register to the next, until it is no longer needed. If we tried to just use the temporary registers we had in our earlier unpipelined data path, values could be overwritten before all uses were completed. For example, the field of a register operand used for a write on a load or ALU operation is supplied from the MEM/WB pipeline register rather than from the IF/ID register. This is because we want a load or ALU operation to write the register designated by that operation, not the register field of the

> 将一个指令中时钟周期之间暂时保持值的所有寄存器都包含在这些管道寄存器中。指令寄存器(IR)的字段是 IF/ID 寄存器的一部分，当它们用于提供寄存器名称时被标记。管道寄存器携带数据和控制，从一个管道阶段到下一个管道阶段。以后的管道阶段所需的任何值都必须放在这样的寄存器中，并从一个管道寄存器复制到下一个管道寄存器，直到不再需要它为止。如果我们试图仅使用较早的不符合数据路径中的临时寄存器，则可以在完成所有用途之前被覆盖值。例如，用于在负载或 ALU 操作上写入的寄存器操作数字段是从 MEM/WB 管道寄存器提供的，而不是从 IF/ID 寄存器中提供的。这是因为我们希望负载或 ALU 操作写下该操作指定的寄存器，而不是该操作的寄存器字段

instruction currently transitioning from IF to ID! This destination register field is simply copied from one pipeline register to the next, until it is needed during the WB stage.

> 当前指令从 IF 过渡到 ID！仅将此目的地寄存器字段从一个管道寄存器复制到下一个管道寄存器，直到在 WB 阶段需要它为止。

Any instruction is active in exactly one stage of the pipeline at a time; therefore, any actions taken on behalf of an instruction occur between a pair of pipeline reg- isters. Thus, we can also look at the activities of the pipeline by examining what has to happen on any pipeline stage depending on the instruction type. [Figure C.20](#_bookmark505) shows this view. Fields of the pipeline registers are named so as to show the flow of data from one stage to the next. Notice that the actions in the first two stages are independent of the current instruction type; they must be independent because the instruction is not decoded until the end of the ID stage. The IF activity depends on whether the instruction in EX/MEM is a taken branch. If so, then the branch-target address of the branch instruction in EX/MEM is written into the PC at the end of IF; otherwise, the incremented PC will be written back. (As we said earlier, this effect of branches leads to complications in the pipeline that we deal with in the next few sections.) The fixed-position encoding of the register source operands is critical to allowing the registers to be fetched during ID.

> 任何指令一次在管道的一个阶段中都处于活动状态；因此，代表指令采取的任何行动都会发生在两对管道统计之间。因此，我们还可以根据指令类型检查在任何管道阶段必须发生的事情来查看管道的活动。[图 C.20](#_bookmark505) 显示了此视图。命名管道寄存器的字段以显示从一个阶段到下一个阶段的数据流。请注意，前两个阶段中的操作与当前指令类型无关；它们必须独立，因为直到 ID 阶段结束之前，该指令才被解码。IF 活动取决于 EX/MEM 中的指令是否为分支。如果是这样，则在 if 的末尾将 EX/MEM 中分支指令的分支目标地址写入 PC；否则，增量的 PC 将被写回。(正如我们之前说的那样，分支机构的这种影响会导致我们在接下来的几节中处理的管道中的并发症。)寄存器源操作数的固定位置编码对于允许在 ID 期间获取寄存器至关重要。

Figure C.20 Events on every pipe stage of the RISC V pipeline. Let’s review the actions in the stages that are specific to the pipeline organization. In IF, in addition to fetching the instruction and computing the new PC, we store the incremented PC both into the PC and into a pipeline register (NPC) for later use in computing the branch-target address. This structure is the same as the organization in [Figure C.19](#_bookmark504), where the PC is updated in IF from one of two sources. In ID, we fetch the registers, extend the sign of the 12 bits of the IR (the immediate field), and pass along the IR and NPC. During EX, we perform an ALU operation or an address calculation; we pass along the IR and the B register (if the instruction is a store). We also set the value of cond to 1 if the instruction is a taken branch. During the MEM phase, we cycle the memory, write the PC if needed, and pass along values needed in the final pipe stage. Finally, during WB, we update the register field from either the ALU output or the loaded value. For simplicity we always pass the entire IR from one stage to the next, although as an instruction proceeds down the pipeline, less and less of the IR is needed.

> 图 C.20 RISC V 管道的每个管道阶段的事件。让我们回顾一下管道组织特定的阶段中的行动。在 IF 中，除了获取指令并计算新 PC 外，我们还将增量 PC 存储到 PC 中并将其存储到 PC 和管道寄存器(NPC)中，以便以后在计算分支目标地址中使用。该结构与[图 C.19](#_bookmark504) 中的组织相同，其中 PC 从两个来源之一中进行了更新。在 ID 中，我们获取寄存器，扩展了 IR(直接场)12 位的标志，然后沿着 IR 和 NPC 传递。在 EX 期间，我们执行 ALU 操作或地址计算；我们通过 IR 和 B 寄存器(如果指令是商店)。如果指令是一个分支，我们还将 COND 的值设置为 1。在 MEM 阶段，我们循环存储器，在需要时编写 PC，并传递最终管道阶段所需的值。最后，在 WB 期间，我们从 ALU 输出或加载值更新寄存器字段。为了简单起见，我们总是将整个 IR 从一个阶段传递到另一个阶段，尽管随着说明的进行，我们需要越来越少的 IR。

To control this simple pipeline we need only determine how to set the con- trol for the four multiplexers in the data path of [Figure C.19](#_bookmark504). The two multi- plexers in the ALU stage are set depending on the instruction type, which is dictated by the IR field of the ID/EX register. The top ALU input multiplexer is set by whether the instruction is a branch or not, and the bottom multiplexer is set by whether the instruction is a register-register ALU operation or any other type of operation. The multiplexer in the IF stage chooses whether to use the value of the incremented PC or the value of the EX/MEM.ALUOutput (the branch target) to write into the PC. This multiplexer is controlled by the field EX/MEM.cond. The fourth multiplexer is controlled by whether the instruction in the WB stage is a load or an ALU operation. In addition to these four mul- tiplexers, there is one additional multiplexer needed that is not drawn in [Figure C.19](#_bookmark504), but whose existence is clear from looking at the WB stage of an ALU operation. The destination register field is in one of two different places depending on the instruction type (register-register ALU versus either ALU immediate or load). Thus, we will need a multiplexer to choose the correct por- tion of the IR in the MEM/WB register to specify the register destination field, assuming the instruction writes a register.

> 为了控制此简单的管道，我们只需要确定如何在[图 C.19]数据路径(#\_bookmark504)的数据路径中设置四个多路复用器的控制。根据指令类型，设置了 ALU 阶段中的两个多旋转器，该指令类型由 ID/EX 寄存器的 IR 字段决定。顶部 ALU 输入多路复用器是通过指令是否为分支来设置的，并且通过指令是寄存器注册的 ALU 操作还是任何其他类型的操作，则底部多路复用器是设置的。IF 阶段中的多路复用器选择是使用增量 PC 的值还是 EX/MEM.ALUOUTPUT(分支目标)的值来写入 PC。该多路复用器由 ex/mem.cond 字段控制。第四多路复用器是通过 WB 阶段的指令是负载还是 ALU 操作来控制的。除了这四个 mul-tiplexer 外，还需要另外一个多路复用器在[图 c.19](#_bookmark504) 中绘制，但是从查看 Alu 操作的 WB 阶段可以清楚地存在其存在。目的地寄存器字段位于两个不同位置之一，具体取决于指令类型(寄存器登录 Alu 与 ALU 立即或负载)。因此，我们将需要一个多路复用器来选择 MEM/WB 寄存器中 IR 的正确处理，以指定寄存器目标字段，假设该指令写入寄存器。

### Implementing the Control for the RISC V Pipeline

The process of letting an instruction move from the instruction decode stage (ID) into the execution stage (EX) of this pipeline is usually called _instruction issue_; an instruction that has made this step is said to have _issued_. For the RISC V integer pipeline, all the data hazards can be checked during the ID phase of the pipeline. If a data hazard exists, the instruction is stalled before it is issued. Likewise, we can determine what forwarding will be needed during ID and set the appropriate con- trols then. Detecting interlocks early in the pipeline reduces the hardware complex- ity because the hardware never has to suspend an instruction that has updated the state of the processor, unless the entire processor is stalled. Alternatively, we can detect the hazard or forwarding at the beginning of a clock cycle that uses an oper- and (EX and MEM for this pipeline). To show the differences in these two approaches, we will show how the interlock for a read after write (RAW) hazard with the source coming from a load instruction (called a _load interlock_) can be implemented by a check in ID, while the implementation of forwarding paths to the ALU inputs can be done during EX. [Figure C.21](#_bookmark506) lists the variety of circum- stances that we must handle.

> 让指令从指令解码阶段(ID)转移到该管道的执行阶段(EX)的过程通常称为* Instruction essue*;据说已经实现了这一步骤的指令。对于 RISC V 整数管道，可以在管道的 ID 阶段检查所有数据危害。如果存在数据危害，则该指令在发布之前就停滞不前。同样，我们可以在 ID 期间确定需要什么转发，然后设置适当的控制。在管道初期检测互锁可以减少硬件复合物，因为硬件不必暂停更新处理器状态的指令，除非整个处理器停滞不前。另外，我们可以在使用操作的时钟周期开始时检测到危险或转发(该管道的 EX 和 MEM)。为了显示这两种方法中的差异，我们将展示如何通过从 ID IN IN IN IN IN 进行校验来实现来自负载指令(称为 *load Interlock*)的源后读取(RAW)危险的互锁，而实现可以在 EX 期间完成转发到 ALU 输入的路径。[图 C.21](#_bookmark506) 列出了我们必须处理的各种情况。

Figure C.21 Situations that the pipeline hazard detection hardware can see by com- paring the destination and sources of adjacent instructions. This table indicates that the only comparison needed is between the destination and the sources on the two instructions following the instruction that wrote the destination. In the case of a stall, the pipeline dependences will look like the third case once execution continues (depen- dence overcome by forwarding). Of course, hazards that involve x0 can be ignored because the register always contains 0, and the preceding test could be extended to do this.

> 图 C.21 管道危险检测硬件可以通过汇总目的地和相邻说明来源来看到的情况。该表表示所需的唯一比较是在编写目的地的指令之后的两个说明中的目标和源之间。在摊位的情况下，一旦执行继续执行(通过转发克服)，管道依赖将看起来像第三种情况。当然，涉及 X0 的危害可以忽略，因为寄存器总是包含 0，并且可以扩展前测试以执行此操作。

Let’s start with implementing the load interlock. If there is a RAW hazard with the source instruction being a load, the load instruction will be in the EX stage when an instruction that needs the load data will be in the ID stage. Thus, we can describe all the possible hazard situations with a small table, which can be directly translated to an implementation. [Figure C.22](#_bookmark507) shows a table that detects all load interlocks when the instruction using the load result is in the ID stage.

> 让我们从实施负载互锁开始。如果源指令是负载的原始危害，则负载指令将在 EX 阶段，当需要负载数据的指令处于 ID 阶段时。因此，我们可以用小表格描述所有可能的危害情况，可以将其直接转化为实施。[图 C.22](#_bookmark507) 显示了一张表，该表可检测使用负载结果的指令处于 ID 阶段时。

Once a hazard has been detected, the control unit must insert the pipeline stall and prevent the instructions in the IF and ID stages from advancing. As we said earlier, all the control information is carried in the pipeline registers. (Carrying the instruction along is enough, because all control is derived from it.) Thus, when we detect a hazard we need only change the control portion of the ID/EX pipeline register to all 0s, which happens to be a no-op (an instruction that does nothing, such as add x0,x0,x0). In addition, we simply recirculate the contents of the IF/ID registers to hold the stalled instruction. In a pipeline with more complex haz- ards, the same ideas would apply: we can detect the hazard by comparing some set of pipeline registers and shift in no-ops to prevent erroneous execution.

> 一旦检测到危险，控制单元必须插入管道摊位，并防止 IF 和 ID 阶段中的说明前进。正如我们之前说的，所有控制信息均在管道登记册中携带。(随身携带指令就足够了，因为所有控制都是从中得出的。)因此，当我们检测到危险时，我们只需要更改 ID/EX 管道寄存器的控制部分，将其置于所有 0s，这恰好是一个 no-op(一种无用的指令，例如添加 x0，x0，x0)。此外，我们简单地将 IF/ID 寄存器的内容循环以保存停滞的指令。在具有更复杂危险的管道中，同样的想法将适用：我们可以通过比较一些管道寄存器并进行 NO-OPS 的转移来检测危险，以防止执行错误。

Figure C.22 The logic to detect the need for load interlocks during the ID stage of an instruction requires two comparisons, one for each possible source. Remember that the IF/ID register holds the state of the instruction in ID, which potentially uses the load result, while ID/EX holds the state of the instruction in EX, which is the load instruction.

> 图 C.22 逻辑在指令的 ID 阶段检测到负载互锁的需求需要两个比较，一个对每个可能的来源。请记住，IF/ID 寄存器在 ID 中持有指令的状态，该指令可能使用负载结果，而 ID/EX 持有 EX 中的指令状态，即负载指令。

Implementing the forwarding logic is similar, although there are more cases to consider. The key observation needed to implement the forwarding logic is that the pipeline registers contain both the data to be forwarded as well as the source and destination register fields. All forwarding logically happens from the ALU or data memory output to the ALU input, the data memory input, or the zero detec- tion unit. Thus, we can implement the forwarding by a comparison of the desti- nation registers of the IR contained in the EX/MEM and MEM/WB stages against the source registers of the IR contained in the ID/EX and EX/MEM registers. [Figure C.23](#_bookmark508) shows the comparisons and possible forwarding operations where the destination of the forwarded result is an ALU input for the instruction cur- rently in EX.

> 实施转发逻辑是类似的，尽管还有更多案例要考虑。实现转发逻辑所需的关键观察是，管道寄存器既包含要转发的数据，又包含源和目标寄存器字段。从逻辑上讲，所有转发都从 ALU 或数据存储器输出到 ALU 输入，数据存储器输入或零检测单元。因此，我们可以通过比较 EX/MEM/MEM/WB 阶段中包含的 IR 的 Destimition 注册机构对 ID/EX/EX/EX/MEM 寄存器中包含的 IR 源登记册的比较来实施转发。[图 C.23](#_bookmark508) 显示了比较和可能的转发操作，其中转发结果的目的地是 EX 中的指令的 ALU 输入。

In addition to the comparators and combinational logic that we must determine when a forwarding path needs to be enabled, we also must enlarge the multiplexers at the ALU inputs and add the connections from the pipeline registers that are used to forward the results. [Figure C.24](#_bookmark509) shows the relevant segments of the pipelined data path with the additional multiplexers and connections in place.

> 除了我们必须确定需要启用转发路径的比较器和组合逻辑外，我们还必须放大 ALU 输入处的多路复用器，并添加用于转发结果的管道寄存器中的连接。[图 C.24](#_bookmark509) 显示了带有附加的多路复用器和连接的管道数据路径的相关段。

For RISC V, the hazard detection and forwarding hardware is reasonably sim- ple; we will see that things become somewhat more complicated when we extend this pipeline to deal with floating point. Before we do that, we need to handle branches.

> 对于 RISC V，危险检测和转发硬件是合理的模拟。当我们扩展该管道以处理浮点时，我们将看到事情变得更加复杂。在这样做之前，我们需要处理分支机构。

### Dealing With Branches in the Pipeline

In RISC V, conditional branches depend on comparing two register values, which we assume occurs during the EX cycle, and uses the ALU for this function. We will need to also compute the branch target address. Because testing the branch condi- tion and determining the next PC will determine what the branch penalty is, we would like to compute both the possible PCs and choose the correct PC before the end of the EX cycle. We can do this by adding a separate adder that computes the branch target address during ID. Because the instruction is not yet decoded, we will be computing a possible target as if every instruction were a branch. This is likely faster than computing the target and evaluating the condition both in EX, but does use slightly more energy.

> 在 RISC V 中，条件分支取决于比较两个寄存器值，我们假设在 EX 周期内发生，并将 ALU 用于此函数。我们还需要计算分支目标地址。因为测试分支条件并确定下一辆 PC 将确定分支罚款是什么，所以我们想在 EX 周期结束之前计算可能的 PC 并选择正确的 PC。我们可以通过添加一个单独的加法器来完成此操作，该加法器在 ID 期间计算分支目标地址。由于指令尚未解码，因此我们将计算一个可能的目标，就好像每个指令都是分支一样。这是可能比计算目标并评估 EX 中的条件的速度更快，但确实使用了更多的能量。

Figure C.23 Forwarding of data to the two ALU inputs (for the instruction in EX) can occur from the ALU result (in EX/MEM or in MEM/WB) or from the load result in MEM/WB. There are 10 separate comparisons needed to tell whether a forwarding operation should occur. The top and bottom ALU inputs refer to the inputs corresponding to the first and second ALU source operands, respectively, and are shown explicitly in [Figure C.18](#_bookmark503) on page C.30 and in [Figure C.24](#_bookmark509) on page C.36. Remember that the pipeline latch for destination instruction in EX is ID/EX, while the source values come from the ALUOutput portion of EX/MEM or MEM/WB or the LMD portion of MEM/WB. There is one complication not addressed by this logic: dealing with multiple instructions that write the same register. For example, during the code sequence add x1, x2, x3; addi x1, x1, 2; sub x4, x3, x1, the logic must ensure that the sub instruction uses the result of the addi instruction rather than the result of the add instruction. The logic shown here can be extended to handle this case by simply testing that forwarding from MEM/WB is enabled only when forwarding from EX/MEM is not enabled for the same input. Because the addi result will be in EX/MEM, it will be forwarded, rather than the add result in MEM/WB.

> 图 C.23 将数据转发到两个 ALU 输入(对于 EX 中的指令)可能会从 ALU 结果(在 EX/MEM 或 MEM/WB 中)或 MEM/WB 中的负载结果发生。需要 10 个单独的比较来判断是否应该发生转发操作。顶部和底部 ALU 输入分别是指与第一和第二 Alu 源操作数相对应的输入，并在[图 C.18](#_bookmark503) 中明确显示。C.30 和[图 C.24](%EF%BC%83_Bookmark509) 在第 36 页。请记住，EX 中的目标指令的管道闩锁为 ID/EX，而源值来自 EX/MEM 或 MEM/WB 或 MEM/WB 的 LMD 部分的 AluOutput 部分。此逻辑没有解决一个并发症：处理编写相同寄存器的多个指令。例如，在代码序列中添加 x1，x2，x3;addi x1，x1，2;SUB X4，X3，X1，逻辑必须确保子指令使用 ADDI 指令的结果，而不是添加指令的结果。可以通过简单地测试仅在不启用从 EX/MEM 转发的情况下启用来自 MEM/WB 的转发，因此可以扩展此处显示的逻辑以处理此情况。因为 ADDI 结果将在 EX/MEM 中，因此将转发，而不是 MEM/WB 中的添加结果。

[Figure C.25](#_bookmark511) shows a pipelined data path assuming the adder in ID and the eval- uation of the branch condition in EX, a minor change of the pipeline structure. This pipeline will incur a two-cycle penalty on branches. In some early RISC proces- sors, such as MIPS, the condition test on branches was restricted to allow the test to occur in ID, reducing the branch delay to one cycle. Of course, that meant that an ALU operation to a register followed by a conditional branch based on that register incurred a data hazard, which does not occur if the branch condition is evaluated in EX.

> [图 C.25](#_bookmark511) 显示了一个管道的数据路径，假设 ID 中的加法器和 EX 中分支条件的评估是管道结构的微小变化。该管道将对分支机构造成两期罚款。在某些早期的 RISC 过程中，例如 MIPS，分支上的条件测试限制以允许在 ID 中进行测试，从而将分支延迟减少到一个周期。当然，这意味着基于该寄存器的有条件分支的 ALU 操作会引起数据危害，如果在 Ex 中评估分支条件，则不会发生。

As pipeline depths increased, the branch delay increased, which made dynamic branch prediction necessary. For example, a processor with separate decode and register fetch stages will probably have a branch delay that is at least 1 clock cycle longer. The branch delay, unless it is dealt with, turns into a branch penalty. Many older processors that implement more complex instruction sets have branch delays of 4 clock cycles or more, and large, deeply pipelined processors often have branch penalties of 6 or 7. Aggressive high-end superscalars, such as the Intel i7 discussed in [Chapter 3](#_bookmark93), may have branch penalties of 10–15 cycles! In general, the deeper the pipeline, the worse the branch penalty in clock cycles, and the more critical that branches be accurately predicted.

> 随着管道深度的增加，分支延迟增加，这使动态分支预测必要。例如，具有单独解码和寄存器提取阶段的处理器可能具有至少 1 个时钟周期的分支延迟。除非处理，否则分支机构延迟会变成分支机构的罚款。许多实施更复杂指令集的较旧的处理器的分支延迟为 4 个时钟周期或更多，并且大型，管道深层的处理器通常具有 6 或 7 的分支罚款，为 6 或 7。激进的高端超级超级标准，例如在[第 3 章中讨论的 Intel I7，例如 Intel I7](#_bookmark93)，可能的分支机构罚款为 10-15 个周期！通常，管道越深，时钟周期中的分支惩罚越严格，并且可以准确预测分支的关键。

Figure C.24 Forwarding of results to the ALU requires the addition of three extra inputs on each ALU multiplexer and the addition of three paths to the new inputs. The paths correspond to a bypass of: (1) the ALU output at the end of the EX, (2) the ALU output at the end of the MEM stage, and (3) the memory output at the end of the MEM stage.

> 图 C.24 将结果转发到 ALU 需要在每个 ALU 多路复用器上添加三个额外的输入，并在新输入中添加了三个路径。路径对应于：(1)EX 末端的 ALU 输出，(2)MEM 阶段末端的 ALU 输出，以及(3)MEM 阶段末端的内存输出。
