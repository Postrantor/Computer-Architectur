## Performance Measurement of Parallel Processors with Scientific Applications

> ##通过科学应用对平行处理器的性能测量

One of the most controversial issues in parallel processing has been how to mea- sure the performance of parallel processors. Of course, the straightforward answer is to measure a benchmark as supplied and to examine wall-clock time. Measuring wall-clock time obviously makes sense; in a parallel processor, measuring CPU time can be misleading because the processors may be idle but unavailable for other uses.

> 并行处理中最具争议的问题之一是如何确保并行处理器的性能。当然，直接的答案是测量提供的基准测试并检查墙壁锁定时间。测量墙壁锁定时间显然是有道理的。在并行处理器中，测量 CPU 时间可能会产生误导，因为处理器可能闲置但无法用于其他用途。

Users and designers are often interested in knowing not just how well a mul- tiprocessor performs with a certain fixed number of processors, but also how the performance scales as more processors are added. In many cases, it makes sense to scale the application or benchmark, since if the benchmark is unscaled, effects aris- ing from limited parallelism and increases in communication can lead to results that are pessimistic when the expectation is that more processors will be used to solve larger problems. Thus, it is often useful to measure the speedup as processors are added both for a fixed-size problem and for a scaled version of the problem, providing an unscaled and a scaled version of the speedup curves. The choice of how to measure the uniprocessor algorithm is also important to avoid anomalous results, since using the parallel version of the benchmark may understate the uniprocessor performance and thus overstate the speedup.

> 用户和设计师通常对不仅了解 Mul-TipRocessor 在一定固定数量的处理器方面的性能，而且还要了解添加更多处理器的性能。在许多情况下，扩展应用程序或基准是有意义的，因为如果基准未量化，则会产生有限的并行性和沟通增加产生的效果，这可能会导致结果，而当期望更多的处理器将用于使用更多处理器时，这种结果是悲观的。解决更大的问题。因此，在为固定尺寸的问题和缩放版本的问题上添加处理器时，测量加速器通常是有用的，提供了加速曲线的未量化和缩放版本。如何测量单层处理算法的选择对于避免异常结果也很重要，因为使用基准的并行版本可能会低估单层处理器性能，从而夸大了加速。

Once we have decided to measure scaled speedup, the question is `how` to scale the application. Let’s assume that we have determined that running a benchmark of size `n` on `p` processors makes sense. The question is how to scale the benchmark to run on `m p` processors. There are two obvious ways to scale the problem:

> 一旦我们决定测量缩放速度，问题就是 *how* 来扩展应用程序。假设我们已经确定在 *p* 处理器上运行大小 *n* 的基准是有道理的。问题是如何扩展基准以在 *M P* 处理器上运行。有两种明显的方法来扩展问题：

1. keeping the amount of memory used per processor constant, and (2) keeping the total execution time, assuming perfect speedup, constant. The first method, called `memory-constrained scaling`, specifies running a problem of size `m n` on `m p` processors. The second method, called `time-constrained scaling`, requires that we know the relationship between the running time and the problem size, since the former is kept constant. For example, suppose the running time of the appli- cation with data size `n` on `p` processors is proportional to `n`<sup>2</sup>/_p_. Then, with time- constrained scaling, the problem to run is the problem whose ideal running time on `m p` processors is still `n`<sup>2</sup>/_p_. The problem with this ideal running time has size

> 1.保持每个处理器使用的内存量，以及(2)保留总执行时间，假设完美的加速，恒定。第一个方法称为* memory-straunder scaleing*，指定在 *M P* 处理器上运行大小 *M n* 的问题。第二种方法称为* Time 受限的缩放*，要求我们知道运行时间和问题大小之间的关系，因为前者保持恒定。例如，假设在 *p* 处理器上使用数据大小 *n* 的应用程序的运行时间与 *n* <sup> 2 </sup>/* p *成比例。然后，随着时间约束的缩放，要运行的问题是* M P *处理器上理想的运行时间仍然是* n* <sup> 2 </sup>/_ p_。这个理想的运行时间的问题有大小

Example Suppose we have a problem whose execution time for a problem of size `n` is pro- portional to `n`<sup>3</sup>. Suppose the actual running time on a 10-processor multiprocessor is 1 hour. Under the time-constrained and memory-constrained scaling models, find the size of the problem to run and the effective running time for a 100-processor multiprocessor.

> 示例假设我们有一个问题，其大小 *n* 问题的执行时间是 *n* <sup> 3 </sup>的问题。假设 10 处理器多处理器上的实际运行时间为 1 小时。在时间约束和内存约束的缩放模型下，找到要运行的问题的大小以及 100 处理器多处理器的有效运行时间。

_Answer_ For the time-constrained pprob lem, the ideal running time is the same, 1 hour, memory-constrained scaling, the size of the problem is 10*n* and the ideal execution time is 10<sup>3</sup>/10, or 100 hours! Since most users will be reluctant to run a problem on an order of magnitude more processors for 100 times longer, this size problem is probably unrealistic.

> `answer` 对于时间约束的 PPROB LEM，理想的运行时间是相同的，1 小时，内存约束的缩放，问题的大小为 10* n*，理想的执行时间为 10 <sup> 3 </sup>/10，或 100 小时！由于大多数用户将不愿意在更长的 100 倍的数量级上运行问题，因此这种尺寸问题可能是不现实的。

In addition to the scaling methodology, there are questions as to how the pro- gram should be scaled when increasing the problem size affects the quality of the result. Often, we must change other application parameters to deal with this effect. As a simple example, consider the effect of time to convergence for solving a dif- ferential equation. This time typically increases as the problem size increases, since, for example, we often require more iterations for the larger problem. Thus, when we increase the problem size, the total running time may scale faster than the basic algorithmic scaling would indicate.

> 除了缩放方法外，还有一些问题，即在增加问题大小时应如何缩放程序会影响结果的质量。通常，我们必须更改其他应用程序参数来处理此效果。作为一个简单的例子，请考虑求解差异方程的收敛时间的效果。这次通常会随着问题大小的增加而增加，因为例如，我们通常需要更多的迭代来解决更大的问题。因此，当我们增加问题大小时，总运行时间可能比基本算法缩放量表所指示的速度快。

For example, suppose that the number of iterations grows as the log of the prob- lem size. Then, for a problem whose algorithmic running time is linear in the size of the problem, the effective running time actually grows proportional to `n` log `n`. If we scaled from a problem of size `m` on 10 processors, purely algorithmic scaling would allow us to run a problem of size 10 `m` on 100 processors. Accounting for the increase in iterations means that a problem of size `k m`, where `k` log `k` 10, will have the same running time on 100 processors. This problem size yields a scaling of 5.72 `m`, rather than 10 `m`.

> 例如，假设迭代的数量随着概率大小的日志而生长。然后，对于一个问题，其算法运行时间在问题的大小上是线性的，有效的运行时间实际上与 *n* log `n` 成正比成正比。如果我们从 10 个处理器上的大小 *m* 问题缩放，则纯粹的算法缩放将使我们能够在 100 个处理器上运行大小 10 `m` 的问题。考虑到迭代的增加意味着大小 *K m* 的问题，其中 *k* log `k` 10 的 *k* 10 将在 100 个处理器上具有相同的运行时间。此问题大小的缩放比例为 5.72 `m`，而不是 10 `m`。

In practice, scaling to deal with error requires a good understanding of the application and may involve other factors, such as error tolerances (for example, it affects the cell-opening criteria in Barnes-Hut). In turn, such effects often signif- icantly affect the communication or parallelism properties of the application as well as the choice of problem size.

> 实际上，缩放以处理错误需要对应用程序有很好的了解，并且可能涉及其他因素，例如错误公差(例如，它会影响 Barnes-HUT 中的细胞开放标准)。反过来，这种效果通常显着影响应用程序的通信或并行性属性以及问题大小的选择。

Scaled speedup is not the same as unscaled (or true) speedup; confusing the two has led to erroneous claims (e.g., see the discussion in [Section I.6](#performance-measurement-of-parallel-processors-with-scientific-applications)). Scaled speedup has an important role, but only when the scaling methodology is sound and the results are clearly reported as using a scaled version of the application. Singh, Hennessy, and Gupta \[1993] described these issues in detail.

> 缩放速度与未添加(或真)的加速度不同；混淆这两者导致了错误的主张(例如，请参见[I.6 节]中的讨论(＃partury-seasurement-of-paralitalle-processors-with-scientific-Applications))。缩放速度具有重要的作用，但是只有当缩放方法是合理的，并且结果清楚地报道了使用该应用程序的缩放版本。Singh，Hennessy 和 Gupta \ [1993 ]详细描述了这些问题。
