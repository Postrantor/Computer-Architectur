> [!note]
> 这里使用泊松变量来分析磁盘的 IO，很有意思
> 或许这个方法也可以用来分析实时性中各个任务的时间？

## A Little Queuing Theory

In processor design, we have simple back-of-the-envelope calculations of perfor- mance associated with the CPI formula in [Chapter 1](#_bookmark2), or we can use full-scale sim- ulation for greater accuracy at greater cost. In I/O systems, we also have a bestcase analysis as a back-of-the-envelope calculation. Full-scale simulation is also much more accurate and much more work to calculate expected performance.

> 在处理器设计中，我们在[第 1 章](#_bookmark2)中对与 CPI 公式相关的 pertormence 进行了简单的后面计算，否则我们可以使用全尺度模拟以提高精确度，以更高的成本准确性。在 I/O 系统中，我们还具有最佳的案例分析作为底板计算。全尺度模拟也更加准确，并且可以计算预期性能的更多工作。

With I/O systems, however, we also have a mathematical tool to guide I/O design that is a little more work and much more accurate than best-case analysis, but much less work than full-scale simulation. Because of the probabilistic nature of I/O events and because of sharing of I/O resources, we can give a set of simple theorems that will help calculate response time and throughput of an entire I/O sys- tem. This helpful field is called _queuing theory_. Since there are many books and courses on the subject, this section serves only as a first introduction to the topic. However, even this small amount can lead to better design of I/O systems.

> 但是，使用 I/O 系统，我们还拥有一个数学工具来指导 I/O 设计，它比最佳案例分析要多得多，而且更准确，但比全尺度仿真要少得多。由于 I/O 事件的概率性质以及 I/O 资源共享，我们可以提供一组简单的定理，这些定理将有助于计算整个 I/O 系统的响应时间和吞吐量。这个有用的领域称为 *queuing 理论*。由于有关该主题的书籍和课程很多，因此本节仅作为该主题的首次介绍。但是，即使是少量的 I/O 系统也可以更好地设计。

Let’s start with a black-box approach to I/O systems, as shown in [Figure D.15](#_bookmark555). In our example, the processor is making I/O requests that arrive at the I/O device, and the requests “depart” when the I/O device fulfills them.

> 让我们从“ I/O 系统”的黑框方法开始，如[图 D.15](#_bookmark555) 所示。在我们的示例中，处理器正在制作到达 I/O 设备的 I/O 请求，并且当 I/O 设备符合 I/O 设备时，请求“离开”。

We are usually interested in the long term, or steady state, of a system rather than in the initial start-up conditions. Suppose we weren’t. Although there is a mathematics that helps (Markov chains), except for a few cases, the only way to solve the resulting equations is simulation. Since the purpose of this section is to show something a little harder than back-of-the-envelope calculations but less than simulation, we won’t cover such analyses here. (See the references in [Appen-](#_bookmark903) [dix M](#_bookmark903) for more details.)

> 我们通常对系统的长期或稳态感兴趣，而不是对初始启动条件感兴趣。假设我们不是。尽管有一个数学可以帮助(马尔可夫链)，但除了几种情况外，求解结果方程的唯一方法是仿真。由于本节的目的是显示出比底板计算的难度，但少于模拟，因此我们不会在此处进行此类分析。(有关更多详细信息，请参见 [appen-](#_bookmark903)中的参考文献(#\_bookmark903)[dix m](＃

Figure D.15 Treating the I/O system as a black box. This leads to a simple but impor- tant observation: If the system is in steady state, then the number of tasks entering the system must equal the number of tasks leaving the system. This _flow-balanced_ state is necessary but not sufficient for steady state. If the system has been observed or mea- sured for a sufficiently long time and mean waiting times stabilize, then we say that the system has reached steady state.

> 图 D.15 将 I/O 系统视为黑匣子。这导致了一个简单但重要的观察：如果系统处于稳态状态，则输入系统的任务数必须等于离开系统的任务数。此 *Flow-Balanced* 状态是必要的，但对于稳态不足。如果已经观察到该系统的时间足够长，并且平均等待时间稳定，那么我们说该系统已达到稳态。

Hence, in this section we make the simplifying assumption that we are evalu- ating systems with multiple independent requests for I/O service that are in equi- librium: The input rate must be equal to the output rate. We also assume there is a steady supply of tasks independent for how long they wait for service. In many real systems, such as TPC-C, the task consumption rate is determined by other system characteristics, such as memory capacity.

> 因此，在本节中，我们做出了一个简化的假设，即我们正在评估系统中有多个独立请求的 I/O 服务的系统：输入率必须等于输出率。我们还假设，在等待服务的时间内，独立于任务的稳定供应。在许多实际系统(例如 TPC-C)中，任务消耗率由其他系统特征(例如内存容量)决定。

This leads us to _Little_’_s law,_ which relates the average number of tasks in the system, the average arrival rate of new tasks, and the average time to perform a task:

> 这使我们达到了\_ _’_ s 的法律，\_ \_将系统中的平均任务数，新任务的平均到达率以及执行任务的平均时间相关联：

Mean number of tasks in system ¼ Arrival rate ×Mean response time

> 系统 ¼ 到达率 × 平均响应时间的平均任务数

Little’s law applies to any system in equilibrium, as long as nothing inside the black box is creating new tasks or destroying them. Note that the arrival rate and the response time must use the same time unit; inconsistency in time units is a common cause of errors.

> Little 的定律适用于任何平衡的系统，只要黑匣子内部没有任何东西可以创建新任务或破坏它们即可。请注意，到达率和响应时间必须使用相同的时间单元；时间单位的不一致是错误的常见原因。

Let’s try to derive Little’s law. Assume we observe a system for Time<sub>observe</sub> minutes. During that observation, we record how long it took each task to be serviced, and then sum those times. The number of tasks completed during Time<sub>observe</sub> is Number<sub>task</sub>, and the sum of the times each task spends in the system is Time<sub>accumulated</sub>. Note that the tasks can overlap in time, so Time<sub>accumulated</sub> Time<sub>observed</sub>. Then,

> 让我们尝试得出小定律。假设我们观察到时间<sub>观察</sub>分钟的系统。在观察期间，我们记录了每项任务需要多长时间，然后总结了这些时间。在时间<sub>观察</sub>的时间<sub>任务</sub>期间完成的任务数</sub>，每个任务在系统中花费的时间的总和为 time <ub>累计</sub>。请注意，任务可以随时间重叠，因此 Time <sub> </sub> Time <sub>观察到的</sub>。然后，

Figure D.16 The single-server model for this section. In this situation, an I/O request

> 图 D.16 本节的单服务器模型。在这种情况下，I/O 请求

If we open the black box, we see [Figure D.16](#_bookmark556). The area where the tasks accu- mulate, waiting to be serviced, is called the _queue_, or _waiting line_. The device per- forming the requested service is called the _server_. Until we get to the last two pages of this section, we assume a single server.

Little’s law and a series of definitions lead to several useful equations:

- Time<sub>server</sub>—Average time to service a task; average service rate is 1/Time<sub>server</sub>, traditionally represented by the symbol μ in many queuing texts.
- Time<sub>queue</sub>—Average time per task in the queue.
- Time<sub>system</sub>—Average time/task in the system, or the response time, which is the sum of Time<sub>queue</sub> and Time<sub>server</sub>.
- Arrival rate—Average number of arriving tasks/second, traditionally represented by the symbol λ in many queuing texts.
- Length<sub>server</sub>—Average number of tasks in service.
- Length<sub>queue</sub>—Average length of queue.
- Length<sub>system</sub>—Average number of tasks in system, which is the sum of Length<sub>queue</sub> and Length<sub>server</sub>.

One common misunderstanding can be made clearer by these definitions: whether the question is how long a task must wait in the queue before service starts (Time- <sub>queue</sub>) or how long a task takes until it is completed (Time<sub>system</sub>). The latter term is what we mean by response time, and the relationship between the terms is Timesystem Timequeue +Timeserver.

> 通过以下定义，可以更清楚地表达一种常见的误解：问题是，任务必须在队列中等待多长时间，然后才能开始服务(Time- <ub> queue </sub>)或任务需要多长时间(直到完成)(Time <sub>系统</sub>)。后一个术语是响应时间的含义，术语之间的关系是 TimeSystem Timequeue +Timeserver。

The mean number of tasks in service (Length<sub>server</sub>) is simply Arrival rate

Time<sub>server</sub>, which is Little’s law. Server utilization is simply the mean number of tasks being serviced divided by the service rate. For a single server, the service rate is 1/Time<sub>server</sub>. Hence, server utilization (and, in this case, the mean number of tasks per server) is simply:

> Time <ub>服务器</sub>，这是 Little 的定律。服务器利用仅仅是服务率除以服务率的平均任务数量。对于单个服务器，服务速率为 1/Time <ub>服务器</sub>。因此，服务器利用率(在这种情况下，每个服务器的平均任务数)简单：

Server utilization ¼ Arrival rate ×Time<sub>server</sub>

> 服务器利用率 ¼ 到达率 ×Time <sub>服务器</sub>

Service utilization must be between 0 and 1; otherwise, there would be more tasks arriving than could be serviced, violating our assumption that the system is in equi- librium. Note that this formula is just a restatement of Little’s law. Utilization is also called _traffic intensity_ and is represented bythesymbolρ inmanyqueuing theorytexts.

> 服务利用率必须在 0 到 1 之间；否则，到达的任务将比服务所能多，这违反了我们的假设，即该系统处于库存中。请注意，此公式只是对 Little 定律的重述。利用率也称为*交通强度*，代表 bytheSymbolρInmanyqueweystexts。

Example Suppose an I/O system with a single disk gets on average 50 I/O requests per second. Assume the average time for a disk to service an I/O request is 10 ms. What is the utilization of the I/O system?

> 示例假设一个具有单个磁盘的 I/O 系统平均每秒获得 50 I/O 请求。假设磁盘服务 I/O 请求的平均时间为 10 ms。I/O 系统的利用率是什么？

How the queue delivers tasks to the server is called the _queue discipline_. The sim- plest and most common discipline is _first in, first out_ (FIFO). If we assume FIFO, we can relate time waiting in the queue to the mean number of tasks in the queue:

> 队列如何将任务交付到服务器被称为 *Queue 纪律*。模拟和最常见的纪律是 *first in of first out*(fifo)。如果我们假设 FIFO，我们可以将等待队列的时间与队列中的平均任务数量相关联：

That is, the time in the queue is the number of tasks in the queue times the mean service time plus the time it takes the server to complete whatever task is being serviced when a new task arrives. (There is one more restriction about the arrival of tasks, which we reveal on page D-28.)

> 也就是说，队列中的时间是队列时间中平均服务时间的任务数，以及服务器完成新任务时要服务的任何任务所花费的时间。(关于任务的到来还有一个限制，我们在第 D-28 页上揭示了这一点。)

The last component of the equation is not as simple as it first appears. A new task can arrive at any instant, so we have no basis to know how long the existing task has been in the server. Although such requests are random events, if we know something about the distribution of events, we can predict performance.

> 方程的最后一个组件并不像首先出现的那样简单。一项新任务可以到达任何瞬间，因此我们没有理由知道服务器中现有任务已有多长时间。尽管此类请求是随机事件，但如果我们对事件的分布有所了解，我们可以预测性能。

### Poisson Distribution of Random Variables

To estimate the last component of the formula we need to know a little about dis- tributions of _random variables_. A variable is random if it takes one of a specified set of values with a specified probability; that is, you cannot know exactly what its next value will be, but you may know the probability of all possible values.

> 为了估计公式的最后一个组成部分，我们需要了解一些\_random 变量的分配。如果变量以指定概率为指定的值集之一，则变量是随机的；也就是说，您无法确切知道其下一个值将是什么，但是您可能知道所有可能值的概率。

Requests for service from an I/O system can be modeled by a random variable because the operating system is normally switching between several processes that generate independent I/O requests. We also model I/O service times by a random variable given the probabilistic nature of disks in terms of seek and rotational delays. One way to characterize the distribution of values of a random variable with discrete values is a _histogram_, which divides the range between the minimum and maximum values into subranges called _buckets_. Histograms then plot the

> 从 I/O 系统提供服务请求可以通过随机变量进行建模，因为操作系统通常在几个生成独立 I/O 请求的过程之间切换。我们还通过随机变量对 I/O 服务时间进行建模，鉴于磁盘在寻求和旋转延迟方面的概率性质。*histogram* 表征随机变量值的值的分布，它将最小值和最大值之间的范围划分为称为 *buckets* 的子弹。直方图然后绘制

number in each bucket as columns.

> 每个存储桶中的数字作为列。

Histograms work well for distributions that are discrete values—for example, the number of I/O requests. For distributions that are not discrete values, such as time waiting for an I/O request, we have two choices. Either we need a curve to plot the values over the full range, so that we can estimate accurately the value, or we need a very fine time unit so that we get a very large number of buckets to estimate time accurately. For example, a histogram can be built of disk service times mea- sured in intervals of 10 μs although disk service times are truly continuous.

> 直方图适用于离散值的分布，例如，I/O 请求的数量。对于不是离散值的发行版，例如等待 I/O 请求的时间，我们有两个选择。我们要么需要一条曲线来绘制整个范围内的值，因此我们可以准确估算值，或者我们需要一个非常好的时间单元，以便我们获得大量的存储桶来准确估算时间。例如，尽管磁盘服务时间确实是连续的，但可以用 10μs 的磁盘服务时间构建直方图。

Hence, to be able to solve the last part of the previous equation we need to characterize the distribution of this random variable. The mean time and some measure of the variance are sufficient for that characterization.

> 因此，要能够求解上一个方程的最后一部分，我们需要表征该随机变量的分布。平均时间和一定程度的方差度量足以使该表征进行表征。

For the first term, we use the _weighted arithmetic mean time_. Let’s first assume that after measuring the number of occurrences, say, _n<sub>i</sub>_, of tasks, you could compute frequency of occurrence of task _i_:

> 在第一个学期，我们使用*重量的算术平均时间*。首先假设，在测量了任务的发生次数(例如 *n <sub> i </sub> *)之后，您可以计算任务的发生频率* i*：：

To characterize variability about the mean, many people use the standard devi- ation. Let’s use the _variance_ instead, which is simply the square of the standard deviation, as it will help us with characterizing the probability distribution. Given the weighted arithmetic mean, the variance can be calculated as

> 为了表征均值的可变性，许多人使用标准偏差。让我们改用 *variance*，只是标准偏差的平方，因为它将帮助我们表征概率分布。考虑到加权算术平均值，可以计算出差异

It is important to remember the units when computing variance. Let’s assume the distribution is of time. If time is about 100 milliseconds, then squaring it yields 10,000 square milliseconds. This unit is certainly unusual. It would be more convenient if we had a unitless measure.

> 计算方差时记住单位很重要。假设分布是时间的。如果时间大约是 100 毫秒，那么将其平方拿到 10,000 平方英尺。这个单元肯定是不寻常的。如果我们有无单位措施，那将更方便。

To avoid this unit problem, we use the _squared coefficient of variance_, traditionally called C<sup>2</sup>:

> 为了避免此单元问题，我们使用* -Squared 方差系数*，传统上称为 c <sup> 2 </sup>：

We are trying to characterize random events, but to be able to predict performance we need a distribution of random events where the mathematics is tractable. The most popular such distribution is the _exponential distribution_, which has a C value of 1.

> 我们正在尝试表征随机事件，但是为了预测性能，我们需要在数学是可行的随机事件的分布中。最受欢迎的分布是*表达分布*，其 C 值为 1。

Note that we are using a constant to characterize variability about the mean. The invariance of C over time reflects the property that the history of events has no impact on the probability of an event occurring now. This forgetful property is called _mem- oryless_, and this property is an important assumption used to predict behavior using these models. (Suppose this memoryless property did not exist; then, we would have to worry about the exact arrival times of requests relative to each other, which would make the mathematics considerably less tractable!)

> 请注意，我们正在使用常数来表征平均值的可变性。随着时间的流逝，C 的不变性反映了事件历史对现在发生的事件的可能性没有影响的属性。这种健忘的属性称为 *mem- oryless*，该属性是使用这些模型预测行为的重要假设。(假设这种无内存的属性不存在；那么，我们必须担心相对于彼此的请求的确切到达时间，这将使数学变得大大降低！)

One of the most widely used exponential distributions is called a _Poisson dis- tribution_, named after the mathematician Sim´eon Poisson. It is used to characterize random events in a given time interval and has several desirable mathematical properties. The Poisson distribution is described by the following equation (called the probability mass function):

> 使用最广泛的指数分布之一称为 *poisson dis-tribution*，以数学家 Sim´eon Poisson 的名字命名。它用于在给定时间间隔中表征随机事件，并具有几种理想的数学属性。泊松分布由以下公式描述(称为概率质量函数)：

where _a_ Rate of events Elapsed time. If interarrival times are exponentially dis- tributed and we use the arrival rate from above for rate of events, the number of arrivals in a time interval _t_ is a _Poisson process_, which has the Poisson distribution with _a_ Arrival rate _t_. As mentioned on page D-26, the equation for Time<sub>server</sub> has another restriction on task arrival: It holds only for Poisson processes.

> 其中 *a* 事件速率经过的时间。如果将到达时间呈指数分配，并且我们将到达速率从上面的事件速率使用，则时间间隔中的到达数量是 *poisson Process*，它的 poisson 分布带有 *a* 到达率 *t*。如 D-26 页所述，时间<ub>服务器的方程式</sub>对任务到达有另一个限制：它仅适用于泊松过程。

Finally, we can answer the question about the length of time a new task must wait for the server to complete a task, called the _average residual service time_, which again assumes Poisson arrivals:

> 最后，我们可以回答有关新任务必须等待服务器完成任务的时间长度的问题，称为 *aaverage 残留服务时间*，该时间再次假设 Poisson 到达：

Although we won’t derive this formula, we can appeal to intuition. When the dis- tribution is not random and all possible values are equal to the average, the standard deviation is 0 and so C is 0. The average residual service time is then just half the average service time, as we would expect. If the distribution is random and it is Poisson, then C is 1 and the average residual service time equals the weighted arith- metic mean time.

> 尽管我们不会得出这个公式，但我们可以吸引直觉。当分布不是随机的，所有可能的值等于平均值时，标准偏差为 0，因此 C 为 0。剩余服务时间仅为平均服务时间的一半，正如我们所期望的那样。如果分布是随机的，并且是泊松，则 C 为 1，平均剩余服务时间等于加权算术平均时间。

Example Using the definitions and formulas above, derive the average time waiting in the queue (Time<sub>queue</sub>) in terms of the average service time (Time<sub>server</sub>) and server utilization.

> 示例使用上面的定义和公式，以平均服务时间(Time <sub> Server </sub>)和服务器利用率来得出队列中的平均时间(Time <ub> queue </sub>)。

_Answer_ All tasks in the queue (Length<sub>queue</sub>) ahead of the new task must be completed before the task can be serviced; each takes on average Time<sub>server</sub>. If a task is at the server, it takes average residual service time to complete. The chance the server is busy is _server utilization_; hence, the expected time for service is Server utiliza- tion ×Average residual service time. This leads to our initial formula:

> *answer *在新任务前的队列中(长度<sub>队列</sub>)中的所有任务必须在维修任务之前完成；每个都需要平均时间<sub>服务器</sub>。如果任务在服务器上，则需要平均剩余服务时间才能完成。服务器忙碌的机会是* server Lifitization*;因此，服务的预期时间是服务器利用 × 平均剩余服务时间。这导致了我们的初始公式：

Therefore, there are 0.5 requests on average in the queue.

> 因此，队列中平均有 0.5 个请求。

As mentioned earlier, these equations and this section are based on an area of applied mathematics called _queuing theory_, which offers equations to predict behavior of such random variables. Real systems are too complex for queuing theory to provide exact analysis, hence queuing theory works best when only approximate answers are needed.

> 如前所述，这些方程式和本节基于称为 *Queing Theory* 的应用数学领域，该方程提供了预测此类随机变量行为的方程式。实际系统太复杂了，无法排队理论，无法提供精确的分析，因此排队理论在只需要近似答案时效果最好。

Queuing theory makes a sharp distinction between past events, which can be characterized by measurements using simple arithmetic, and future events, which are predictions requiring more sophisticated mathematics. In computer systems, we commonly predict the future from the past; one example is least recently used block replacement (see [Chapter 2](#_bookmark46)). Hence, the distinction between measurements and predicted distributions is often blurred; we use measurements to verify the type of distribution and then rely on the distribution thereafter.

> 排队理论在过去的事件之间做出了鲜明的区别，可以通过简单算术和未来事件进行测量来表征，这是需要更复杂的数学的预测。在计算机系统中，我们通常可以预测过去的未来。一个示例是最近使用的块替换最少(请参阅[第 2 章](#_bookmark46))。因此，测量和预测分布之间的区别通常是模糊的。我们使用测量值来验证分布的类型，然后依赖于分布。

Let’s review the assumptions about the queuing model:

> 让我们回顾有关排队模型的假设：

- The system is in equilibrium.

> - 系统处于平衡状态。

- The times between two successive requests arriving, called the _interarrival times_, are exponentially distributed, which characterizes the arrival rate mentioned earlier.

> - 两个连续的请求之间的时间(称为*间 arrartarival times*)是指数分布的，这表征了前面提到的到达率。

- The number of sources of requests is unlimited. (This is called an _infinite population model_ in queuing theory; finite population models are used when arrival rates vary with the number of jobs already in the system.)

> - 请求来源的数量是无限的。(这在排队理论中称为\_infinite 人群模型；当到达率随系统中的作业数量而变化时，使用有限种群模型。)

- The server can start on the next job immediately after finishing the prior one.

> - 服务器可以在完成之前的下一个作业中立即启动。

- There is no limit to the length of the queue, and it follows the first in, first out order discipline, so all tasks in line must be completed.

> - 队列的长度没有限制，它遵循第一个，第一顺序纪律，因此必须完成所有任务。

- There is one server.

> - 有一台服务器。

Such a queue is called _M/M/1:_

> 这样的队列称为 *m/m/1：*

The assumption of exponential distribution is commonly used in queuing exam- ples for three reasons—one good, one fair, and one bad. The good reason is that a superposition ofmanyarbitrarydistributionsactsasanexponentialdistribution. Many times in computer systems, a particular behavior is the result of many components interacting, so an exponential distribution of interarrival times is the right model. The fair reason is that when variability is unclear, an exponential distribution with intermediate variability (C 1) is a safer guess than low variability (C 0) or high variability (large C). The bad reason is that the math is simpler if you assume expo- nential distributions.

> 指数分布的假设通常用于排队检查，这是出于三个原因 - 一个好，一个公平和一个不好的原因。充分的理由是，manyarbitraryDistributionsActsasanexponentialdistribution 的叠加。在计算机系统中很多次，特定的行为是许多组件相互作用的结果，因此，在 Arrarive 时间的指数分布是正确的模型。公平的原因是，当变异性不清楚时，具有中间变异性(C 1)的指数分布比低变异性(C 0)或高变异性(大 C)更安全。不好的理由是，如果您假设启动分布，则数学会更简单。

Let’s put queuing theory to work in a few examples.

> 让我们将排队理论用于一些示例。

Example Suppose a processor sends 40 disk I/Os per second, these requests are exponen- tially distributed, and the average service time of an older disk is 20 ms. Answer the following questions:

> 示例假设处理器每秒发送 40 个磁盘 I/OS，这些请求是分布式分布的，较旧磁盘的平均服务时间为 20 ms。回答以下问题：

1. On average, how utilized is the disk?

> 1.平均而言，磁盘的使用方式？

2. What is the average time spent in the queue?

> 2.队列中花费的平均时间是多少？

3. What is the average response time for a disk request, including the queuing time and disk service time?

> 3.磁盘请求的平均响应时间是多少，包括排队时间和磁盘服务时间？

_Answer_ Let’s restate these facts:

> *answer* 让我们重申以下事实：

The average response time is 10 + 6.7 ms or 16.7 ms, 6.0 times faster than the old response time even though the new service time is only 2.0 times faster.

> 平均响应时间为 10 + 6.7 ms 或 16.7 ms，即使新服务时间快 2.0 倍，也比旧响应时间快 6.0 倍。

Figure D.17 The M/M/m multiple-server model.

> 图 D.17 M/M/M 多服务器模型。

Thus far, we have been assuming a single server, such as a single disk. Many real systems have multiple disks and hence could use multiple servers, as in [Figure D.17](#_bookmark557). Such a system is called an _M/M/m_ model in queuing theory.

> 到目前为止，我们一直在假设一台服务器，例如单个磁盘。许多真实系统具有多个磁盘，因此可以使用多个服务器，如[图 D.17](#_bookmark557) 中。这种系统在排队理论中称为 *m/m/m* 模型。

Let’s give the same formulas for the M/M/m queue, using N<sub>servers</sub> to represent the number of servers. The first two formulas are easy:

> 让我们使用 N <sub>服务器</sub>为 M/M/M 队列提供相同的公式来表示服务器数。前两个公式很容易：

This formula is related to the one for M/M/1, except we replace utilization of a single server with the probability that a task will be queued as opposed to being immediately serviced, and divide the time in queue by the number of servers. Alas, calculating the probability of jobs being in the queue is much more compli- cated when there are N<sub>servers</sub>. First, the probability that there are no tasks in the system is

> 此公式与 M/M/1 的公式有关，除非我们替换单个服务器的利用率，概率是将任务排队而不是立即维修，并将排队的时间除以服务器的数量。las，当有 N <sub>服务器</sub>时，计算队列中的作业概率更为融合。首先，系统中没有任务的概率是

Example Suppose instead of a new, faster disk, we add a second slow disk and duplicate the data so that reads can be serviced by either disk. Let’s assume that the requests are all reads. Recalculate the answers to the earlier questions, this time using an M/M/ m queue.

> 示例假设我们添加了第二个慢速磁盘并复制数据，而不是新的，更快的磁盘，以便可以通过任何一个磁盘为读取。假设请求都是读取的。这次使用 M/ M/ M 队列重新计算早期问题的答案。

The average response time is 20 + 3.8 ms or 23.8 ms. For this workload, two disks cut the queue waiting time by a factor of 21 over a single slow disk and a factor of

> 平均响应时间为 20 + 3.8 ms 或 23.8 ms。对于此工作负载，两个磁盘在单个慢速磁盘上减少了队列等待时间 21 倍

1.75 versus a single fast disk. The mean service time of a system with a single fast disk, however, is still 1.4 times faster than one with two disks since the disk service time is 2.0 times faster.

> 1.75 与单个快速磁盘相比。但是，具有单个快速磁盘的系统的平均服务时间仍然比两个磁盘快的速度快 1.4 倍，因为磁盘服务时间快 2.0 倍。

It would be wonderful if we could generalize the M/M/m model to multiple queues and multiple servers, as this step is much more realistic. Alas, these models are very hard to solve and to use, and so we won’t cover them here.

> 如果我们可以将 M/M/M 模型推广到多个队列和多个服务器，那将是很棒的，因为此步骤更加现实。las，这些模型很难解决和使用，因此我们不会在这里介绍它们。
