## Historical Perspective and References

Section M.5 (available online) features a discussion on the development of pipelining and instruction-level parallelism covering both this appendix and the material in [Chapter 3](#_bookmark93). We provide numerous references for further reading and exploration of these topics.

## Updated Exercises by Diana Franklin

1. [15/15/15/15/25/10/15] <A.2>Use the following code fragment:

Assume that the initial value of x3 is x2 + 396.

1. [15] <C.2>Data hazards are caused by data dependences in the code. Whether a dependency causes a hazard depends on the machine implementation (i.e., number of pipeline stages). List all of the data dependences in the code above. Record the register, source instruction, and destination instruction; for example, there is a data dependency for register x1 from the ld to the addi.
2. [15] <C.2>Show the timing of this instruction sequence for the 5-stage RISC pipeline without any forwarding or bypassing hardware but assuming that a register read and a write in the same clock cycle "forwards" through the register file, as between the add and or shown in [Figure C.5](#_bookmark489). Use a pipeline timing chart like that in [Figure C.8](#_bookmark492). Assume that the branch is handled by flushing the pipeline. If all memory references take 1 cycle, how many cycles does this loop take to execute?
3. [15] <C.2>Show the timing of this instruction sequence for the 5-stage RISC pipeline with full forwarding and bypassing hardware. Use a pipeline timing chart like that shown in [Figure C.8](#_bookmark492). Assume that the branch is handled by pre- dicting it as not taken. If all memory references take 1 cycle, how many cycles does this loop take to execute?
4. [15] <C.2>Show the timing of this instruction sequence for the 5-stage RISC pipeline with full forwarding and bypassing hardware, as shown in [Figure C.6](#_bookmark490). Use a pipeline timing chart like that shown in [Figure C.8](#_bookmark492). Assume that the branch is handled by predicting it as taken. If all memory references take 1 cycle, how many cycles does this loop take to execute?
5. [25] <C.2>High-performance processors have very deep pipelines—more than 15 stages. Imagine that you have a 10-stage pipeline in which every stage of the 5-stage pipeline has been split in two. The only catch is that, for data for- warding, data are forwarded from the end of a _pair of stages_ to the beginning of the two stages where they are needed. For example, data are forwarded from the output of the second execute stage to the input of the first execute stage, still causing a 1-cycle delay. Show the timing of this instruction sequence for the 10-stage RISC pipeline with full forwarding and bypassing hardware. Use a pipeline timing chart like that shown in [Figure C.8](#_bookmark492) (but with stages labeled IF1, IF2, ID1, etc.). Assume that the branch is handled by predicting it as taken. If all memory references take 1 cycle, how many cycles does this loop take to execute?
6. [10] <C.2>Assume that in the 5-stage pipeline, the longest stage requires 0.8 ns, and the pipeline register delay is 0.1 ns. What is the clock cycle time of the 5-stage pipeline? If the 10-stage pipeline splits all stages in half, what is the cycle time of the 10-stage machine?

<!--  -->

1. [15] <C.2>Using your answers from parts (d) and (e), determine the cycles per instruction (CPI) for the loop on a 5-stage pipeline and a 10-stage pipeline. Make sure you count only from when the first instruction reaches the write-back stage to the end. Do not count the start-up of the first instruction. Using the clock cycle time calculated in part (f), calculate the average instruction execute time for each machine.
2. [15/15] <C.2>Suppose the branch frequencies (as percentages of all instructions) are as follows: Conditional branches 15%

Jumps and calls 1%

Taken conditional branches 60% are taken

1. [15] <C.2>We are examining a four-stage pipeline where the branch is resolved at the end of the second cycle for unconditional branches and at the end of the third cycle for conditional branches. Assuming that only the first pipe stage can always be completed independent of whether the branch is taken and ignoring other pipeline stalls, how much faster would the machine be without any branch hazards?
2. [15] <C.2>Now assume a high-performance processor in which we have a 15- deep pipeline where the branch is resolved at the end of the fifth cycle for unconditional branches and at the end of the tenth cycle for conditional branches. Assuming that only the first pipe stage can always be completed inde- pendent of whether the branch is taken and ignoring other pipeline stalls, how much faster would the machine be without any branch hazards?
3. [5/15/10/10] <C.2>We begin with a computer implemented in single-cycle implementation. When the stages are split by functionality, the stages do not require exactly the same amount of time. The original machine had a clock cycle time of 7 ns. After the stages were split, the measured times were IF, 1 ns; ID, 1.5 ns; EX, 1 ns; MEM, 2 ns; and WB, 1.5 ns. The pipeline register delay is 0.1 ns.
4. [5] <C.2>What is the clock cycle time of the 5-stage pipelined machine?
5. [15] <C.2>If there is a stall every four instructions, what is the CPI of the new machine?
6. [10] <C.2>What is the speedup of the pipelined machine over the single-cycle machine?
7. [10] <C.2>If the pipelined machine had an infinite number of stages, what would its speedup be over the single-cycle machine?

<!-- -->

1. [15] <C.1, C.2>A reduced hardware implementation of the classic five-stage RISC pipeline might use the EX stage hardware to perform a branch instructio comparison and then not actually deliver the branch target PC to the IF stage until the clock cycle in which the branch instruction reaches the MEM stage. Control hazard stalls can be reduced by resolving branch instructions in ID, but improving performance in one respect may reduce performance in other circumstances. Write a small snippet of code in which calculating the branch in the ID stage causes a data hazard, even with data forwarding.
2. [12/13/20/20/15/15] <C.2, C.3>For these problems, we will explore a pipeline for a register-memory architecture. The architecture has two instruction formats: a register-register format and a register-memory format. There is a single-memory addressing mode (offset +base register). There is a set of ALU operations with the format: where the ALUop is one of the following: add, subtract, AND, OR, load (Rsrc1 ignored), or store. Rsrc or Rdest are registers. MEM is a base register and offset pair. Branches use a full compare of two registers and are PC relative. Assume that this machine is pipelined so that a new instruction is started every clock cycle. The pipeline structure, similar to that used in the VAX 8700 micropipeline (Clark, 1987), is

The first ALU stage is used for effective address calculation for memory references and branches. The second ALU cycle is used for operations and branch compa- rison. RF is both a decode and register-fetch cycle. Assume that when a register read and a register write of the same register occur in the same clock, the write data are forwarded.

1. [12] <C.2>Find the number of adders needed, counting any adder or incre- menter; show a combination of instructions and pipe stages that justify this answer. You need only give one combination that maximizes the adder count.
2. [13] <C.2>Find the number of register read and write ports and memory read and write ports required. Show that your answer is correct by showing a combination of instructions and pipeline stage indicating the instruction and the number of read ports and write ports required for that instruction.
3. [20] <C.3>Determine any data forwarding for any ALUs that will be needed. Assume that there are separate ALUs for the ALU1 and ALU2 pipe stages. Put in all forwarding among ALUs necessary to avoid or reduce stalls. Show the relationship between the two instructions involved in forwarding using the for- mat of the table in [Figure C.23](#_bookmark508) but ignoring the last two columns. Be careful to consider forwarding across an intervening instruction—for example,

<!--  -->

1. [20] <C.3>Show all of the data forwarding requirements necessary to avoid or reduce stalls when either the source or destination unit is not an ALU. Use the same format as in [Figure C.23](#_bookmark508), again ignoring the last two columns. Remember to forward to and from memory references.
2. [15] <C.3>Show all the remaining hazards that involve at least one unit other than an ALU as the source or destination unit. Use a table like that shown in [Figure C.25](#_bookmark511), but replace the last column with the lengths of the hazards.
3. [15] <C.2>Show all control hazards by example and state the length of the stall. Use a format like that shown in [Figure C.11](#_bookmark495), labeling each example.

   1. [12/13/13/15/15] <C.1, C.2, C.3>We will now add support > for register-memory ALU operations to the classic five-stage > RISC pipeline. To offset this increase in complexity, _all_ memory addressing will be restricted to register indirect (i.e., all addresses are simply a value held in a register; no offset or displacement may be added to the register value). For example, the register-memory instruction add x4, x5, (x1) means add the contents of register x5 to the contents of the memory location with address equal to the value in register x1 and put the sum in register x4. Register-register ALU operations are unchanged. The following items apply to the integer RISC pipeline:
4. [12] <C.1>List a rearranged order of the five traditional stages of the RISC pipeline that will support register-memory operations implemented exclusively by register indirect addressing.
5. [13] <C.2, C.3>Describe what new forwarding paths are needed for the rear- ranged pipeline by stating the source, destination, and information transferred on each needed new path.
6. [13] <C.2, C.3>For the reordered stages of the RISC pipeline, what new data hazards are created by this addressing mode? Give an instruction sequence illus- trating each new hazard.
7. [15] <C.3>List all of the ways that the RISC pipeline with register-memory ALU operations can have a different instruction count for a given program than the original RISC pipeline. Give a pair of specific instruction sequences, one for the original pipeline and one for the rearranged pipeline, to illustrate each way.
8. [15] <C.3>Assume that all instructions take 1 clock cycle per stage. List all of the ways that the register-memory RISC V can have a different CPI for a given program as compared to the original RISC V pipeline.
9. [10/10] <C.3>In this problem, we will explore how deepening the pipeline affects performance in two ways: faster clock cycle and increased stalls due to data and control hazards. Assume that the original machine is a 5-stage pipeline with a 1 ns clock cycle. The second machine is a 12-stage pipeline with a 0.6 ns clock cycle. The 5-stage pipeline experiences a stall due to a data hazard every five instructions, whereas the 12-stage pipeline experiences three stalls every eight instructions. In addition, branches constitute 20% of the instructions, and the mis- prediction rate for both machines is 5%.
10. [10] <C.3>What is the speedup of the 12-stage pipeline over the 5-stage pipe- line, taking into account only data hazards?
11. [10] <C.3>If the branch mispredict penalty for the first machine is 2 cycles but the second machine is 5 cycles, what are the CPIs of each, taking into account the stalls due to branch mispredictions?
12. [15] <C.5>Construct a table like that shown in [Figure C.21](#_bookmark506) to check for WAW stalls in the RISC V FP pipeline of [Figure C.30](#_bookmark517). Do not consider FP divides.
13. [20/22/22] <C.4, C.6>In this exercise, we will look at how a common vector loop runs on statically and dynamically scheduled versions of the RISC V pipe- line. The loop is the so-called DAXPY loop (discussed extensively in Appendix G) and the central operation in Gaussian elimination. The loop implements the vector operation Y= _a_\*_X_ + _Y_ for a vector of length 100. Here is the MIPS code for the loop:

For parts (a) to (c), assume that integer operations issue and complete in 1 clock cycle (including loads) and that their results are fully bypassed. You will use the FP latencies (only) shown in [Figure C.29](#_bookmark516), but assume that the FP unit is fully pipe- lined. For scoreboards below, assume that an instruction waiting for a result from another function unit can pass through read operands at the same time the result is written. Also assume that an instruction in WB completing will allow a currently active instruction that is waiting on the same functional unit to issue in the same clock cycle in which the first instruction completes WB.

1. [20] <C.5>For this problem, use the RISC V pipeline of Section C.5 with the pipeline latencies from [Figure C.29](#_bookmark516), but a fully pipelined FP unit, so the initiation interval is 1. Draw a timing diagram, similar to [Figure C.32](#_bookmark519), showing the timing of each instruction's execution. How many clock cycles does each loop iteration take, counting from when the first instruction enters the WB stage to when the last instruction enters the WB stage?
2. [20] <C.8>Perform _static instruction reordering_ to reorder the instructions to minimize the stalls for this loop, renaming registers where necessary. Use all the same assumptions as in (a). Draw a timing diagram, similar to [Figure C.32](#_bookmark519), showing the timing of each instruction's execution. How many clock cycles does each loop iteration take, counting from when the first instruction enters the WB stage to when the last instruction enters the WB stage?
3. [20] <C.8>Using the original code above, consider how the instructions would have executed using scoreboarding, a form of dynamic scheduling. Draw a timing diagram, similar to [Figure C.32](#_bookmark519), showing the timing of the instructions through stages IF, IS (issue), RO (read operands), EX (exe- cution), and WR (write result). How many clock cycles does each loop iter- ation take, counting from when the first instruction enters the WB stage to when the last instruction enters the WB stage?
4. [25] <C.8>It is critical that the scoreboard be able to distinguish RAW and WAR hazards, because a WAR hazard requires stalling the instruction doing the writing until the instruction reading an operand initiates execution, but a RAW hazard requires delaying the reading instruction until the writing instruction finishes—just the opposite. For example, consider the sequence: fmul.d f0,f6,f4 fsub.d f8,f0,f2 fadd.d f2,f10,f2

The fsub.d depends on the fmul.d (a RAW hazard), thus the fmul.d must be allowed to complete before the fsub.d. If the fmul.d were stalled for the fsub.d due to the inability to distinguish between RAW and WAR hazards, the processor will deadlock. This sequence contains a WAR hazard between the fadd.d and the fsub.d, and the fadd.d cannot be allowed to complete until the fsub.d begins execution. The difficulty lies in distinguishing the RAW haz- ard between fmul.d and fsub.d, and the WAR hazard between the fsub.d and fadd.d. To see just why the three-instruction scenario is important, trace the han- dling of each instruction stage by stage through issue, read operands, execute, and write result. Assume that each scoreboard stage other than execute takes 1 clock cycle. Assume that the fmul.d instruction requires 3 clock cycles to execute and that the fsub.d and fadd.d instructions each take 1 cycle to execute. Finally, assume that the processor has two multiply function units and two add function units. Present the trace as follows.

1. Make a table with the column headings Instruction, Issue, Read Operands, Exe- cute, Write Result, and Comment. In the first column, list the instructions in program order (be generous with space between instructions; larger table cells will better hold the results of your analysis). Start the table by writing a 1 in the Issue column of the fmul.d instruction row to show that fmul.d completes the issue stage in clock cycle 1. Now, fill in the stage columns of the table through the cycle at which the scoreboard first stalls an instruction.
2. For a stalled instruction write the words "waiting at clock cycle X," where X is the number of the current clock cycle, in the appropriate table column to show that the scoreboard is resolving an RAW or WAR hazard by stalling that stage. In the Comment column, state what type of hazard and what dependent instruc- tion is causing the wait.
3. Adding the words "completes with clock cycle Y" to a "waiting" table entry, fill in the rest of the table through the time when all instructions are complete. For an instruction that stalled, add a description in the Comments column telling why the wait ended when it did and how deadlock was avoided (Hint: Think about how WAW hazards are prevented and what this implies about active instruction sequences.). Note the completion order of the three instructions as compared to their program order.

   1. [10/10/10] <C.5>For this problem, you will create a series of small snippets that illustrate the issues that arise when using functional units with different latencies. For each one, draw a timing diagram similar to [Figure C.32](#_bookmark519) that illustrates each concept, and clearly indicate the problem.
4. [10] <C.5>Demonstrate, using code different from that used in [Figure C.32](#_bookmark519), the structural hazard of having the hardware for only one MEM and WB stage.
5. [10] <C.5>Demonstrate a WAW hazard requiring a stall.

<!-- -->
