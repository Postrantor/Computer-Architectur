## Historical Perspective and References

Section M.4 (available online) features a discussion on the evolution of instruction sets and includes references for further reading and exploration of related topics.

## Exercises by Gregory D. Peterson

1. [10] <A.9>Compute the effective CPI for an implementation of an embedded RISC-V CPU using Figure A.29. Assume we have made the following measure- ments of average CPI for each of the instruction types:

Average the instruction frequencies of astar and gcc to obtain the instruction mix.

1. [10] <A.9>Compute the effective CPI for RISC-V using Figure A.29 and the table above. Average the instruction frequencies of bzip and hmmer to obtain the instruction mix. You may assume that all other instructions (for instructions not accounted for by the types in Table A.29) require 3.0 clock cycles each.
2. [10] <A.9>Compute the effective CPI for an implementation of a RISC-V CPU using Figure A.29. Assume we have made the following measurements of average CPI for each of the instruction types:

Average the instruction frequencies of gobmk and mcf to obtain the instruction mix. You may assume that all other instructions (for instructions not accounted for by the types in Table A.29) require 3.0 clock cycles each.

1. [10] <A.9>Compute the effective CPI for RISC-V using Figure A.29 and the table above. Average the instruction frequencies of perlbench and sjeng to obtain the instruction mix.
2. [10] <A.8>Consider this high-level code sequence of three statements:

Use the technique of copy propagation (see Figure A.20) to transform the code sequence to the point where no operand is a computed value. Note the instances in which the transformation has reduced the computational work of a statement and those cases where the work has increased. What does this suggest about the technical challenge faced in trying to satisfy the desire for optimizing compilers?

1. [30] <A.8>Compiler optimizations may result in improvements to code size and/or performance. Consider one or more of the benchmark programs from the SPEC CPU2017 or the EEMBC benchmark suites. Use the RISC-V processor or a processor available to you along with the GNU C compiler to optimize the benchmark program(s) using no optimization, –O1, –O2, and –O3. Compare the performance and size of the resulting programs. Also compare your results to Figure A.21.
2. [20/20/20/25/10] <A.2, A.9>Consider the following fragment of C code:

Assume that A and B are arrays of 64-bit integers, and C and i are 64-bit inte- gers. Assume that all data values and their addresses are kept in memory (at addresses 1000, 3000, 5000, and 7000 for A, B, C, and i, respectively) except when they are operated on. Assume that values in registers are lost between iterations of the loop. Assume all addresses and words are 64 bits.

1. [20] <A.2, A.9>Write the code for RISC-V. How many instructions are required dynamically? How many memory-data references will be executed? What is the code size in bytes?
2. [20] <A.2>Write the code for x86. How many instructions are required dynamically? How many memory-data references will be executed? What is the code size in bytes?
3. [20] <A.2>Write the code for a stack machine. Assume all operations occur on top of the stack. Push and pop are the only instructions that access memory; all others remove their operands from the stack and replace them with the result. The implementation uses a hardwired stack for only the top two stack entries, which keeps the processor circuit very small and low in cost. Additional stack positions are kept in memory locations, and accesses to these stack positions require memory references. How many instructions are required dynamically? How many memory-data references will be executed?
4. [25] <A.2, A.9>Instead of the code fragment above, write a routine for computing a matrix multiplication for dense, single precision matrices, also known as SGEMM. For input matrices of size 100 100, how many instruc- tions are required dynamically? How many memory-data references will be executed?
5. [10] <A.2, A.9>As the matrix size increases, how does this affect the number of instructions executed dynamically or the number of memory-data references?
6. [25/25] <A.2, A.8, A.9>Consider the following fragment of C code:

Assume that R, fi, B, Y, U, and V are arrays of 64-bit integers. Assume that all data values and their addresses are kept in memory (at addresses 1000, 2000, 3000, 4000, 5000, and 6000 for R, fi, B, Y, U, and V, respectively) except when they are operated on. Assume that values in registers are lost between iterations of the loop. Assume all addresses and words are 64 bits.

1. [25] <A.2, A.9>Write the code for RISC-V. How many instructions are required dynamically? How many memory-data references will be executed? What is the code size in bytes?
2. [25] <A.2>Write the code for x86. How many instructions are required dynamically? How many memory-data references will be executed? What is the code size in bytes? Compare your results to the multimedia instructions (MMX) and vector implementations discussed in the A.8.
3. [10/10/10/10] <A.2, A.7>For the following, we consider instruction encoding for instruction set architectures.

   1. [10] <A.2, A.7>Consider the case of a processor with an > instruction length of 14 bits and with 64 general-purpose > registers so the size of the address fields is 6 bits. Is it possible to have instruction encodings for the following?

- 3 two-address instructions
- 63 one-address instructions
- 45 zero-address instructions

1. [10] <A.2, A.7>Assuming the same instruction length and address field sizes as above, determine if it is possible to have

   - 3 two-address instructions
   - 65 one-address instructions
   - 35 zero-address instructions Explain your answer.
2. [10] <A.2, A.7>Assume the same instruction length and address field sizes as above. Further assume there are already 3 two-address and 24 zero-address instructions. What is the maximum number of one-address instructions that can be encoded for this processor?
3. [10] <A.2, A.7>Assume the same instruction length and address field sizes as above. Further assume there are already 3 two-address and 65 zero-address instructions. What is the maximum number of one-address instructions that can be encoded for this processor?
4. [10/15] <A.2>For the following assume that integer values A, B, C, D, E, and F reside in memory. Also assume that instruction operation codes are represented in 8 bits, memory addresses are 64 bits, and register addresses are 6 bits.
5. [10] <A.2>For each instruction set architecture shown in Figure A.2, how many addresses, or names, appear in each instruction for the code to compute C=A+B, and what is the total code size?
6. [15] <A.2>Some of the instruction set architectures in Figure A.2 destroy operands in the course of computation. This loss of data values from processor internal storage has performance consequences. For each architecture in Figure A.2, write the code sequence to compute:

In your code, mark each operand that is destroyed during execution and mark each  "overhead"  instruction that is included just to overcome this loss of data from processor internal storage. What is the total code size, the number of bytes of instructions and data moved to or from memory, the number of overhead instruc- tions, and the number of overhead data bytes for each of your code sequences?

1. [15] <A.2, A.7, A.9>The design of RISC-V provides for 32 general-purpose reg- isters and 32 floating-point registers. If registers are good, are more registers better? List and discuss as many trade-offs as you can that should be considered by instruction set architecture designers examining whether to, and how much to, increase the number of RISC-V registers.
2. [5] <A.3>Consider a C struct that includes the following members:

Note that for C, the compiler must keep the elements of the struct in the same order as given in the struct definition. For a 32-bit machine, what is the size of the foo struct? What is the minimum size required for this struct, assuming you may arrange the order of the struct members as you wish? What about for a 64-bit machine?

1. [30] <A.7>Many computer manufacturers now include tools or simulators that allow you to measure the instruction set usage of a user program. Among the methods in use are machine simulation, hardware-supported trapping, and tech- niques that instrument the object code module by inserting counters in software or using built-in hardware counters. Pick a processor and tools to instrument user programs. (The open source RISC-V architecture supports a collection of tools. Tools such as the Performance API (PAPI) work with x86 processors.) Use the processor and tools to measure the instruction set mix for one of the SPEC CPU2017 benchmarks. Compare the results to those shown in this chapter.
2. [30] <A.8>Newer processors such as Intel's i7 Kaby Lake include support for AVX2 vector/multimedia instructions. Write a dense matrix multiply function using single-precision values and compile it with different compilers and optimi- zation flags. Linear algebra codes using Basic Linear Algebra Subroutine (BLAS) routines such as SGEMM include optimized versions of dense matrix multiply. Compare the code size and performance of your code to that of BLAS SGEMM. Explore what happens when using double-precision values and DGEMM.
3. [30] <A.8>For the SGEMM code developed above for the i7 processor, include the use of AVX2 intrinsics to improve the performance. In particular, try to vec- torize your code to better utilize the AVX hardware. Compare the code size and performance to the original code. Compare your results to Intel's Math Kernel Library (MKL) implementation for SGEMM.
4. [30] <A.7, A.9>The RISC-V processor is open source and boasts an impressive collection of implementations, simulators, compilers, and other tools. See [riscv.org](http://riscv.org/) for an overview of tools, including spike, a simulator for RISC-V processors. Use spike or another simulator to measure the instruction set mix for some SPEC CPU2017 benchmark programs.
5. [35/35/35/35] <A.2–A.8>gcc targets most modern instruction set architectures (see [www.gnu.org/software/gcc/](http://www.gnu.org/software/gcc/)). Create a version of gcc for several architectures that you have access to, such as x86, RISC-V, PowerPC, and ARM.
6. [35] <A.2–A.8>Compile a subset of SPEC CPU2017 integer benchmarks and create a table of code sizes. Which architecture is best for each program?
7. [35] <A.2–A.8>Compile a subset of SPEC CPU2017 floating-point benchmarks and create a table of code sizes. Which architecture is best for each program?
8. [35] <A.2–A.8>Compile a subset of EEMBC AutoBench benchmarks (see [www.eembc.org/home.php](http://www.eembc.org/home.php)) and create a table of code sizes. Which architecture is best for each program?
9. [35] <A.2–A.8>Compile a subset of EEMBC FPBench floating-point bench- marks and create a table of code sizes. Which architecture is best for each program?

<!-- -->

1. [40] <A.2–A.8>Power efficiency has become very important for modern proces- sors, particularly for embedded systems. Create a version of gcc for two architec- tures that you have access to, such as x86, RISC-V, PowerPC, Atom, and ARM. (Note that the different versions of RISC-V can also be explored and compared.) Compile a subset of EEMBC benchmarks while using EnergyBench to measure energy usage during execution. Compare code size, performance, and energy usage for the processors. Which is best for each program?
2. [20/15/15/20] Your task is to compare the memory efficiency of four different styles of instruction set architectures. The architecture styles are:

- _Accumulator_—All operations occur between a single register and a memory location.
- _Memory-memory_—All instruction addresses reference only memory locations.
- _Stack_—All operations occur on top of the stack. Push and pop are the only instructions that access memory; all others remove their operands from the stack and replace them with the result. The implementation uses a hardwired stack for only the top two stack entries, which keeps the processor circuit very small and low in cost. Additional stack positions are kept in memory loca- tions, and accesses to these stack positions require memory references.
- _Load-store_—All operations occur in registers, and register-to-register instruc- tions have three register names per instruction. To measure memory efficiency, make the following assumptions about all four instruction sets:
- All instructions are an integral number of bytes in length.
- The opcode is always one byte (8 bits).
- Memory accesses use direct, or absolute, addressing.
- The variables A, B, C, and D are initially in memory.

1. [20] <A.2, A.3>Invent your own assembly language > mnemonics (Figure A.2 provides a useful sample to generalize), > and for each architecture write the best equivalent assembly language code for this high-level language code sequence:
2. [15] <A.3>Label each instance in your assembly codes for part (a) where a value is loaded from memory after having been loaded once. Also label each instance in your code where the result of one instruction is passed to another instruction as an operand, and further classify these events as involving storage within the processor or storage in memory.
3. [15] <A.7>Assume that the given code sequence is from a small, embedded computer application that uses a 16-bit memory address and data operands. If a load-store architecture is used, assume it has 16 general-purpose registers. For each architecture answer the following questions: How many instruction bytes are fetched? How many bytes of data are transferred from/to memory? Which architecture is most efficient as measured by total memory traffic (code+data)?
4. [20] <A.7>Now assume a processor with 64-bit memory addresses and data operands. For each architecture answer the questions of part (c). How have the relative merits of the architectures changed for the chosen metrics?
5. [30] <A.2, A.3>Use the four different instruction set architecture styles from above, but assume that the memory operations supported include register indirect as well as direct addressing. Invent your own assembly language mnemonics (Fig- ure A.2 provides a useful sample to generalize), and for each architecture, write the best equivalent assembly language code for this fragment of C code:

Assume that A and B are arrays of 64-bit integers, and C, D, and i are 64-bit integers.

1. [20/20] <A.3, A.6, A.9>The size of displacement values needed for the displace- ment addressing mode or for PC-relative addressing can be extracted from com- piled applications. Use a disassembler with one or more of the SPEC CPU2017 or EEMBC benchmarks compiled for the RISC-V processor.
2. [20] <A.3, A.9>For each instruction using displacement addressing, record the displacement value used. Create a histogram of displacement values. Com- pare the results to those shown in this appendix in Figure A.8.
3. [20] <A.6, A.9>For each branch instruction using PC-relative addressing, record the offset value used. Create a histogram of offset values. Compare the results to those shown in this chapter in Figure A.15.
4. [15/15/10/10/10/10] <A.3>The value represented by the hexadecimal number 5249 5343 5643 5055 is to be stored in an aligned 64-bit double word.

   1. [15] <A.3>Using the physical arrangement of the first > row in Figure A.5, write the value to be stored using Big > Endian byte order. Next, interpret each byte as an ASCII character and below each byte write the corresponding char- acter, forming the character string as it would be stored in Big Endian order.
5. [15] <A.3>Using the same physical arrangement as in part (a), write the value to be stored using Little Endian byte order, and below each byte write the cor- responding ASCII character.
6. [10] <A.3>What are the hexadecimal values of all misaligned 2-byte words that can be read from the given 64-bit double word when stored in Big Endian byte order?
7. [10] <A.3>What are the hexadecimal values of all misaligned 2-byte words that can be read from the given 64-bit double word when stored in Big Endian byte order?
8. [10] <A.3>What are the hexadecimal values of all misaligned 2-byte words that can be read from the given 64-bit double word when stored in Little Endian byte order?
9. [10] <A.3>What are the hexadecimal values of all misaligned 4-byte words that can be read from the given 64-bit double word when stored in Little Endian byte order?

<!-- -->

1. [25,25] < A.3, A.9>The relative frequency of different addressing modes impacts the choices of addressing modes support for an instruction set architecture. Figure A.7 illustrates the relative frequency of addressing modes for three applications on the VAX.
2. [25] <A.3>Compile one or more programs from the SPEC CPU2017 or EEMBC benchmark suites to target the x86 architecture. Using a disassembler, inspect the instructions and the relative frequency of various addressing modes. Create a histogram to illustrate the relative frequency of the addressing modes. How do your results compare to Figure A.7?
3. [25] <A.3, A.9>Compile one or more programs from the SPEC CPU2017 or EEMBC benchmark suites to target the RISC-V architecture. Using a disassembler, inspect the instructions and the relative frequency of various addressing modes. Create a histogram to illustrate the relative frequency of the addressing modes. How do your results compare to Figure A.7?
4. [Discussion] <A.2–A.12>Consider typical applications for desktop, server, cloud, and embedded computing. How would instruction set architecture be impacted for machines targeting each of these markets?
