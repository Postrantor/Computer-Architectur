## Cross-Cutting Issues

### Hardware Versus Software Speculation

The hardware-intensive approaches to speculation in this chapter and the software approaches of Appendix H provide alternative approaches to exploiting ILP. Some of the trade-offs, and the limitations, for these approaches are listed here:

> 本章中的硬件密集型方法和附录 H 的软件方法提供了利用 ILP 的替代方法。这里列出了这些方法的一些权衡以及限制：

To speculate extensively, we must be able to disambiguate memory references. This capability is difficult to do at compile time for integer programs that contain pointers. In a hardware-based scheme, dynamic runtime disambiguation of memory addresses is done using the techniques we saw earlier for Tomasulo’s algorithm. This disambiguation allows us to move loads past stores at runtime. Support for speculative memory references can help overcome the conservatism of the compiler, but unless such approaches are used carefully, the overhead of the recovery mechanisms may swamp the advantages.

> 为了广泛推测，我们必须能够消除记忆参考。对于包含指针的整数程序，很难在编译时间执行此功能。在基于硬件的方案中，使用我们先前为 Tomasulo 算法看到的技术进行了动态运行时歧义。这种歧义使我们能够在运行时将负载移至存储。对投机记忆参考的支持可以帮助克服编译器的保守主义，但是除非仔细使用这种方法，否则恢复机制的开销可能会淹没优势。

Hardware-based speculation works better when control flow is unpredictable and when hardware-based branch prediction is superior to software-based branch prediction done at compile time. These properties hold for many integer programs, where the misprediction rates for dynamic predictors are usually less than one-half of those for static predictors. Because speculated instructions may slow down the computation when the prediction is incorrect, this difference is significant. One result of this difference is that even statically scheduled processors normally include dynamic branch predictors.

> 当控制流不可预测时，基于硬件的推测效果更好，并且基于硬件的分支预测优于基于软件的分支预测，在编译时进行了分支预测。这些属性适用于许多整数程序，其中动态预测变量的错误预测率通常小于静态预测变量的错误。因为当预测不正确时，推测的指令可能会减慢计算的速度，所以这种差异很大。这种差异的结果是，即使是静态计划的处理器，通常也包括动态分支预测指标。

Hardware-based speculation maintains a completely precise exception model even for speculated instructions. Recent software-based approaches have added special support to allow this as well.

> 基于硬件的投机即使在推测说明中也保持完全精确的异常模型。最近的基于软件的方法增加了特殊的支持以允许这一点。

Hardware-based speculation does not require compensation or bookkeeping code, which is needed by ambitious software speculation mechanisms.

> 基于硬件的投机不需要补偿或簿记代码，这是雄心勃勃的软件投机机制所需的。

Compiler-based approaches may benefit from the ability to see further into the code sequence, resulting in better code scheduling than a purely hardwaredriven approach.

> 基于编译器的方法可能会受益于进一步查看代码顺序的能力，从而使代码调度更好，而不是纯粹的硬件方法。

Hardware-based speculation with dynamic scheduling does not require different code sequences to achieve good performance for different implementations of an architecture. Although this advantage is the hardest to quantify, it may be the most important one in the long run. Interestingly, this was one of the motivations for the IBM 360/91. On the other hand, more recent explicitly parallel architectures, such as IA-64, have added flexibility that reduces the hardware dependence inherent in a code sequence.

> 具有动态调度的基于硬件的投机不需要不同的代码序列来实现架构的不同实现的良好性能。尽管此优势最难量化，但从长远来看可能是最重要的优势。有趣的是，这是 IBM 360/91 的动机之一。另一方面，诸如 IA-64 之类的最新显式并行体系结构增加了灵活性，从而减少了代码序列中固有的硬件依赖性。

The major disadvantage of supporting speculation in hardware is the complexity and additional hardware resources required. This hardware cost must be evaluated against both the complexity of a compiler for a software-based approach and the amount and usefulness of the simplifications in a processor that relies on such a compiler.

> 支持硬件中投机的主要缺点是所需的复杂性和其他硬件资源。必须针对基于软件的方法的编译器的复杂性以及依赖于这种编译器的处理器中简化的数量和实用性来评估此硬件成本。

Some designers have tried to combine the dynamic and compiler-based approaches to achieve the best of each. Such a combination can generate interesting and obscure interactions. For example, if conditional moves are combined with register renaming, a subtle side effect appears. A conditional move that is annulled must still copy a value to the destination register because it was renamed earlier in the instruction pipeline. These subtle interactions complicate the design and verification process and can also reduce performance.

> 一些设计师试图将基于动态和编译器的方法结合在一起，以实现每种方法的最佳状态。这样的组合可以产生有趣而晦涩的互动。例如，如果将条件移动与寄存器重命名合并，则会出现微妙的副作用。被废除的有条件移动仍然必须将值复制到目标寄存器，因为它在指令管道中较早地重命名。这些微妙的互动使设计和验证过程变得复杂，还可以降低性能。

The Intel Itanium processor was the most ambitious computer ever designed based on the software support for ILP and speculation. It did not deliver on the hopes of the designers, especially for general-purpose, nonscientific code. As designers’ ambitions for exploiting ILP were reduced in light of the difficulties described on page 244, most architectures settled on hardware-based mechanisms with issue rates of three to four instructions per clock.

> Intel Itanium 处理器是有史以来最雄心勃勃的计算机，该计算机基于 ILP 和投机的软件支持。它没有为设计师的希望提供，特别是对于通用，非科学代码。根据设计师对 ILP 的利用野心，根据第 244 页所述的困难，大多数体系结构都定居在基于硬件的机制上，其发行速率为每个时钟三到四个说明。

### Speculative Execution and the Memory System

Inherent in processors that support speculative execution or conditional instructions is the possibility of generating invalid addresses that would not occur without speculative execution. Not only would this be incorrect behavior if protection exceptions were taken, but also the benefits of speculative execution would be swamped by false exception overhead. Therefore the memory system must identify speculatively executed instructions and conditionally executed instructions and suppress the corresponding exception.

> 支持投机执行或条件指令的处理器固有的是生成无需投机执行不会发生的无效地址的可能性。如果采取保护例外，这不仅是不正确的行为，而且投机执行的好处将被虚假的例外开销所淹没。因此，内存系统必须识别投机执行的指令和有条件执行的指令，并抑制相应的异常。

By similar reasoning, we cannot allow such instructions to cause the cache to stall on a miss because, again, unnecessary stalls could overwhelm the benefits of speculation. Thus these processors must be matched with nonblocking caches.

> 通过类似的推理，我们不能允许此类说明导致缓存失速，因为再次，不必要的摊位可能会压倒投机的好处。因此，这些处理器必须与非封锁缓存匹配。

In reality, the penalty of a miss that goes to DRAM is so large that speculated misses are handled only when the next level is on-chip cache (L2 or L3). Figure 2.5 on page 84 shows that for some well-behaved scientific programs, the compiler can sustain multiple outstanding L2 misses to cut the L2 miss penalty effectively. Once again, for this to work, the memory system behind the cache must match the goals of the compiler in number of simultaneous memory accesses.

> 实际上，对 DRAM 的失误的惩罚是如此之大，以至于只有在下一个级别的芯片缓存(L2 或 L3)时才能进行猜测的错过。第 84 页的图 2.5 显示，对于某些行为良好的科学计划，编译器可以维持多个出色的 L2 失误，以有效地削减 L2 失误。再一次，为此，缓存背后的内存系统必须在同时内存访问的数量中匹配编译器的目标。

Figure 3.29 An example of six instructions to be issued in the same clock cycle and what has to happen. The instructions are shown in program order: 1–6; they are, however, issued in 1 clock cycle! The notation pi is used to refer to a physical register; the contents of that register at any point is determined by the renaming map. For simplicity, we assume that the physical registers holding the architectural registers x1, x2, and x3 are initially p1, p2, and p3 (they could be any physical register). The instructions are issued with physical register numbers, as shown in column four. The rename map, which appears in the last column, shows how the map would change if the instructions were issued sequentially. The difficulty is that all this renaming and replacement of architectural registers by physical renaming registers happens effectively in 1 cycle, not sequentially. The issue logic must find all the dependences and  "rewrite"  the instruction in parallel.

> 图 3.29 在同一时钟周期中发出的六个指令以及必须发生的事情。说明以程序顺序显示：1-6；但是，它们是在 1 个时钟周期中发出的！符号 PI 用于参考物理寄存器；该寄存器的内容在任何时候都由重命名地图确定。为简单起见，我们假设持有建筑寄存器 X1，X2 和 X3 的物理寄存器最初是 P1，P2 和 P3(它们可以是任何物理寄存器)。指令以物理寄存器编号发布，如第四列所示。重命名映射出现在最后一列中，显示了如果依次发布指令，则映射将如何更改。困难在于，通过物理重命名寄存器对建筑登记簿的所有重命名和替换都有效地发生在 1 周期中，而不是顺序地发生。问题逻辑必须找到所有依赖关系，并并行 "重写" 指令。
>
>>

##### _How Much to Speculate_

One of the significant advantages of speculation is its ability to uncover events that would otherwise stall the pipeline early, such as cache misses. This potential advantage, however, comes with a significant potential disadvantage. Speculation is not free. It takes time and energy, and the recovery of incorrect speculation further reduces performance. In addition, to support the higher instruction execution rate needed to benefit from speculation, the processor must have additional resources, which take silicon area and power. Finally, if speculation causes an exceptional event to occur, such as a cache or translation lookaside buffer (TLB) miss, the potential for significant performance loss increases, if that event would not have occurred without speculation.

> 猜测的重要优势之一是它有能力揭示事件，否则可以尽早停止管道，例如高速缓存。但是，这种潜在的优势带有明显的潜在劣势。猜测不是免费的。它需要时间和精力，而不正确的投机恢复进一步降低了性能。此外，为了支持从投机中受益所需的更高的指令执行率，处理器必须具有额外的资源，这些资源需要硅区域和权力。最后，如果推测会导致出色的事件发生，例如缓存或翻译 lookAside 缓冲液(TLB)失误，则如果不推测就不会发生该事件，则可能会增加绩效损失的可能性。

To maintain most of the advantage while minimizing the disadvantages, most pipelines with speculation will allow only low-cost exceptional events (such as a first-level cache miss) to be handled in speculative mode. If an expensive exceptional event occurs, such as a second-level cache miss or a TLB miss, the processor will wait until the instruction causing the event is no longer speculative before handling the event. Although this may slightly degrade the performance of some programs, it avoids significant performance losses in others, especially those that suffer from a high frequency of such events coupled with less-than-excellent branch prediction.

> 为了在最小化缺点的同时保持大部分优势，大多数具有猜测的管道将只允许以投机模式处理低成本的异常事件(例如第一级缓存失误)。如果发生昂贵的特殊事件，例如二级缓存失误或 TLB 失误，则处理器将等到导致事件的指令不再投机，然后才能处理事件。尽管这可能会稍微降低某些程序的性能，但它避免了其他程序的重大绩效损失，尤其是那些遭受高频率此类事件的损失以及不太偏见的分支预测。

In the 1990s the potential downsides of speculation were less obvious. As processors have evolved, the real costs of speculation have become more apparent, and the limitations of wider issue and speculation have been obvious. We return to this issue shortly.

> 在 1990 年代，投机的潜在弊端不太明显。随着处理器的发展，猜测的实际成本变得越来越明显，更广泛的问题和猜测的局限性也很明显。我们很快就回到了这个问题。

##### _Speculating Through Multiple Branches_

In the examples we have considered in this chapter, it has been possible to resolve a branch before having to speculate on another. Three different situations can benefit from speculating on multiple branches simultaneously: (1) a very high branch frequency, (2) significant clustering of branches, and (3) long delays in functional units. In the first two cases, achieving high performance may mean that multiple branches are speculated, and it may even mean handling more than one branch per clock. Database programs and other less structured integer computations, often exhibit these properties, making speculation on multiple branches important. Likewise, long delays in functional units can raise the importance of speculating on multiple branches as a way to avoid stalls from the longer pipeline delays.

> 在我们在本章中考虑的示例中，在不得不推测另一个分支之前，可以解决一个分支。三种不同的情况可以通过同时推测多个分支的猜测受益：(1)非常高的分支频率，(2)分支的显着聚类，以及(3)功能单位中的长延迟。在前两种情况下，实现高性能可能意味着要猜测多个分支，甚至可能意味着每个时钟处理多个分支。数据库程序和其他结构较低的整数计算经常表现出这些属性，从而对多个分支的猜测很重要。同样，功能单元中的长时间延迟可以提高在多个分支上投机的重要性，以避免较长管道延迟的失速。

Speculating on multiple branches slightly complicates the process of speculation recovery but is straightforward otherwise. As of 2017, no processor has yet combined full speculation with resolving multiple branches per cycle, and it is unlikely that the costs of doing so would be justified in terms of performance versus complexity and power.

> 在多个分支上推测略微使投机恢复过程变得复杂，但否则很简单。截至 2017 年，尚无处理器将充分的猜测与每个周期的多个分支结合在一起，因此，这样做的成本不可能是合理的，从性能与复杂性和功率方面则是合理的。

##### _Speculation and the Challenge of Energy Efficiency_

What is the impact of speculation on energy efficiency? At first glance, one might argue that using speculation always decreases energy efficiency because whenever speculation is wrong, it consumes excess energy in two ways:

> 投机对能源效率有什么影响？乍一看，人们可能会争辩说，使用猜测总是会降低能源效率，因为只要投机是错误的，它就会以两种方式消耗多余的能量：

1. Instructions that are speculated and whose results are not needed generate excess work for the processor, wasting energy.
2. Undoing the speculation and restoring the state of the processor to continue execution at the appropriate address consumes additional energy that would not be needed without speculation.

> 1. 推测且不需要其结果的说明为处理器产生过多的工作，从而浪费能量。
> 2. 取消猜测并恢复处理器的状态以继续在适当地址执行的情况下会消耗额外的能量，而没有投机就不需要。

Certainly, speculation will raise the power consumption, and if we could control speculation, it would be possible to measure the cost (or at least the dynamic power cost). But, if speculation lowers the execution time by more than it increases the average power consumption, then the total energy consumed may be less.

> 当然，猜测将提高功耗，如果我们能够控制猜测，则可以衡量成本(或至少动态功率成本)。但是，如果推测将执行时间降低超过增加平均功耗，那么所消耗的总能量可能会更少。

Thus, to understand the impact of speculation on energy efficiency, we need to look at how often speculation is leading to unnecessary work. If a significant number of unneeded instructions is executed, it is unlikely that speculation will improve running time by a comparable amount. [Figure 3.30](#_bookmark133) shows the fraction of instructions that are executed from misspeculation for a subset of the SPEC2000 benchmarks using a sophisticated branch predictor. As we can see, this fraction of executed misspeculated instructions is small in scientific code and significant (about 30% on average) in integer code. Thus it is unlikely that speculation is energy-efficient for integer applications, and the end of Dennard scaling makes imperfect speculation more problematic. Designers could avoid speculation, try to reduce the misspeculation, or think about new approaches, such as only speculating on branches that are known to be highly predictable.

> 因此，要了解投机对能源效率的影响，我们需要研究投机的频率导致不必要的工作。如果执行了大量的不需要说明，则猜测不太可能将运行时间提高到可比的数量。[图 3.30](#_bookmark133) 显示了使用复杂的分支预测指标从拼配中执行的指令的比例。如我们所见，这一小部分执行的拼写错误指令在科学代码中很小，整数代码中的显着(平均约为 30％)。因此，投机对于整数应用不可能有能力，而丹纳德缩放的终结使人们的猜测更加有问题。设计师可以避免猜测，尝试减少拼写错误或思考新方法，例如仅在已知的高度可预测的分支上推测。

Figure 3.30 The fraction of instructions that are executed as a result of misspeculation is typically much higher for integer programs (the first five) versus FP programs (the last five).

> 图 3.30 整数程序(前五个)与 FP 程序(最后五个)相比，由于拼写错误而执行的指令的比例通常要高得多。

##### _Address Aliasing Prediction_

_Address aliasing prediction_ is a technique that predicts whether two stores or a load and a store refer to the same memory address. If two such references do not refer to the same address, then they may be safely interchanged. Otherwise, we must wait until the memory addresses accessed by the instructions are known. Because we need not actually predict the address values, only whether such values conflict, the prediction can be reasonably accurate with small predictors. Address prediction relies on the ability of a speculative processor to recover after a misprediction; that is, if the actual addresses that were predicted to be different (and thus not alias) turn out to be the same (and thus are aliases), the processor simply restarts the sequence, just as though it had mispredicted a branch. Address value speculation has been used in several processors already and may become universal in the future.

> *address 别名预测*是一种预测是否两个存储或负载和存储的技术，请参阅相同的内存地址。如果两个这样的引用不参考相同的地址，则可以安全地互换。否则，我们必须等到已知指令访问的内存地址。因为我们实际上不需要实际预测地址值，所以只有这种值是否需要冲突，因此预测可以合理地准确地使用小型预测变量。地址预测取决于投机处理器在错误预测后恢复的能力；也就是说，如果预测的实际地址是不同的(因此不是别名)是相同的(因此是别名)，那么处理器只是重新启动序列，就好像它已经错误地预测了分支。地址价值推测已经在几个处理器中使用，并且将来可能会变得普遍。

Address prediction is a simple and restricted form of _value prediction,_ which attempts to predict the value that will be produced by an instruction. Value prediction could, if it were highly accurate, eliminate data flow restrictions and achieve higher rates of ILP. Despite many researchers focusing on value prediction in the past 15 years in dozens of papers, the results have never been sufficiently attractive to justify general value prediction in real processors.

> 地址预测是*value 预测的一种简单且受限的形式，*试图预测指令将产生的值。如果高度准确，可以消除数据流限制并获得更高的 ILP 速率。尽管许多研究人员在过去的 15 年中专注于价值预测，但结果从来没有足够吸引力，可以证明实际处理器中的一般价值预测是合理的。
