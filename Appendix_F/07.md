## Practical Issues for Commercial Interconnection Networks

> ##商业互连网络的实用问题

There are practical issues in addition to the technical issues described thus far that are important considerations for interconnection networks within certain domains. We mention a few of these below.

> 除了迄今为止所描述的技术问题外，还有一些实际问题，是某些域内互连网络的重要考虑因素。我们在下面提到其中一些。

### Connectivity

> ###连接

The type and number of devices that communicate and their communication require- ments affect the complexity of the interconnection network and its protocols. The protocols must target the largest network size and handle the types of anomalous systemwide events that might occur. Among some of the issues are the following: How lightweight should the network interface hardware/software be? Should it attach to the memory network or the I/O network? Should it support cache coher- ence? If the operating system must get involved for every network transaction, the sending and receiving overhead becomes quite large. If the network interface attaches to the I/O network (PCI-Express or HyperTransport interconnect), the injection and reception bandwidth will be limited to that of the I/O network. This is the case for the Cray XT3 SeaStar, Intel Thunder Tiger 4 QsNet<sup>II</sup>, and many other supercomputer and cluster networks. To support coherence, the sender may have to flush the cache before each send, and the receiver may have to flush its cache before each receive to prevent the stale-data problem. Such flushes further increase sending and receiving overhead, often causing the network interface to be the network bottleneck.

> 通信及其通信要求的设备的类型和数量会影响互连网络及其协议的复杂性。协议必须针对最大的网络大小，并处理可能发生的异常事件的类型。其中包括以下问题：网络接口硬件/软件应如何轻巧？它应该连接到内存网络还是 I/O 网络？它应该支持缓存相干吗？如果操作系统必须参与每个网络交易，则发送和接收开销将变得很大。如果网络接口连接到 I/O 网络(PCI-Express 或 HyperTransport InterConnect)，则注入和接收带宽将仅限于 I/O 网络的带宽。Cray XT3 Seastar，Intel Thunder Tiger 4 QSNET <SUP> II </sup>以及许多其他 SuperComputer 和 cluster 网络就是这种情况。为了支持连贯性，发件人可能必须在每次发送之前冲洗缓存，并且接收器可能必须在每次接收之前冲洗其缓存，以防止陈旧数据。这种冲洗进一步增加了发送和接收开销，通常会导致网络接口成为网络瓶颈。

Computer systems typically have a multiplicity of interconnects with different functions and cost-performance objectives. For example, processor-memory inter- connects usually provide higher bandwidth and lower latency than I/O interconnects and are more likely to support cache coherence, but they are less likely to follow or become standards. Personal computers typically have a processormemory intercon- nect and an I/O interconnect (e.g., PCI-X 2.0, PCIe or Hyper-Transport) designed to connect both fast and slow devices (e.g., USB 2.0, Gigabit Ethernet LAN, Firewire 800). The Blue Gene/L supercomputer uses five interconnection networks, only one of which is the 3D torus used for most of the interprocessor application traffic. The others include a tree-based collective communication network for broadcast and multicast; a tree-based barrier network for combining results (scatter, gather); a control network for diagnostics, debugging, and initialization; and a Gigabit Ethernet networkfor I/Obetweenthenodesanddisk. The Universityof Texasat Austin’s TRIPS Edge processor has eight specialized on-chip networks—some with bidirectional channels as wide as 128 bits and some with 168 bits in each direction—to interconnect the 106 heterogeneous tiles composing the two processor cores with L2 on-chip cache. It also has a chip-to-chip switched network to interconnect multiple chips in a multi- processor configuration. Two of the on-chip networks are switched networks: One is used for operand transport and the other is used for on-chip memory communication. The others are essentially fan-out trees or recombination dedicated link networks used for status and control. The portion of chip area allocated to the interconnect is substantial, with five of the seven metal layers used for global network wiring.

> 计算机系统通常具有与不同功能和成本绩效目标的多种互连。例如，处理器内存之间的连接通常比 I/O 互连提供更高的带宽和更低的延迟，并且更有可能支持高速缓存相干性，但是它们不太可能遵循或成为标准标准。个人计算机通常具有 ProcessorMory 互连和 I/O 互连(例如 PCI-X 2.0，PCIE 或 Hyper-Transport)，旨在连接快速和慢速设备(例如 USB 2.0，Gigabit Ethernet LAN，FireWire 800)。蓝色基因/L 超级计算机使用五个互连网络，其中只有一个是用于大多数 Instrapsorsor 应用程序流量的 3D 圆环。其他包括基于树的集体通信网络，用于广播和多播；基于树的屏障网络，用于结合结果(散射，收集)；用于诊断，调试和初始化的控制网络；以及一个千兆以太网网络 I/Obetweenthenodesanddisk。Texasat Austin 的 Trips Edge 处理器大学具有八个专业的片网络，有些具有双向频道，宽至 128 位，每个方向有 168 位，将 106 个异质瓷砖与 L2 芯片式缓存组成的 106 个异质瓷砖互连。它还具有一个芯片到芯片开关网络，可在多处理器配置中互连多个芯片。片上的两个网络是切换网络：一个用于操作数，另一个用于运输网络，用于芯片内存通信。其他实质上是扇形树或用于状态和控制的专用链接网络。分配给互连的芯片区域的部分是实质性的，其中七个金属层中有五个用于全球网络接线。

### Standardization: Cross-Company Interoperability

> ###标准化：跨公司互操作性

Standards are useful in many places in computer design, including interconnection networks. Advantages of successful standards include low cost and stability.

> 标准在计算机设计的许多地方都有用，包括互连网络。成功标准的优势包括低成本和稳定性。

The customer has many vendors to choose from, which keeps price close to cost due to competition. It makes the viability of the interconnection independent of the stability of a single company. Components designed for a standard interconnection may also have a larger market, and this higher volume can reduce the vendors’ costs, further benefiting the customer. Finally, a standard allows many companies to build products with interfaces to the standard, so the customer does not have to wait for a single company to develop interfaces to all the products of interest.

> 客户有许多供应商可供选择，这可以使价格保持在竞争中的成本。它使互连的生存能力独立于单个公司的稳定性。为标准互连设计的组件也可能具有更大的市场，并且该较高的量可以降低供应商的成本，从而进一步使客户受益。最后，标准允许许多公司构建具有标准界面的产品，因此客户不必等待单个公司就可以为所有感兴趣的产品开发接口。

One drawback of standards is the time it takes for committees and special- interest groups to agree on the definition of standards, which is a problem when technology is changing rapidly. Another problem is _when_ to standardize: On the one hand, designers would like to have a standard before anything is built; on the other hand, it would be better if something were built before standardization to avoid legislating useless features or omitting important ones. When done too early, it is often done entirely by committee, which is like asking all of the chefs in France to prepare a single dish of food—masterpieces are rarely served. Stan- dards can also suppress innovation at that level, since standards fix the interfaces— at least until the next version of the standards surface, which can be every few years or longer. More often, we are seeing consortiums of companies getting together to define and agree on technology that serve as “_de facto_” industry standards. This was the case for InfiniBand.

> 标准的一个缺点是委员会和特殊利益集团就标准的定义达成共识所需的时间，这是技术迅速变化时的问题。另一个问题是_when_标准化：一方面，设计师希望在建立任何东西之前先拥有标准；另一方面，如果在标准化之前构建的东西以避免立法无用的功能或省略重要功能，那就更好了。太早完成后，通常完全由委员会完成，这就像要求法国的所有厨师准备一道食物一样，很少提供杂物。由于标准修复了界面，因此标准还可以在该级别上抑制创新，至少直到标准表面的下一个版本为止，这可能是每隔几年或更长时间。我们经常看到公司的财团聚集在一起，以定义并同意作为“ _de facto_”行业标准的技术。Infiniband 就是这种情况。

LANs and WANs use standards and interoperate effectively. WANs involve many types of companies and must connect to many brands of computers, so it is difficult to imagine a proprietary WAN ever being successful. The ubiquitous nature of the Ethernet shows the popularity of standards for LANs as well as WANs, and it seems unlikely that many customers would tie the viability of their LAN to the stability of a single company. Some SANs are standardized such as Fibre Channel, but most are proprietary. OCNs for the most part are proprietary designs, with a few gaining widespread commercial use in system-on-chip (SoC) applications, such as IBM’s CoreConnect and ARM’s AMBA.

> LAN 和 WANS 使用标准并有效地进行互操作。WAN 涉及多种类型的公司，必须与许多品牌的计算机联系，因此很难想象专有的 WAN 曾经成功。以太网的无处不在的性质显示了 LAN 和 WANS 标准的普及，而且似乎许多客户不太可能将其 LAN 的可行性与单个公司的稳定性联系起来。有些 SAN 是标准化的，例如纤维通道，但大多数是专有的。OCN 在大多数情况下是专有的设计，在 System-Chip(SOC)应用中，例如 IBM 的 CoreConnect 和 Arm 的 Amba，都可以广泛获得商业用途。

### Congestion Management

> ###拥堵管理

Congestion arises when too many packets try to use the same link or set of links. This leads to a situation in which the bandwidth required exceeds the bandwidth supplied. Congestion by itself does not degrade network performance: simply, the congested links are running at their maximum capacity. Performance degradation occurs in the presence of HOL blocking where, as a consequence of packets going to noncongested destinations getting blocked by packets going to congested des- tinations, some link bandwidth is wasted and network throughput drops, as illus- trated in the example given at the end of [Section F.4](#network-topology). _Congestion control_ refers to schemes that reduce traffic when the collective traffic of all nodes is too large for the network to handle.

> 当太多的数据包尝试使用相同的链接或一组链接时，就会出现拥堵。这导致了所需带宽超过所提供带宽的情况。拥堵本身不会降低网络性能：简单地，拥挤的链接以其最大能力运行。性能降解发生在 hol 阻塞的存在下，由于数据包进入了不昂贵的目的地，因此被包含在拥挤的数据的数据包被阻止的结果，浪费了一些链接带宽，网络吞吐量下降，如在示例中给出的插图，[F.4 节]的末尾(＃网络 - 流行病)。_congestion Control _是指在所有节点的集体流量太大以至于无法处理网络时减少流量的方案。

One advantage of a circuit-switched network is that, once a circuit is estab- lished, it ensures that there is sufficient bandwidth to deliver all the information sent along that circuit. Interconnection bandwidth is reserved as circuits are estab- lished, and if the network is full, no more circuits can be established. Other switch- ing techniques generally do not reserve interconnect bandwidth in advance, so the interconnection network can become clogged with too many packets. Just as with poor rush-hour commuters, a traffic jam of packets increases packet latency and, in extreme cases, fewer packets per second get delivered by the interconnect. In order to handle congestion in packet-switched networks, some form of _congestion man- agement_ must be implemented. The two kinds of mechanisms used are those that control congestion and those that eliminate the performance degradation intro- duced by congestion.

> 电路开关网络的一个优点是，一旦构建了电路，它将确保有足够的带宽来传递沿该电路发送的所有信息。互连带宽将保留，因为电路是估计的，如果网络已满，则无法建立更多的电路。其他开关技术通常不会提前保留互连带宽，因此互连网络可能会被太多数据包堵塞。就像高速公路通勤者一样，数据包的交通堵塞也会增加包数据包的延迟，在极端情况下，互连可提供的每秒较少的数据包。为了处理数据包切换网络中的拥堵，必须实施某种形式的_congestion mangement_。所使用的两种机制是控制充血的机制，以及那些消除了充血引起的性能降解引入的机制。

There are three basic schemes used for congestion control in interconnection networks, each with its own weaknesses: packet discarding, flow control, and choke packets. The simplest scheme is _packet discarding_, which we discussed briefly in [Section F.2](#interconnecting-two-devices). If a packet arrives at a switch and there is no room in the buffer, the packet is discarded. This scheme relies on higher-level software that handles errors in transmission to resend lost packets. This leads to significant band- width wastage due to (re)transmitted packets that are later discarded and, therefore, is typically used only in lossy networks like the Internet.

> 互连网络中有三种基本方案用于拥堵控制，每个方案都有其自身的弱点：丢弃数据包，流量控制和 choke 数据包。最简单的方案是_packet dustrand_，我们在[f.2]节(＃互连-two-two-evices)中进行了简要讨论。如果数据包到达开关，缓冲区中没有空间，则数据包被丢弃。该方案依靠高级软件，该软件处理传输中的错误以重新发送丢失的数据包。这导致(重新)传输数据包，这会导致巨大的带宽浪费，这些数据包被丢弃，因此通常仅在诸如 Internet 之类的损失网络中使用。

The second scheme relies on _flow control_, also discussed previously. When buffers become full, link-level flow control provides feedback that prevents the transmission of additional packets. This _backpressure_ feedback rapidly propagates backward until it reaches the sender(s) of the packets producing congestion, forcing a reduction in the injection rate of packets into the network. The main draw- backs of this scheme are that sources become aware of congestion too late when the network is already congested, and nothing is done to alleviate congestion. Back- pressure flow control is common in lossless networks like SANs used in supercom- puters and enterprise systems.

> 第二个方案依赖于_Flow Control_，这也是之前讨论的。当缓冲区变得完整时，链接级流量控制提供了防止其他数据包传输的反馈。此_backPressure_反馈迅速向后传播，直到到达产生拥塞的数据包的发件人，迫使数据包注入率降低到网络中。该计划的主要吸引力是，当网络已经交通拥堵时，消息来源意识到拥塞太晚了，没有采取任何措施来减轻拥堵。后压力流控制在无损网络中很常见，例如超级委托人和企业系统中使用的 SAN。

A more elaborate way of using flow control is by implementing it directly between the sender and the receiver end nodes, generically called _end-to-end flow control_. _Windowing_ is one version of end-to-end credit-based flow control where the window size should be large enough to efficiently pipeline packets through the network. The goal of the window is to limit the number of unacknowledged packets, thus bounding the contribution of each source to congestion, should it arise. The TCP protocol uses a sliding window. Note that end-to-end flow control describes the interaction between just two nodes of the interconnection network, not the entire interconnection network between all end nodes. Hence, flow control helps congestion control, but it is not a global solution.

> 使用流量控制的一种更详细的方法是直接在发件人和接收器端节点之间实现，该节点通常称为_端到端端流控制_。_windowing_是基于端到端信用的流量控制的一种版本，其中窗口大小应足够大，可以通过网络有效地管道数据包。窗口的目的是限制未经确认的数据包的数量，从而限制每个来源对拥塞的贡献。TCP 协议使用滑动窗口。请注意，端到端流量控制描述了互连网络的两个节点之间的相互作用，而不是所有末端节点之间的整个互连网络。因此，流控制有助于拥堵控制，但这不是全球解决方案。

_Choke packets_ are used in the third scheme, which is built upon the premise that traffic injection should be throttled only when congestion exists across the net- work. The idea is for each switch to see how busy it is and to enter into a warning state when it passes a threshold. Each packet received by a switch in the warning state is sent back to the source via a choke packet that includes the intended des- tination. The source is expected to reduce traffic to that destination by a fixed per- centage. Since it likely will have already sent other packets along that path, the source node waits for all the packets in transit to be returned before acting on the choke packets. In this scheme, congestion is controlled by reducing the packet injection rate until traffic reduces, just as metering lights that guard on-ramps con- trol the rate of cars entering a freeway. This scheme works efficiently when the feedback delay is short. When congestion notification takes a long time, usually due to long time of flight, this congestion control scheme may become unsta- ble—reacting too slowly or producing oscillations in packet injection rate, both of which lead to poor network bandwidth utilization.

> _ Choke 数据包用于第三个方案中，该方案是基于前提，即只有在整个网络中存在拥塞时才能进行交通注入。这个想法是针对每个开关来查看它的繁忙，并在通过阈值时进入警告状态。警告状态下的开关接收到的每个数据包都通过包括预期限制的扼流包发送回源。预计该来源将减少到该目的地的流量固定百分比。由于它可能已经沿该路径发送了其他数据包，因此源节点会等待在 Choke 数据包上作用之前要返回的所有传输中的所有数据包。在此计划中，拥塞是通过降低数据包注入速率直到交通降低的控制量来控制的，就像衡量灯在电脑上固定撞机的灯一样，控制了进入高速公路的汽车速度。当反馈延迟短时，该方案有效地工作。当交通拥堵通知需要很长时间(通常是由于长时间的飞行)时，这种拥塞控制方案可能会变得不稳定 - 反应得太慢或产生了数据包注入率的振荡，这两者都导致网络带宽利用率较差。

An alternative to congestion control consists of eliminating the negative consequences of congestion. This can be done by eliminating HOL blocking at every switch in the network as discussed previously. Virtual output queues can be used for this purpose; however, it would be necessary to implement as many queues at every switch input port as devices attached to the network. This solution is very expensive, and not scalable at all. Fortunately, it is possible to achieve good results by dynamically assigning a few set-aside queues to store only the congested packets that travel through some hot-spot regions of the network, very much like caches are intended to store only the more frequently accessed memory locations. This strategy is referred to as _regional explicit congestion notification_ (RECN).

> 拥塞控制的一种替代方法是消除拥塞的负面后果。如前所述，可以通过消除网络中每个开关的 HOL 阻止来完成。虚拟输出队列可用于此目的；但是，有必要在每个交换机输入端口上与网络上的设备实现尽可能多的队列。该解决方案非常昂贵，根本不可扩展。幸运的是，可以通过动态分配几个固定的队列来仅存储通过网络的某些热点区域传播的拥挤数据包来实现良好的结果，就像 Caches 旨在仅存储更频繁的访问的内存位置。该策略称为_区域显式拥塞 Notification_(RECN)。

### Fault Tolerance

> ###容错

The probability of system failures increases as transistor integration density and the number of devices in the system increases. Consequently, system reliability and availability have become major concerns and will be even more important in future systems with the proliferation of interconnected devices. A practical issue arises, therefore, as to whether or not the interconnection network relies on all the devices being operational in order for the network to work properly. Since software failures are generally much more frequent than hardware failures, another question sur- faces as to whether a software crash on a single device can prevent the rest of the devices from communicating. Although some hardware designers try to build fault-free networks, in practice, it is only a question of the rate of failures, not whether they can be prevented. Thus, the communication subsystem must have mechanisms for dealing with faults when—not if—they occur.

> 系统故障的概率随着晶体管积分密度和系统中的设备数量的增加而增加。因此，系统的可靠性和可用性已成为主要问题，并且随着互连设备的扩散，将在未来的系统中变得更加重要。因此，出现了一个实际问题，即互连网络是否依赖于所有正在运行的设备，以使网络正常工作。由于软件故障通常比硬件故障要频繁得多，因此另一个问题表明，在单个设备上崩溃是否可以防止其余设备崩溃。尽管一些硬件设计人员试图构建无故障网络，但实际上，这只是一个失败率的问题，而不是可以防止失败的问题。因此，沟通子系统必须具有处理故障的机制，当时它们发生了。

There are two main kinds of failure in an interconnection network: _transient_ and _permanent_. Transient failures are usually produced by electromagnetic inter- ference and can be detected and corrected using the techniques described in [Section F.2](#interconnecting-two-devices). Oftentimes, these can be dealt with simply by retransmitting the packet either at the link level or end-to-end. Permanent failures occur when some component stops working within specifications. Typically, these are produced by overheating, overbiasing, overuse, aging, and so on and cannot be recovered from simply by retransmitting packets with the help of some higher-layer software pro- tocol. Either an alternative physical path must exist in the network and be supplied by the routing algorithm to circumvent the fault or the network will be crippled, unable to deliver packets whose only paths are through faulty resources.

> 互连网络中有两种主要故障：_transient_和_permanent_。瞬态失败通常是通过电磁间相互作用产生的，可以使用[f.2](＃互连两个 devices)中描述的技术检测和校正。通常，可以简单地通过在链接级别或端到端重新传输数据包来处理这些问题。当某些组件停止在规格中工作时，会发生永久失败。通常，这些是通过过热，过度使用，过度使用，衰老等产生的，并且无法通过在一些更高层的软件支持的帮助下通过重新汇总数据包来恢复。要么在网络中存在替代物理路径，要么由路由算法提供以绕过故障的路由算法，或者网络将被削弱，无法传递唯一路径是通过错误资源的数据包。

Three major categories of techniques are used to deal with permanent failures:

> 使用三个主要类别的技术来处理永久失败：

_resource sparing, fault-tolerant routing_, and _network reconfiguration_. In the first technique, faulty resources are switched off or bypassed, and some spare resources are switched in to replace the faulty ones. As an example, the ServerNet intercon- nection network is designed with two identical switch fabrics, only one of which is usable at any given time. In case of failure in one fabric, the other is used. This technique can also be implemented without switching in spare resources, leading to a degraded mode of operation after a failure. The IBM Blue Gene/L supercom- puter, for instance, has the facility to bypass failed network resources while retain- ing its base topological structure and routing algorithm. The main drawback of this technique is the relatively large number of healthy resources (e.g., midplane node boards) that may need to be switched off after a failure in order to retain the base topological structure (e.g., a 3D torus).

> _resource 抛光，容忍故障的路由_和_network reconfiguration_。在第一个技术中，有缺陷的资源被关闭或绕过，并切换了一些备用资源以替换有故障的资源。例如，Servernet 互连网络设计使用两个相同的开关织物，其中仅在任何给定时间可用。如果一种织物失败，则使用另一种织物。该技术也可以在不转换备用资源的情况下实现，从而导致故障后的操作模式退化。例如，IBM Blue Gene/L SuperCom-Puter 具有绕过网络资源失败的设施，同时保留其基本拓扑结构和路由算法。该技术的主要缺点是相对较大的健康资源(例如，平面节点板)，可能需要在未能保留基础拓扑结构(例如 3D 圆圈)后关闭。

Fault-tolerant routing, on the other hand, takes advantage of the multiple paths already existing in the network topology to route messages in the presence of fail- ures without requiring spare resources. Alternative paths for each supported fault combination are identified at design time and incorporated into the routing algo- rithm. When a fault is detected, a suitable alternative path is used. The main dif- ficulty when using this technique is guaranteeing that the routing algorithm will remain deadlock-free when using the alternative paths, given that arbitrary fault patterns may occur. This is especially difficult in direct networks whose regularity can be compromised by the fault pattern. The Cray T3E is an example system that successfully applies this technique on its 3D torus direct network. There are many examples of this technique in systems using indirect networks, such as with the bidirectional multistage networks in the ASCI White and ASC Purple. Those net- works provide multiple minimal paths between end nodes and, inherently, have no routing deadlock problems (see [Section F.5](#network-routing-arbitration-and-switching)). In these networks, alternative paths are selected at the source node in case of failure.

> 另一方面，容忍故障的路由利用网络拓扑中已经存在的多个路径在不需要备用资源的情况下在存在故障的情况下路由消息。在设计时间确定了每个受支持的故障组合的替代路径，并将其掺入路由算法中。当检测到故障时，使用合适的替代路径。使用此技术时，主要的差异是在使用替代路径时保证路由算法将保持无僵局，鉴于可能会发生任意故障模式。这在直接网络中尤其困难，其规律性可能会因故障模式而损害。Cray T3E 是一个示例系统，可在其 3D Torus Direct 网络上成功应用此技术。在系统中使用间接网络的系统中有许多示例，例如 ASCI 白色和 ASC 紫色的双向多阶段网络。这些网络作品在末端节点之间提供了多个最小路径，并且本质上没有路由僵局问题(请参阅[[F.5]节(＃Network-Routing-arbitration-arbitration-switching))。在这些网络中，如果失败，则在源节点上选择替代路径。

Network reconfiguration is yet another, more general technique to handle vol- untary and involuntary changes in the network topology due either to failures or to some other cause. In order for the network to be reconfigured, the nonfaulty por- tions of the topology must first be discovered, followed by computation of the new routing tables and distribution of the routing tables to the corresponding network locations (i.e., switches and/or end node devices). Network reconfiguration requires the use of programmable switches and/or network interfaces, depending on how routing is performed. It may also make use of generic routing algorithms (e.g., up\*/down\* routing) that can be configured for all the possible network topol- ogies that may result after faults. This strategy relieves the designer from having to supply alternative paths for each possible fault combination at design time. Pro- grammable network components provide a high degree of flexibility but at the expense of higher cost and latency. Most standard and proprietary interconnection networks for clusters and SANs—including Myrinet, Quadrics, InfiniBand, Advanced Switching, and Fibre Channel—incorporate software for (re)configur- ing the network routing in accordance with the prevailing topology.

> 网络重新配置是另一种更通用的技术，可以处理由于失败或其他原因而导致的网络拓扑变量和非自愿变化。为了重新配置网络，必须首先发现拓扑的非故障易变，然后计算新路由表以及将路由表的分布分配到相应的网络位置(即开关和/或 END 节点设备)。网络重新配置需要使用可编程开关和/或网络接口，具体取决于如何执行路由。它还可以利用通用路由算法(例如，向上\*/down \*路由)，可以为所有可能在故障后可能导致的网络托管配置配置。该策略使设计人员不得不在设计时为每个可能的故障组合提供替代路径。潜在的网络组件提供了高度的灵活性，但以更高的成本和延迟为代价。大多数用于集群和 SAN 的标准和专有互连网络，包括迈尔特，四边形，Infiniband，Advanced Switching 和 Fiber Channel，用于(重新)根据普遍拓扑配置网络路由的(重新配置网络路由)。

Another practical issue ties to node failure tolerance. If an interconnection net- work can survive a failure, can it also continue operation while a new node is added to or removed from the network, usually referred to as _hot swapping_? If not, each addition or removal of a new node disables the interconnection network, which is impractical for WANs and LANs and is usually intolerable for most SANs. Online system expansion requires hot swapping, so most networks allow for it. Hot swap- ping is usually supported by implementing _dynamic network reconfiguration_, in which the network is reconfigured without having to stop user traffic. The main difficulty with this is guaranteeing deadlock-free routing while routing tables for switches and/or end node devices are dynamically and asynchronously updated as more than one routing algorithm may be alive (and, perhaps, clashing) in the network at the same time. Most WANs solve this problem by dropping packets whenever required, but dynamic network reconfiguration is much more complex in lossless networks. Several theories and practical techniques have recently been developed to address this problem efficiently.

> 另一个实际问题与节点故障耐受性有关。如果互连网络可以在失败中生存，那么在添加新节点或从网络中删除的新节点时，它也可以继续操作，通常称为_ hot 交换_？如果没有，新节点的每次添加或去除都会禁用互连网络，这对于 WAN 和 LAN 是不切实际的，通常对于大多数 SAN 来说都是无法忍受的。在线系统扩展需要热交换，因此大多数网络都允许它。热交换通常通过实现_DYNAMIC 网络重新配置_支持，在该_ dynamic 网络重新配置_可以重新配置网络而无需停止用户流量。这样做的主要困难是确保在交换机和/或终端节点设备的路由表中进行动态和同步更新，因为多个路由算法可能同时还活着(也许，也许是冲突)。大多数 WAN 通过在需要时丢弃数据包来解决此问题，但是在无损网络中，动态网络重新配置更为复杂。最近已经开发了几种理论和实用技术来有效解决这一问题。

Example Figure F.27 shows the number of failures of 58 desktop computers on a local area network for a period of just over one year. Suppose that one local area net- work is based on a network that requires all machines to be operational for the interconnection network to send data; if a node crashes, it cannot accept mes- sages, so the interconnection becomes choked with data waiting to be delivered. An alternative is the traditional local area network, which can operate in the presence of node failures; the interconnection simply discards messages for a node that decides not to accept them. Assuming that you need to have both your workstation and the connecting LAN to get your work done, how much greater are your chances of being prevented from getting your work done using the failure-intolerant LAN versus traditional LANs? Assume the downtime for a crash is less than 30 minutes. Calculate using the one-hour intervals from this figure.

> 示例图 F.27 显示了仅一年以上的局部网络上 58 台台式计算机的故障数量。假设一项局域网工作是基于一个网络，该网络要求所有计算机都必须为互连网络发送数据。如果节点崩溃，它不能接受序列，因此互连会被等待传递的数据所 cho 住。另一种选择是传统的局域网，可以在存在节点故障的情况下运行。互连只是丢弃了决定不接受的节点的消息。假设您需要同时设置工作站和连接 LAN 才能完成工作，那么使用失败的局势 LAN 与传统 LAN 相比，阻止您无法完成工作的机会要多得多？假设撞车的停机时间不到 30 分钟。使用该图的一个小时间隔计算。

The percentage of hours that you can’t get your work done using the traditional network is just the time your workstation has crashed. If these failures are equally distributed among workstations, the percentage is

> 您无法使用传统网络完成工作的小时百分比只是您的工作站崩溃的时间。如果这些故障在工作站之间平均分配，则百分比是

Hence, you are more than 30 times more likely to be prevented from getting your work done with the failure-intolerant LAN than with the traditional LAN, accord- ing to the failure statistics in Figure F.27. Stated alternatively, the person respon- sible for maintaining the LAN would receive a 30-fold increase in phone calls from irate users!

> 因此，根据图 F.27 中的故障统计数据，您无法阻止失败的 LAN 完成工作的可能性高 30 倍以上。或者说，维护 LAN 的人可以从愤怒的用户接到电话 30 倍！

Figure F.27 Measurement of reboots of 58 DECstation 5000 s running Ultrix over a 373-day period. These reboots are distributed into time intervals of one hour and one day. The first column sorts the intervals according to the num- ber of machines that failed in that interval. The next two columns concern one-hour intervals, and the last two col- umns concern one-day intervals. The second and fourth columns show the number of intervals for each number of failed machines. The third and fifth columns are just the product of the number of failed machines and the number of intervals. For example, there were 50 occurrences of one-hour intervals with 2 failed machines, for a total of 100 failed machines, and there were 35 days with 2 failed machines, for a total of 70 failures. As we would expect, the number of failures per interval changes with the size of the interval. For example, the day with 31 failures might include one hour with 11 failures and one hour with 20 failures. The last row shows the total number of each column; the number of failures doesn’t agree because multiple reboots of the same machine in the same interval do not result in separate entries. (Randy Wang of the University of California–Berkeley collected these data.)

> 图 F.27 在 373 天内运行 Ultrix 的 58 decStation 5000 S 的重新启动的测量。这些重新启动分布成一小时零一天的时间间隔。第一列根据该间隔失败的机器数量对间隔进行分类。接下来的两列涉及一个小时的间隔，最后两个 columns 涉及一日间隔。第二和第四列显示了每个故障计算机数量的间隔数。第三列和第五列只是故障计算机数量和间隔数量的乘积。例如，有 50 次发生的一小时间隔，有 2 台故障机器，总共有 100 台故障机器，有 35 天有 2 台失败的机器，总共有 70 台故障。正如我们期望的那样，随着间隔的大小，每个间隔更改的故障数量。例如，发生 31 次失败的一天可能包括一个小时，有 11 个失败和 1 个小时，有 20 个失败。最后一行显示每列的总数；失败的数量不同意，因为在同一间隔中对同一计算机进行多次重启不会导致单独的条目。(加利福尼亚大学 - 伯克利分校的兰迪·王(Randy Wang)收集了这些数据。)
