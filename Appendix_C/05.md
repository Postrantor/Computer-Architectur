## Extending the RISC V Integer Pipeline to Handle Multicycle Operations

We now want to explore how our RISC V pipeline can be extended to handle floating-point operations. This section concentrates on the basic approach and the design alternatives, closing with some performance measurements of a RISC V floating-point pipeline.

> 现在，我们想探索如何扩展我们的 RISC V 管道以处理浮点操作。本节关注基本方法和设计替代方案，并通过 RISC V 浮点管道的一些性能测量结束。

It is impractical to require that all RISC V FP operations complete in 1 clock cycle, or even in 2. Doing so would mean accepting a slow clock or using enor- mous amounts of logic in the FP units, or both. Instead, the FP pipeline will allow for a longer latency for operations. This is easier to grasp if we imagine the FP instructions as having the same pipeline as the integer instructions, with two impor- tant changes. First, the EX cycle may be repeated as many times as needed to com- plete the operation—the number of repetitions can vary for different operations. Second, there may be multiple FP functional units. A stall will occur if the instruc- tion to be issued will cause either a structural hazard for the functional unit it uses or a data hazard.

> 不切实际地要求所有 RISC V FP 操作在 1 个时钟周期中完成，甚至在 2 中完成。这样做意味着接受缓慢的时钟或在 FP 单元中或两者兼而有之。相反，FP 管道将允许操作延迟。如果我们想象 FP 指令具有与整数指令相同的管道，并且具有两个重要的更改，则更容易掌握。首先，可以根据需要重复多次 EX 周期以完成操作 - 重复的数量可能会因不同的操作而变化。其次，可能有多个 FP 功能单元。如果要发行的指令会对其使用的功能单元或数据危害造成结构性危害，则会发生失速。

For this section, let’s assume that there are four separate functional units in our RISC V implementation:

> 对于本节，我们假设我们的 RISC v 实施中有四个单独的功能单元：

1. The main integer unit that handles loads and stores, integer ALU operations, and branches
2. FP and integer multiplier
3. FP adder that handles FP add, subtract, and conversion
4. FP and integer divider

If we also assume that the execution stages of these functional units are not pipe- lined, then [Figure C.28](#_bookmark515) shows the resulting pipeline structure. Because EX is not pipelined, no other instruction using that functional unit may issue until the previ- ous instruction leaves EX. Moreover, if an instruction cannot proceed to the EX stage, the entire pipeline behind that instruction will be stalled.

> 如果我们还假设这些功能单元的执行阶段没有管道，则[图 c.28](#_bookmark515) 显示了生成的管道结构。因为没有管道，因此没有其他使用该功能单元的指令可以发行，直到前面的指令离开 Ex。此外，如果指令无法进入 EX 阶段，则该说明背后的整个管道将停滞不前。

In reality, the intermediate results are probably not cycled around the EX unit as [Figure C.28](#_bookmark515) suggests; instead, the EX pipeline stage has some number of clock delays larger than 1. We can generalize the structure of the FP pipeline shown in [Figure C.28](#_bookmark515) to allow pipelining of some stages and multiple ongoing operations. To describe such a pipeline, we must define both the latency of the functional units and also the _initiation interval_ or _repeat interval_. We define latency the same way we defined it earlier: the number of intervening cycles between an instruction that produces a result and an instruction that uses the result. The initiation or repeat interval is the number of cycles that must elapse between issuing two operations of a given type. For example, we will use the latencies and initiation intervals shown in [Figure C.29](#_bookmark516).

> 实际上，中间结果可能不会围绕 EX 单元循环，如[图 C.28](#_bookmark515) 建议；取而代之的是，EX 管道阶段的时钟延迟大于 1。我们可以概括[图 C.28](#_bookmark515) 中所示的 FP 管道的结构，以允许某些阶段和多个正在进行的操作的管道进行管道。要描述这样的管道，我们必须定义功能单元的延迟，以及 *initiation Interval* 或 *repeat Interval*。我们定义延迟方式，就像我们先前定义的方式相同：产生结果的指令与使用结果的指令之间的中间周期数。启动或重复间隔是在发出给定类型的两个操作之间必须通过的循环数。例如，我们将使用[图 C.29](#_bookmark516) 中显示的潜伏期和启动间隔。

With this definition of latency, integer ALU operations have a latency of 0, because the results can be used on the next clock cycle, and loads have a latency of 1, because their results can be used after one intervening cycle. Because most operations consume their operands at the beginning of EX, the latency is usually the number of stages after EX that an instruction produces a result—for example, zero stages for ALU operations and one stage for loads. The primary exception is stores, which consume the value being stored one cycle later. Hence, the latency to

> 通过这种延迟的定义，整数 ALU 操作的延迟为 0，因为结果可以在下一个时钟周期中使用，并且负载的延迟为 1，因为它们的结果可以在一个中间循环后使用。由于大多数操作在 EX 的开头消耗其操作数，因此延迟通常是指令产生结果后的 EX 后阶段数，例如，ALU 操作的零阶段和一个负载阶段。主要例外是商店，该商店会在以后消耗一个周期的值。因此，延迟

![](../media/image576.png)

Figure C.28 The RISC V pipeline with three additional unpipelined, floating-point, functional units. Because only one instruction issues on every clock cycle, all instruc- tions go through the standard pipeline for integer operations. The FP operations simply loop when they reach the EX stage. After they have finished the EX stage, they proceed to MEM and WB to complete execution.

> 图 C.28 RISC V 管道，带有三个额外的浮点，浮点，功能单元。因为在每个时钟周期中只有一个指令问题，所以所有的工程都通过标准管道进行整数操作。FP 操作到达前阶段时只需循环即可。完成前阶段后，他们继续前往 MEM 和 WB 完成执行。

Figure C.29 Latencies and initiation intervals for functional units.

a store for the value being stored, but not for the base address register, will be one cycle less. Pipeline latency is essentially equal to one cycle less than the depth of the execution pipeline, which is the number of stages from the EX stage to the stage that produces the result. Thus, for the preceding example pipeline, the number of stages in an FP add is four, while the number of stages in an FP multiply is seven. To achieve a higher clock rate, designers need to put fewer logic levels in each pipe stage, which makes the number of pipe stages required for more complex operations larger. The penalty for the faster clock rate is thus longer latency for operations.

> 存储的值的商店(但不能用于基本地址寄存器)，将少一个周期。管道延迟基本上等于一个周期小于执行管道深度的循环，这是从 EX 阶段到产生结果的阶段的阶段数。因此，对于上一个示例管道，fp 添加中的阶段数为四个，而 fp 倍数中的阶段数为 7。为了达到更高的时钟速率，设计人员需要在每个管道阶段将更少的逻辑水平放置，这使得更大的操作更大的管道阶段数量。因此，更快的时钟率的罚款是操作的延迟。

The example pipeline structure in [Figure C.29](#_bookmark516) allows up to four outstanding FP adds, seven outstanding FP/integer multiplies, and one FP divide. [Figure C.30](#_bookmark517) shows how this pipeline can be drawn by extending [Figure C.28](#_bookmark515). The repeat inter- val is implemented in [Figure C.30](#_bookmark517) by adding additional pipeline stages, which will be separated by additional pipeline registers. Because the units are independent, we name the stages differently. The pipeline stages that take multiple clock cycles, such as the divide unit, are further subdivided to show the latency of those stages. Because they are not complete stages, only one operation may be active. The pipe- line structure can also be shown using the familiar diagrams from earlier in the appendix, as [Figure C.31](#_bookmark518) shows for a set of independent FP operations and FP loads and stores. Naturally, the longer latency of the FP operations increases the frequency of RAW hazards and resultant stalls, as we will see later in this section. The structure of the pipeline in [Figure C.30](#_bookmark517) requires the introduction of the additional pipeline registers (e.g.,A1/A2, A2/A3, A3/A4) and the modification of the connections to those registers. The ID/EX register must be expanded to connect ID to EX, DIV, M1, and A1; we can refer to the portion of the register associated with one of the next stages with the notation ID/EX, ID/DIV, ID/ M1, or ID/A1. The pipeline register between ID and all the other stages may be thought of as logically separate registers and may, in fact, be implemented as sep- arate registers. Because only one operation can be in a pipe stage at a time, the control information can be associated with the register at the head of the stage.

> [图 C.29](#_bookmark516) 中的示例流水线结构允许最多 4 个未完成的 FP 加法、7 个未完成的 FP/整数乘法和 1 个 FP 除法。 [图 C.30](#_bookmark517) 显示了如何通过扩展 [图 C.28](#_bookmark515) 绘制此管道。 重复间隔在 [图 C.30](#_bookmark517) 中通过添加额外的流水线级实现，这些流水线级将由额外的流水线寄存器分隔。 因为单元是独立的，所以我们以不同的方式命名阶段。 需要多个时钟周期的流水线阶段，例如除法单元，被进一步细分以显示这些阶段的延迟。 因为它们不是完整的阶段，所以只有一个操作可能处于活动状态。 管道结构也可以使用附录前面的熟悉图表来显示，如[图 C.31](#_bookmark518) 所示的一组独立的 FP 操作和 FP 加载和存储。 自然地，较长的 FP 操作延迟会增加 RAW 危险和由此产生的停顿的频率，正如我们将在本节后面看到的那样。 [图 C.30](#_bookmark517) 中的流水线结构需要引入额外的流水线寄存器（例如，A1/A2、A2/A3、A3/A4）并修改与这些寄存器的连接。 ID/EX 寄存器必须扩展，将 ID 连接到 EX、DIV、M1、A1； 我们可以用符号 ID/EX、ID/DIV、ID/M1 或 ID/A1 来指代与下一阶段之一关联的寄存器部分。 ID 和所有其他阶段之间的流水线寄存器可以被认为是逻辑上独立的寄存器，并且实际上可以作为单独的寄存器来实现。 因为在一个流水阶段中一次只能有一个操作，所以控制信息可以与阶段头部的寄存器相关联。

![](../media/image582.png)<span id="_bookmark517" class="anchor"></span>Integer unit

Figure C.30 A pipeline that supports multiple outstanding FP operations. The FP multiplier and adder are fully pipelined and have a depth of seven and four stages, respectively. The FP divider is not pipelined, but requires 24 clock cycles to complete. The latency in instructions between the issue of an FP operation and the use of the result of that operation without incurring a RAW stall is determined by the number of cycles spent in the execution stages. For example, the fourth instruction after an FP add can use the result of the FP add. For integer ALU operations, the depth of the execution pipeline is always one and the next instruction can use the results.

> 图 C.30 支持多个出色的 FP 操作的管道。FP 乘数和加法器已完全管道，分别具有七个和四个阶段的深度。FP 分隔线没有管道，但需要 24 个时钟周期才能完成。FP 操作发行和使用该操作结果的使用中的延迟在不产生原始失速的情况下取决于执行阶段中花费的周期数量。例如，FP 添加后的第四个指令可以使用 FP 添加的结果。对于整数 ALU 操作，执行管道的深度始终是一个，下一个指令可以使用结果。

Figure C.31 The pipeline timing of a set of independent FP operations. The stages in italics show where data are needed, while the stages in bold show where a result is available. FP loads and stores use a 64-bit path to memory so that the pipelining timing is just like an integer load or store.

> 图 C.31 一组独立的 FP 操作的管道时间。斜体中的阶段显示了需要数据的位置，而大胆显示结果可用的阶段。FP 负载和商店使用 64 位的内存路径，使管道时机就像整数负载或存储一样。

### Hazards and Forwarding in Longer Latency Pipelines

There are a number of different aspects to the hazard detection and forwarding for a pipeline like that shown in [Figure C.30](#_bookmark517).

> 如[图 C.30]中所示的管道的危险检测和转发有许多不同的方面(#\_bookmark517)。

1. Because the divide unit is not fully pipelined, structural hazards can occur. These will need to be detected and issuing instructions will need to be stalled.

> 1.由于分裂单元没有完全管道，因此可能会发生结构性危害。这些将需要检测到，并且需要停滞不前发行说明。

2. Because the instructions have varying running times, the number of register writes required in a cycle can be larger than 1.

> 2.由于指令的运行时间有所不同，因此周期中所需的寄存器数量可能大于 1。

3. Write after write (WAW) hazards are possible, because instructions no longer reach WB in order. Note that write after read (WAR) hazards are not possible, because the register reads always occur in ID.

> 3.在写入后写入(WAW)危害是可能的，因为说明不再按顺序达到 WB。请注意，在阅读后写入(战争)危害是不可能的，因为寄存器读取始终在 ID 中出现。

4. Instructions can complete in a different order than they were issued, causing problems with exceptions; we deal with this in the next subsection.

> 4.指示可以按照与发行不同的顺序完成，从而导致例外问题；我们在下一个小节中处理此问题。

5. Because of longer latency of operations, stalls for RAW hazards will be more frequent.

> 5.由于操作的延迟时间更长，因此原始危害的摊位将更加频繁。

The increase in stalls arising from longer operation latencies is fundamentally the same as that for the integer pipeline. Before describing the new problems that arise in this FP pipeline and looking at solutions, let’s examine the potential impact of RAW hazards. [Figure C.32](#_bookmark519) shows a typical FP code sequence and the resultant stalls. At the end of this section, we’ll examine the performance of this FP pipeline for our SPEC subset.

> 较长的操作潜伏期产生的摊位的增加在根本上与整数管道相同。在描述 FP 管道中出现的新问题并研究解决方案之前，让我们研究原始危害的潜在影响。[图 C.32](#_bookmark519) 显示了典型的 FP 代码序列和结果摊位。在本节的末尾，我们将研究该 SPEC 子集的 FP 管道的性能。

Now look at the problems arising from writes, described as (2) and (3) in the earlier list. If we assume that the FP register file has one write port, sequences of FP operations, as well as an FP load together with FP operations, can cause conflicts for the register write port. Consider the pipeline sequence shown in [Figure C.33](#_bookmark520). In clock cycle 11, all three instructions will reach WB and want to write the register file. With only a single register file write port, the processor must serialize the instruction completion. This single register port represents a structural hazard. We could increase the number of write ports to solve this, but that solution may be unattractive because the additional write ports would be used only rarely. This is because the maximum steady-state number of write ports needed is 1. Instead, we choose to detect and enforce access to the write port as a structural hazard.

> 现在查看由写作引起的问题，即早期列表中的(2)和(3)。如果我们假设 FP 寄存器文件具有一个写入端口，则 FP 操作的序列以及与 FP 操作一起使用 FP 负载，可能会导致寄存器写入端口的冲突。考虑[图 C.33]中显示的管道序列(#\_bookmark520)。在时钟周期 11 中，所有三个说明都将到达 WB 并要编写寄存器文件。只有单个寄存器文件写端口，处理器必须序列化指令完成。该单个寄存器端口代表结构性危害。我们可以增加写入端口的数量来解决此问题，但是该解决方案可能没有吸引力，因为附加写入端口只会很少使用。这是因为所需的写入端口的最大稳态数为 1。相反，我们选择检测并强制执行对写入端口的访问作为结构性危害。

Figure C.32 A typical FP code sequence showing the stalls arising from RAW hazards. The longer pipeline sub- stantially raises the frequency of stalls versus the shallower integer pipeline. Each instruction in this sequence is dependent on the previous and proceeds as soon as data are available, which assumes the pipeline has full bypassing and forwarding. The fsd must be stalled an extra cycle so that its MEM does not conflict with the fadd.d. Extra hardware could easily handle this case.

> 图 C.32 典型的 FP 代码序列显示了由原始危害引起的失速。较长的管道可在地下提高摊位的频率与较浅的整数管道。此序列中的每个指令取决于上一个，并在数据可用后立即进行，这假设管道具有完整的绕过和转发。必须将 FSD 停滞在一个额外的周期中，以使其 MEM 不会与 Fadd.D 发生冲突。额外的硬件可以轻松处理这种情况。

There are two different ways to implement this interlock. The first is to track the use of the write port in the ID stage and to stall an instruction before it issues, just as we would for any other structural hazard. Tracking the use of the write port can be done with a shift register that indicates when already-issued instructions will use the register file. If the instruction in ID needs to use the register file at the same time as an instruction already issued, the instruction in ID is stalled for a cycle. On each clock the reservation register is shifted 1 bit. This implementation has an advan- tage: It maintains the property that all interlock detection and stall insertion occurs in the ID stage. The cost is the addition of the shift register and write conflict logic. We will assume this scheme throughout this section.

> 实施此互锁的方法有两种不同的方法。首先是跟踪在 ID 阶段的写入端口的使用，并在发出的指令之前停止使用指令，就像我们对任何其他结构危险一样。可以使用移位寄存器来跟踪写入端口的使用，该寄存器指示何时已经发布的说明将使用寄存器文件。如果 ID 中的指令需要与已经发布的指令同时使用寄存器文件，则 ID 中的指令停滞了一个周期。在每个时钟上，预订寄存器都移动了 1 位。该实现具有一个优势：它维护所有互锁检测和失速插入发生在 ID 阶段中的属性。成本是增加移位寄存器和写冲突逻辑。我们将在本节中假设该方案。

Figure C.33 Three instructions want to perform a write-back to the FP register file simultaneously, as shown in clock cycle 11. This is _not_ the worst case, because an earlier divide in the FP unit could also finish on the same clock. Note that although the fmul.d, fadd.d, and fld are in the MEM stage in clock cycle 10, only the fld actually uses the memory, so no structural hazard exists for MEM.

> 图 C.33 三个指令希望同时对 FP 寄存器文件进行写入，如时钟周期 11 所示。这是 *not* 最坏的情况，因为 FP 单元中的较早鸿沟也可以在同一时钟上完成。请注意，尽管 FMUL.D，FADD.D 和 FLD 处于时钟周期 10 中的 MEM 阶段，但只有 FLD 实际使用内存，因此不存在 MEM 的结构危害。

An alternative scheme is to stall a conflicting instruction when it tries to enter either the MEM or WB stage. If we wait to stall the conflicting instructions until they want to enter the MEM or WB stage, we can choose to stall either instruction. A simple, though sometimes suboptimal, heuristic is to give priority to the unit with the longest latency, because that is the one most likely to have caused another instruction to be stalled for a RAW hazard. The advantage of this scheme is that it does not require us to detect the conflict until the entrance of the MEM or WB stage, where it is easy to see. The disadvantage is that it complicates pipeline con- trol, as stalls can now arise from two places. Notice that stalling before entering MEM will cause the EX, A4, or M7 stage to be occupied, possibly forcing the stall to trickle back in the pipeline. Likewise, stalling before WB would cause MEM to back up.

> 另一种方案是在尝试进入 MEM 或 WB 阶段时停滞不前的指令。如果我们等待陷入矛盾的指示，直到他们想进入 MEM 或 WB 阶段，我们可以选择停滞任何指令。一个简单的启发式启发式是一个简单的，尽管有时是次优的，但要优先考虑最长的延迟，因为这是最有可能导致另一种指导因原始危害而停滞的一种。该方案的优点是，它不需要我们在易于看到的 MEM 或 WB 阶段的入口之前检测冲突。缺点是它使管道控制复杂化，因为摊位现在可以从两个地方产生。请注意，进入 MEM 前的停滞将导致 EX，A4 或 M7 阶段被占用，可能会迫使摊位滴入管道中。同样，在 WB 之前停滞会导致 MEM 备份。

Our other problem is the possibility of WAW hazards. To see that these exist, consider the example in [Figure C.33](#_bookmark520). If the fadd.d instruction were issued one cycle earlier and had a destination of f2, then it would create a WAW hazard, because it would write f2 one cycle earlier than the fadd.d. Note that this hazard only occurs when the result of the fadd.d is overwritten _without_ any instruction ever using it! If there were a use of f2 between the fadd.d and the fadd.d, the pipeline would need to be stalled for a RAW hazard, and the fadd.d would not issue until the fadd.d was completed. We could argue that, for our pipeline, WAW hazards only occur when a useless instruction is executed, but we must still detect them and make sure that the result of the fadd.d appears in f2 when we are done. (As we will see in [Section C.8](#_bookmark537), such sequences sometimes _do_ occur in reasonable code.)

> 我们的另一个问题是造成危险的可能性。要查看这些存在，请考虑[图 C.33]中的示例(#*bookmark520)。如果 FADD.D 指令提前发布一个周期并具有 F2 目的地，则会产生 WAW 危险，因为它将比 FADD.D 提前写入 F2。请注意，只有在 Fadd.d 的结果被覆盖的结果\_without*的任何指令中，才会发生这种危害！如果 FADD.D 和 FADD.D 之间使用 F2，则需要将管道停滞起来，以解决原始危害，而 Fadd.D 直到 FADD.D 完成后才发行。我们可以说，对于我们的管道，只有在执行无用的指令时才会发生 WAW 危险，但是我们仍然必须检测到它们，并确保 FADD.D 的结果在完成后出现在 F2 中。(正如我们将在 [C.8](#_bookmark537) 中看到的那样，此类序列有时会出现在合理的代码中。)

There are two possible ways to handle this WAW hazard. The first approach is to delay the issue of the load instruction until the fadd.d enters MEM. The sec- ond approach is to stamp out the result of the fadd.d by detecting the hazard and changing the control so that the fadd.d does not write its result. Then the fadd.d can issue right away. Because this hazard is rare, either scheme will work fine—you can pick whatever is simpler to implement. In either case, the hazard can be detected during ID when the fadd.d is issuing, and stalling the fadd.d or making the fadd.d a no-op is easy. The difficult situation is to detect that the fadd.d might finish before the fadd.d, because that requires knowing the length of the pipeline and the current position of the fadd.d. Luck- ily, this code sequence (two writes with no intervening read) will be very rare, so we can use a simple solution: if an instruction in ID wants to write the same reg- ister as an instruction already issued, do not issue the instruction to EX. In [Section C.7](#cross-cutting-issues-5), we will see how additional hardware can eliminate stalls for such hazards. First, let’s put together the pieces for implementing the hazard and issue logic in our FP pipeline.

> 有两种可能处理此 WAW 危险的方法。第一种方法是将负载指令的问题推迟到 FADD.D 进入 MEM。SEC-OND 方法是通过检测危害并更改控制的 Fadd.D 的结果来消除 FADD.D 的结果，以使 FADD.D 不写出其结果。然后 Fadd.D 可以立即发出。由于这种危害很少见，所以任何一个方案都可以正常工作 - 您可以选择更简单的实施的内容。无论哪种情况，在 Fadd.D 发行时都可以在 ID 期间检测到危险，并使 Fadd.D 停滞或使 Fadd.D 变得轻松。困难的情况是检测 Fadd.D 可能在 FADD.D 之前完成，因为这需要知道管道的长度和 FADD.D 的当前位置。幸运的是，此代码序列(两个没有中间阅读的写作)非常罕见，因此我们可以使用一个简单的解决方案：如果 ID 中的指令想编写相同的 reg-iSter 作为已经发布的指令，请不要发行前任的指示。在[c.7 节](＃交叉切割 - 发行-5)中，我们将看到其他硬件如何消除这种危险的摊位。首先，让我们整理一下在 FP 管道中实施危害并发行逻辑的部分。

In detecting the possible hazards, we must consider hazards among FP instruc- tions, as well as hazards between an FP instruction and an integer instruction. Except for FP loads-stores and FP-integer register moves, the FP and integer registers are distinct. All integer instructions operate on the integer registers, while the FP operations operate only on their own registers. Thus, we need only consider FP loads-stores and FP register moves in detecting hazards between FP and integer instructions. This simplification of pipeline control is an additional advantage of having separate register files for integer and floating-point data. (The main advan- tages are a doubling of the number of registers, without making either set larger, and an increase in bandwidth without adding more ports to either set. The main disadvantage, beyond the need for an extra register file, is the small cost of occa- sional moves needed between the two register sets.) Assuming that the pipeline does all hazard detection in ID, there are three checks that must be performed before an instruction can issue:

> 在检测可能的危害时，我们必须考虑 FP 指导之间的危害，以及 FP 指导和整数指令之间的危害。除了 FP Loads 商店和 FP-Integer 寄存器移动外，FP 和整数寄存器都是不同的。所有整数说明都在整数寄存器上运行，而 FP 操作仅在自己的登记册上运行。因此，我们只需要考虑 FP 载荷商店和 FP 寄存器移动即可检测 FP 和整数指令之间的危害。管道控制的简化是将单独的寄存器文件用于整数和浮点数据的另一个优点。(主要的优势是寄存器数量的一倍，没有使要么更大，带宽的增加而不添加更多端口。两个寄存器组之间需要进行的偶数移动成本。)假设管道在 ID 中进行所有危险检测，则必须在指令发出之前进行三项检查：

1. _Check for structural hazards_—Wait until the required functional unit is not busy (this is only needed for divides in this pipeline) and make sure the register write port is available when it will be needed.

> 1. _ CHECK 结构性危害_-等待直到所需的功能单元不忙(仅在此管道中进行分割需要)，并确保在需要时可用寄存器写入端口。

2. _Check for a RAW data hazard_—Wait until the source registers are not listed as pending destinations in a pipeline register that will not be available when this instruction needs the result. A number of checks must be made here, depending on both the source instruction, which determines when the result will be avail- able, and the destination instruction, which determines when the value is needed. For example, if the instruction in ID is an FP operation with source reg- ister f2, then f2 cannot be listed as a destination in ID/A1, A1/A2, or A2/A3, which correspond to FP add instructions that will not be finished when the instruction in ID needs a result. (ID/A1 is the portion of the output register of ID that is sent to A1.) Divide is somewhat more tricky, if we want to allow the last few cycles of a divide to be overlapped, because we need to handle the case when a divide is close to finishing as special. In practice, designers might ignore this optimization in favor of a simpler issue test.

> 2. _ check for 原始数据危害_-等待，直到源寄存器未列为管道寄存器中的待处理目的地，当此指令需要结果时，该目的是无法可用的。必须在此处进行许多检查，具体取决于源指令，这些指令确定结果何时可用以及目标指令，该指令确定何时需要值。例如，如果 ID 中的指令是带有源 reg-iSter F2 的 FP 操作，则 F2 不能列为 ID/A1，A1/A2 或 A2/A3 中的目标，该目的当 ID 中的指令需要结果时，要完成。(id/a1 是发送到 A1 的 ID 输出寄存器的一部分。)鸿沟有些棘手，如果我们要允许分隔的最后几个周期重叠，因为我们需要在情况下处理情况。鸿沟几乎是特殊的。实际上，设计师可能会忽略此优化，而不是更简单的问题测试。

3. _Check for a WAW data hazard_—Determine if any instruction in A1, … , A4, D, M1, … , M7 has the same register destination as this instruction. If so, stall the issue of the instruction in ID.

> 3. _ check for waw 数据危害_-确定的 A1，…，A4，D，M1，…，M7 中的任何指令具有与此指令相同的寄存器目的地。如果是这样，请在 ID 中拖延指令问题。

Although the hazard detection is more complex with the multicycle FP operations, the concepts are the same as for the RISC V integer pipeline. The same is true for the forwarding logic. The forwarding can be implemented by checking if the destination register in any of the EX/MEM, A4/MEM, M7/MEM, D/MEM, or MEM/WB registers is one of the source registers of a floating-point instruction. If so, the appropriate input multiplexer will have to be enabled so as to choose the forwarded data. In the exercises, you will have the opportunity to specify the logic for the RAW and WAW hazard detection as well as for forwarding.

> 尽管危险检测与多环形 FP 操作更为复杂，但这些概念与 RISC V Integer Pipeline 相同。转发逻辑也是如此。可以通过检查 EX/MEM，A4/MEM，M7/MEM，D/MEM 或 MEM/WB 寄存器中的任何一个中的目标寄存器是否是浮点指令的来源寄存器之一，可以实现转发。如果是这样，则必须启用适当的输入多路复用器，以便选择转发数据。在练习中，您将有机会指定原始危害检测和转发的逻辑。

Multicycle FP operations also introduce problems for our exception mecha- nisms, which we deal with next.

> 多环形 FP 操作还引入了我们的例外机械性问题，我们接下来要处理。

### Maintaining Precise Exceptions

> CPU 在执行指令的时候也有乱序执行

Another problem caused by these long-running instructions can be illustrated with the following sequence of code:

> 这些长期运行的说明引起的另一个问题可以用以下代码顺序说明：

This code sequence looks straightforward; there are no dependences. A problem arises, however, because an instruction issued early may complete after an instruc- tion issued later. In this example, we can expect fadd.d and fsub.d to complete _before_ the fdiv.d completes. This is called _out-of-order completion_ and is com- mon in pipelines with long-running operations (see [Section C.7](#cross-cutting-issues-5)). Because hazard detection will prevent any dependence among instructions from being violated, why is out-of-order completion a problem? Suppose that the fsub.d causes a floating-point arithmetic exception at a point where the fadd.d has completed but the fdiv.d has not. The result will be an imprecise exception, something we are trying to avoid. It may appear that this could be handled by letting the floating-point pipeline drain, as we do for the integer pipeline. But the exception may be in a position where this is not possible. For example, if the fdiv.d decided to take a floating-point-arithmetic exception after the add completed, we could not have a precise exception at the hardware level. In fact, because the fadd.d destroys one of its operands, we could not restore the state to what it was before the fdiv.d, even with software help.

> 这个代码序列看起来很简单； 没有依赖性。 然而，出现了一个问题，因为较早发出的指令可能会在较晚发出的指令之后完成。 在这个例子中，我们可以预期 fadd.d 和 fsub.d 在 fdiv.d 完成之前完成。 这称为*乱序完成*，在具有长时间运行操作的管道中很常见（请参阅[第 C.7 节](#cross-cutting-issues-5)）。 因为危险检测将防止违反指令之间的任何依赖性，为什么乱序完成是一个问题？ 假设 fsub.d 在 fadd.d 已完成但 fdiv.d 尚未完成的位置处导致浮点算术异常。 结果将是一个不精确的异常，这是我们试图避免的。 看起来这可以通过让浮点管道排空来处理，就像我们对整数管道所做的那样。 但例外情况可能处于无法做到这一点的位置。 例如，如果 fdiv.d 在 add 完成后决定采用浮点算术异常，我们就无法在硬件级别获得精确的异常。 事实上，因为 fadd.d 破坏了它的一个操作数，我们无法将状态恢复到 fdiv.d 之前的状态，即使有软件帮助也是如此。

This problem arises because instructions are completing in a different order than they were issued. There are four possible approaches to dealing with out- of-order completion. The first is to ignore the problem and settle for imprecise exceptions. This approach was used in the 1960s and early 1970s. It was still used in some supercomputers in thepast fifteen years, where certain classes of excep- tions were not allowed or were handled by the hardware without stopping the pipe- line. It is difficult to use this approach in most processors built today because of features such as virtual memory and the IEEE floating-point standard that essen- tially require precise exceptions through a combination of hardware and software. As mentioned earlier, some recent processors have solved this problem by intro- ducing two modes of execution: a fast, but possibly imprecise mode and a slower, precise mode. The slower precise mode is implemented either with a mode switch or by insertion of explicit instructions that test for FP exceptions. In either case, the amount of overlap and reordering permitted in the FP pipeline is significantly restricted so that effectively only one FP instruction is active at a time. This solu- tion was used in the DEC Alpha 21064 and 21164, in the IBM Power1 and Power2, and in the MIPS R8000.

> 出现此问题是因为指令的完成顺序与发出顺序不同。 有四种可能的方法来处理乱序完成。 第一种是忽略问题并满足于不精确的异常。 这种方法曾在 1960 年代和 1970 年代初期使用。 在过去的 15 年里，它仍在一些超级计算机中使用，其中某些类别的异常是不允许的，或者由硬件在不停止管道的情况下处理。 由于虚拟内存和 IEEE 浮点标准等功能本质上需要通过硬件和软件的组合来实现精确的异常，因此很难在当今构建的大多数处理器中使用这种方法。 如前所述，最近的一些处理器通过引入两种执行模式解决了这个问题：一种是快速但可能不精确的模式，另一种是较慢但精确的模式。 较慢的精确模式是通过模式切换或通过插入用于测试 FP 异常的显式指令来实现的。 在任何一种情况下，FP 流水线中允许的重叠和重新排序的数量都受到显着限制，因此实际上一次只有一条 FP 指令处于活动状态。 该解决方案用于 DEC Alpha 21064 和 21164、IBM Power1 和 Power2 以及 MIPS R8000。

A second approach is to buffer the results of an operation until all the operations that were issued earlier are complete. Some processors actually use this solution, but it becomes expensive when the difference in running times among operations is large, because the number of results to buffer can become large. Furthermore, results from the queue must be bypassed to continue issuing instructions while wait- ing for the longer instruction. This requires a large number of comparators and a very large multiplexer.

> 第二种方法是缓冲操作的结果，直到较早发行的所有操作都完成为止。一些处理器实际上使用了该解决方案，但是当操作之间的运行时间差异很大时，它变得昂贵，因为要缓冲的结果数量可能会变大。此外，必须绕过队列的结果，以便在等待更长的说明时继续发行说明。这需要大量的比较器和一个非常大的多路复用器。

There are two viable variations on this basic approach. The first is a _history file_, used in the CYBER 180/990. The history file keeps track of the original values of registers. When an exception occurs and the state must be rolled back earlier than some instruction that completed out of order, the original value of the register can be restored from the history file. A similar technique is used for autoincrement and autodecrement addressing on processors such as VAXes. Another approach, the _future file_, proposed by [Smith and Pleszkun (1988)](#_bookmark1007), keeps the newer value of a register; when all earlier instructions have completed, the main register file is updated from the future file. On an exception, the main register file has the precise values for the interrupted state. In [Chapter 3](#_bookmark93), we will see another approach that is needed to support speculation, a method of executing instructions before we know the outcome of previous branches.

> 这种基本方法有两个可行的变化。第一个是网络 180/990 中使用的*历史文件*。历史记录文件跟踪寄存器的原始值。当发生异常，并且必须比未订单完成的某些指令更早地回滚，则可以从历史记录文件中恢复寄存器的原始值。类似的技术用于在诸如 Vaxes 之类的处理器上进行自动递送和自动补偿。[Smith and Pleszkun(1988)](#_bookmark1007)提出的另一种方法是 *future file*，保留了寄存器的较新值；当所有较早的说明都完成后，主寄存器文件将从未来文件中更新。除了例外，主寄存器文件具有中断状态的精确值。在[第 3 章](#_bookmark93)中，我们将看到另一种支持投机所需的方法，即在我们知道先前分支的结果之前执行指令的方法。

A third technique in use is to allow the exceptions to become somewhat impre- cise, but to keep enough information so that the trap-handling routines can create a precise sequence for the exception. This means knowing what operations were in the pipeline and their PCs. Then, after handling the exception, the software finishes any instructions that precede the latest instruction completed, and the sequence can restart. Consider the following worst-case code sequence:

> 使用的第三种技术是允许异常变得有些巧妙，但是要保留足够的信息，以便陷阱处理程序可以为例外创建精确的序列。这意味着要知道管道中的操作及其 PC。然后，在处理异常后，软件完成了完成最新指令之前的任何指令，并且序列可以重新启动。考虑以下最差的代码序列：

Instruction<sub>1</sub>—A long-running instruction that eventually interrupts execution. Instruction<sub>2</sub>, … , Instruction<sub>_n_—1</sub>—A series of instructions that are not completed. Instruction*<sub>n</sub>*—An instruction that is finished.

> 指令<sub> 1 </sub> - 一项长期运行的指令，最终会中断执行。指令<sub> 2 </sub>，…，指令<sub> _n_—1 </sub> - 一系列未完成的指令。指令*<sub> n </sub>* - 完成的指令。

Given the PCs of all the instructions in the pipeline and the exception return PC, the software can find the state of instruction1 and instruction*<sub>n</sub>*. Because instruction*<sub>n</sub>* has completed, we will want to restart execution at instruction<sub>_n_+1</sub>. After handling the exception, the software must simulate the execution of instruction<sub>1</sub>, … , instruction<sub>_n_—1</sub>. Then we can return from the exception and restart at instruction<sub>_n_+1</sub>. The complexity of executing these instructions properly by the handler is the major difficulty of this scheme.

> 鉴于管道中所有指令的 PC 和异常返回 PC，该软件可以找到指令状态 1 和指令*<ub> n </sub>*。因为指令* <sub> n </sub>*已经完成，所以我们将要通过指令重新启动执行<ub> _n_+1 </sub>。处理异常后，该软件必须模拟指令的执行<ub> 1 </sub>，…，指令<ub> _n_—1 </sub>。然后，我们可以从异常返回，然后通过指令重新启动<sub> _n_+1 </sub>。处理程序正确执行这些说明的复杂性是该计划的主要困难。

There is an important simplification for simple RISC V-like pipelines: If instruction<sub>2</sub>, … , instruction*<sub>n</sub>* are all integer instructions, we know that if instruction*<sub>n</sub>* has completed then all of instruction<sub>2</sub>, … , instruction<sub>_n_—1</sub> have also completed. Thus, only FP operations need to be handled. To make this scheme tractable, the number of floating-point instructions that can be overlapped in execution can be limited. For example, if we only overlap two instructions, then only the interrupting instruction need be completed by software. This restriction may reduce the potential throughput if the FP pipelines are deep or if there are a significant number of FP functional units. This approach is used in some SPARC implementations to allow overlap of floating-point and integer operations.

> 对于简单的 RISC VISE 管道来说，有一个重要的简化：如果指令<ub> 2 </sub>，…，指令*<sub> n </sub>*都是整数指令，我们知道，如果指令*<sub sub> n </sub>*已经完成，然后所有指令<ub> 2 </sub>，…，指令<ub> _n_—1 </sub>也已经完成。因此，仅需要处理 FP 操作。为了使此方案可处理，可以限制可以在执行中重叠的浮点指令的数量。例如，如果我们仅重叠两个说明，则只需要通过软件完成中断指令。如果 FP 管道深处或有大量 FP 功能单位，则该限制可能会减少潜在的吞吐量。这种方法用于某些 SPARC 实现，以允许浮点和整数操作重叠。

The final technique is a hybrid scheme that allows the instruction issue to con- tinue only if it is certain that all the instructions before the issuing instruction will complete without causing an exception. This guarantees that when an exception occurs, no instructions after the interrupting one will be completed and all of the instructions before the interrupting one can be completed. This sometimes means stalling the processor to maintain precise exceptions. To make this scheme work, the floating-point functional units must determine if an exception is possible early in the EX stage (in the first 3 clock cycles in the RISC V pipeline), so as to prevent further instructions from completing. This scheme is used in the MIPS R2000/3000, the R4000, and the Intel Pentium. It is discussed further in Appendix J.

> 最终技术是一种混合方案，只有在确定发行指令之前的所有指令将完成而不会引起例外的情况下，才能允许指令问题连续。这可以保证当发生异常时，中断后没有说明，并且可以完成中断之前的所有说明。有时意味着停滞处理器以保持精确的例外。为了使该方案起作用，浮点功能单元必须确定在 EX 阶段(在 RISC V Pipeline 的前 3 个时钟周期中)是否可能出现异常，以防止进一步的说明完成。该方案用于 MIPS R2000/3000，R4000 和 Intel Pentium 中。在附录 J 中进一步讨论了它。

### Performance of a Simple RISC V FP Pipeline

> ###简单的 RISC V FP 管道的性能

The RISC V FP pipeline of [Figure C.30](#_bookmark517) on page C.48 can generate both structural stalls for the divide unit and stalls for RAW hazards (it also can have WAW haz- ards, but this rarely occurs in practice). [Figure C.34](#_bookmark522) shows the number of stall cycles for each type of floating-point operation on a per-instance basis (i.e., the first bar for each FP benchmark shows the number of FP result stalls for each FP add, subtract, or convert). As we might expect, the stall cycles per operation track the latency of the FP operations, varying from 46% to 59% of the latency of the functional unit.

> [图 C.30](#_bookmark517) 的 RISC V fp 管道 C.48 可以生成分隔单元的两个结构性摊位和原始危害的摊位(也可能具有 waw haw haf hax-ards，但这很少发生在实践)。[图 C.34](#_bookmark522) 以每种浮点操作为基础显示每种浮点操作的失速循环数(即，每个 FP 基准的第一个 bar 显示了每个 FP 的 FP 结果的数量添加，减去或转换)。正如我们可能期望的那样，每个操作的失速循环跟踪 FP 操作的潜伏期，从功能单元的延迟的 46％到 59％不等。

[Figure C.35](#_bookmark523) gives the complete breakdown of integer and FP stalls for five SPECfp benchmarks. There are four classes of stalls shown: FP result stalls, FP compare stalls, load and branch delays, and FP structural delays. Branch delay stalls, which would be small with a one cycle delay and even a modest branch predictor, are not included. The total number of stalls per instruction varies from 0.65 to 1.21.

> [图 C.35](#_bookmark523) 给出了五个 SPECFP 基准的整数和 FP 摊位的完整分解。显示了四类摊位：FP 结果摊位，FP 比较摊位，负载和分支延迟以及 FP 结构延迟。不包括一个周期延迟甚至适度的分支预测器，分支延迟摊位不包括在一个周期延迟中。每指令的摊位总数从 0.65 到 1.21 不等。

Putting It All Together: The MIPS R4000 Pipeline

> 将所有内容放在一起：MIPS R4000 管道

In this section, we look at the pipeline structure and performance of the MIPS R4000 processor family, which includes the 4400. The MIPS architecture and RISC V are very similar, differing only in a few instructions, including a delayed branch in the MIPS ISA. The R4000 implements MIPS64 but uses a deeper pipe- line than that of our five-stage design both for integer and FP programs. This dee- per pipeline allows it to achieve higher clock rates by decomposing the five-stage integer pipeline into eight stages. Because cache access is particularly time critical, the extra pipeline stages come from decomposing the memory access. This type of deeper pipelining is sometimes called _superpipelining_.

> 在本节中，我们查看包括 4400 在内的 MIPS R4000 处理器家族的管道结构和性能。MIPSArchitecture 和 Risc V 非常相似，仅在一些说明中有所不同，包括 MIPS ISA 中的延迟分支。R4000 实现了 MIPS64，但使用了比我们的五阶段设计更深的管道线，用于整数和 FP 程序。这种管道使它通过将五阶段整数管道分为八个阶段来实现更高的时钟速率。由于缓存访问特别关键时间，因此额外的管道阶段来自分解内存访问。这种更深的管道有时称为 *superpipelining*。

[Figure C.36](#_bookmark524) shows the eight-stage pipeline structure using an abstracted version of the data path. [Figure C.37](#_bookmark525) shows the overlap of successive instructions in the pipeline. Notice that, although the instruction and data memory occupy multiple cycles, they are fully pipelined, so that a new instruction can start on every clock.

> [图 C.36](#_bookmark524) 使用数据路径的抽象版本显示了八阶段管道结构。[图 C.37](#_bookmark525) 显示了管道中连续说明的重叠。请注意，尽管指令和数据存储器占据了多个周期，但它们是完全管道的，因此可以在每个时钟上启动新的指令。

Number of stalls

> 摊位数

Figure C.34 Stalls per FP operation for each major type of FP operation for the SPEC89 FP benchmarks. Except for the divide structural hazards, these data do not depend on the frequency of an operation, only on its latency and the number of cycles before the result is used. The number of stalls from RAW hazards roughly tracks the latency of the FP unit. For example, the average number of stalls per FP add, subtract, or convert is 1.7 cycles, or 56% of the latency (three cycles). Likewise, the average num- ber of stalls for multiplies and divides are 2.8 and 14.2, respectively, or 46% and 59% of the corresponding latency. Structural hazards for divides are rare, because the divide frequency is low.

> 图 C.34 对于 SPEC89 FP 基准测试的每种主要类型 FP 操作的每 FP 操作摊位。除了划分结构危害外，这些数据不取决于操作的频率，仅取决于其潜伏期和结果之前的循环数。原始危害的摊位数量大致跟踪 FP 单元的延迟。例如，每 FP 添加，减法或转换的平均摊位数为 1.7 个周期，或延迟的 56％(三个循环)。同样，乘数和分隔的摊位的平均数量分别为 2.8 和 14.2，或相应潜伏期的 46％和 59％。划分的结构危害很少，因为鸿沟频率很低。

In fact, the pipeline uses the data before the cache hit detection is complete; [Chapter 3](#_bookmark93) discusses how this can be done in more detail.

> 实际上，管道在完成缓存命中检测之前使用数据；[第 3 章](#_bookmark93)讨论了如何更详细地完成此操作。

The function of each stage is as follows:

> 每个阶段的功能如下：

- IF—First half of instruction fetch; PC selection actually happens here, together with initiation of instruction cache access.

> - 如果 - 指令的第一半；PC 选择实际上是在此处进行的，并启动了指令缓存访问。

- IS—Second half of instruction fetch, complete instruction cache access.

> - 是 - 指令的第二半，完整的指令缓存访问。

- RF—Instruction decode and register fetch, hazard checking, and instruction cache hit detection.

> -RF-指导解码和注册提取，危险检查和指令缓存命中检测。

Figure C.35 The stalls occurring for the a simple RISC V FP pipeline for five of the SPEC89 FP benchmarks. The total number of stalls per instruction ranges from 0.65 for su2cor to 1.21 for doduc, with an average of 0.87. FP result stalls dominate in all cases, with an average of 0.71 stalls per instruction, or 82% of the stalled cycles. Com- pares generate an average of 0.1 stalls per instruction and are the second largest source. The divide structural hazard is only significant for doduc. Branch stalls are not accounted for, but would be small.

> 图 C.35 Spial RISC V FP 管道的档位用于 SPEC89 FP 基准中的五个。每指令的摊位总数范围从 SU2COR 的 0.65 到 DODUC 的 1.21，平均为 0.87。在所有情况下，FP 结果失速均占主导地位，平均每个指令降低了 0.71 个失速，占停滞周期的 82％。每个说明平均产生 0.1 个摊位，并且是第二大源。划分结构危害仅对 DODUC 显着。分支机构摊位不计算，但很小。

Figure C.36 The eight-stage pipeline structure of the R4000 uses pipelined instruction and data caches. The pipe stages are labeled and their detailed function is described in the text. The vertical dashed lines represent the stage boundaries as well as the location of pipeline latches. The instruction is actually available at the end of IS, but the tag check is done in RF, while the registers are fetched. Thus, we show the instruction memory as operating through RF. The TC stage is needed for data memory access, because we cannot write the data into the register until we know whether the cache access was a hit or not.

> 图 C.36 R4000 的八个阶段管道结构使用管道指令和数据缓存。管道阶段被标记，其详细功能在文本中描述。垂直虚线表示阶段边界以及管道闩锁的位置。该说明实际上在 IS 的末尾可用，但是标签检查是在 RF 中完成的，而寄存器则被获取。因此，我们将指令内存显示为通过 RF 操作。数据存储器访问需要 TC 阶段，因为我们不能将数据写入寄存器中，直到我们知道缓存访问是否为 hit。

Figure C.37 The structure of the R4000 integer pipeline leads to a x1 load delay. A x1 delay is possible because the data value is available at the end of DS and can be bypassed. If the tag check in TC indicates a miss, the pipeline is backed up a cycle, when the correct data are available.

> 图 C.37 R4000 整数管道的结构导致 X1 负载延迟。X1 延迟是可能的，因为数据值在 DS 的末尾可用，并且可以绕过。如果 TC 中的标签检查指示错过，则在可用的数据可用时，管道将备份一个周期。

- EX—Execution, which includes effective address calculation, ALU operation, and branch-target computation and condition evaluation.

> - 执行，包括有效的地址计算，ALU 操作以及分支目标计算和条件评估。

- DF—Data fetch, first half of data cache access.

> -DF -Data 提取，数据缓存访问的前半部分。

- DS—Second half of data fetch, completion of data cache access.

> -DS-数据获取的一半，数据缓存访问的完成。

- TC—Tag check, to determine whether the data cache access hit.

> -TC- TC 检查，确定数据缓存访问是否命中。

- WB—Write-back for loads and register-register operations.

> -WB - 负载和注册登记操作的写入。

In addition to substantially increasing the amount of forwarding required, this longer-latency pipeline increases both the load and branch delays. [Figure C.37](#_bookmark525) shows that load delays are two cycles, because the data value is available at the end of DS. [Figure C.38](#_bookmark526) shows the shorthand pipeline schedule when a use imme- diately follows a load. It shows that forwarding is required for the result of a load instruction to a destination that is three or four cycles later.

> 除了实质上增加所需的转发量外，此更长的延迟管道还增加了负载和分支延迟。[图 C.37](#_bookmark525) 表明，加载延迟是两个周期，因为数据值在 DS 的末尾可用。[图 C.38](#_bookmark526) 显示了当然遵循负载时的速记管道时间表。它表明，在三到四个周期之后，将负载指令的结果引起的结果是需要转发的。

[Figure C.39](#_bookmark527) shows that the basic branch delay is three cycles, because the branch condition is computed during EX. The MIPS architecture has a single-cycle delayed branch. The R4000 uses a predicted-not-taken strategy for the remaining two cycles of the branch delay. As [Figure C.40](#_bookmark528) shows, untaken branches are simply one-cycle delayed branches, while taken branches have a one-cycle delay slot fol- lowed by two idle cycles. The instruction set provides a branch-likely instruction, which we described earlier and which helps in filling the branch delay slot.

> [图 C.39](#_bookmark527) 表明，基本分支延迟是三个周期，因为在 EX 期间计算分支条件。MIPS 体系结构具有单周期延迟分支。R4000 对分支延迟的其余两个循环使用了预测的未捕获策略。如[图 C.40](#_bookmark528) 所示，未捕获的分支仅仅是单周延迟分支，而被带走的分支具有一个由两个空闲循环的一个周期延迟插槽。该指令集提供了一个很可能分支的指令，我们先前描述了该指令，并有助于填充分支延迟插槽。

Figure C.38 A load instruction followed by an immediate use results in a x1 stall. Normal forwarding paths can be used after two cycles, so the add and sub get the value by forwarding after the stall. The or instruction gets the value from the register file. Because the two instructions after the load could be independent and hence not stall, the bypass can be to instructions that are three or four cycles after the load.

> 图 C.38 载荷指令，然后立即使用导致 X1 失速。两个循环后可以使用正常的转发路径，因此添加和子通过在失速后转发来获得值。或指令从寄存器文件获取值。由于负载后的两个指令可能是独立的，因此也不失速，因此旁路可能是指载后三个或四个周期的说明。

Figure C.39 The basic branch delay is three cycles, because the condition evaluation is performed during EX.

> 图 C.39 基本分支延迟是三个周期，因为在 EX 期间进行了条件评估。

Pipeline interlocks enforce both the x1 branch stall penalty on a taken branch and any data hazard stall that arises from use of a load result. After the R4000, all implementations of MIPS processor made use of dynamic branch prediction.

> 管道互锁对 X1 分支分支的 X1 分支机构进行了惩罚，也可以通过使用负载结果引起的任何数据危险失速。在 R4000 之后，MIPS 处理器的所有实现均使用动态分支预测。

In addition to the increase in stalls for loads and branches, the deeper pipeline increases the number of levels of forwarding for ALU operations. In our RISC V five-stage pipeline, forwarding between two register-register ALU instructions could happen from the ALU/MEM or the MEM/WB registers. In the R4000 pipe- line, there are four possible sources for an ALU bypass: EX/DF, DF/DS, DS/TC, and TC/WB.

> 除了增加负载和分支的摊位外，更深的管道还增加了 ALU 操作的转发水平。在我们的 RISC V 五阶段管道中，可能会从 ALU/MEM 或 MEM/WB 登记册之间进行两个注册登记册 Alu 指示之间的转发。在 R4000 管道中，有四个可能的 ALU 旁路来源：EX/DF，DF/DS，DS/TC 和 TC/WB。

Figure C.40 A taken branch, shown in the top portion of the figure, has a one-cycle delay slot followed by a x1 stall, while an untaken branch, shown in the bottom portion, has simply a one-cycle delay slot. The branch instruc- tion can be an ordinary delayed branch or a branch-likely, which cancels the effect of the instruction in the delay slot if the branch is untaken.

> 图 C.40 在图的顶部显示的一个占据分支，有一个单周延迟插槽，然后是 X1 摊位，而底部显示的未遗产分支仅具有一个单周期延迟插槽。分支指南可以是普通的延迟分支或类似分支，如果分支未被遗忘，则取消延迟插槽中指令的效果。

### The Floating-Point Pipeline

> ###浮点管道

The R4000 floating-point unit consists of three functional units: a floating-point divider, a floating-point multiplier, and a floating-point adder. The adder logic is used on the final step of a multiply or divide. Double-precision FP operations can take from 2 cycles (for a negate) up to 112 cycles (for a square root). In addi- tion, the various units have different initiation rates. The FP functional unit can be thought of as having eight different stages, listed in [Figure C.41](#_bookmark529); these stages are combined in different orders to execute various FP operations.

> R4000 浮点单元由三个功能单元组成：浮点分隔器，浮点乘数和浮点器加法器。加法逻辑用于乘法或划分的最后一步。双精度 FP 操作可以从 2 个循环(负)循环(对于平方根)中。此外，各个单元的起始率不同。FP 功能单元可以被认为具有八个不同阶段，在[图 C.41]中列出(#\_bookmark529);这些阶段以不同的订单合并以执行各种 FP 操作。

There is a single copy of each of these stages, and various instructions may use a stage zeroormoretimes and indifferent orders. [Figure C.42](#_bookmark530) shows the latency, initiation rate, and pipeline stages used by the most common double-precision FP operations.

> 每个阶段中都有一个副本，各种说明可能会使用阶段的零时间和无关紧要的订单。[图 C.42](#_bookmark530) 显示了最常见的双精度 FP 操作使用的潜伏期，启动率和管道阶段。

Figure C.42 The latencies and initiation intervals for the FP operations initiation intervals for the FP operations both depend on the FP unit stages that a given operation must use. The latency values assume that the destination instruction is an FP operation; the latencies are one cycle less when the destination is a store. The pipe stages are shown in the order in which they are used for any operation. The notation S+A indicates a clock cycle in which both the S and A stages are used. The notation D<sup>28</sup> indicates that the D stage is used 28 times in a row.

> 图 C.42 FP 操作的 FP 操作启动间隔的潜伏期和启动间隔都取决于给定操作必须使用的 FP 单元阶段。延迟值假定目标指令是 FP 操作；目的地是商店时，潜伏期较小。管道阶段以用于任何操作的顺序显示。符号 s+a 表示使用 S 和 A 阶段的时钟周期。符号 D <sup> 28 </sup>表示 D 级连续使用 28 次。

From the information in [Figure C.42](#_bookmark530), we can determine whether a sequence of different, independent FP operations can issue without stalling. If the timing of the sequence is such that a conflict occurs for a shared pipeline stage, then a stall will be needed. [Figures C.43–C.46](#_bookmark531) show four common possible two-instruction sequences: a multiply followed by an add, an add followed by a multiply, a divide followed by an add, and an add followed by a divide. The figures show all the inter- esting starting positions for the second instruction and whether that second instruc- tion will issue or stall for each position. Of course, there could be three instructions active, in which case the possibilities for stalls are much higher and the figures more complex.

> 根据[图 C.42](#_bookmark530) 中的信息，我们可以确定一系列不同的，独立的 FP 操作是否可以发行而不会停滞。如果序列的时机使得共享管道阶段发生冲突，则需要一个摊位。[图 C.43 – c.46](#_bookmark531) 显示了四个可能的两个可能的两指导序列：一个乘法，然后是添加，添加，然后是倍数，一个划分，然后是添加，然后加上一个添加划分。这些数字显示了第二个指令的所有关系起始位置，以及第二个指导是否会发出或为每个位置发出失速。当然，可能有三个指示活动，在这种情况下，摊位的可能性要高得多，而且数字更为复杂。

### Performance of the R4000 Pipeline

In this section, we examine the stalls that occur for the SPEC92 benchmarks when running on the R4000 pipeline structure. There are four major causes of pipeline stalls or losses:

> 在本节中，我们检查在 R4000 管道结构上运行时 SPEC92 基准的摊位。管道摊位或损失有四个主要原因：

1. _Load stalls_—Delays arising from the use of a load result one or two cycles after the load

> 1. _ load Stalls_ - 延迟是由加载后一个或两个循环的使用结果产生的。

2. _Branch stalls_—Two-cycle stalls on every taken branch plus unfilled or canceled branch delay slots. The version of the MIPS instruction set implemented in the R4000 supports instructions that predict a branch at compile time and cause the instruction in the branch delay slot to be canceled when the branch behavior differs from the prediction. This makes it easier to fill branch delay slots.

> 2. _分支摊位_-每个距离分支上的两个循环摊位，以及未填充或取消的分支延迟插槽。R4000 中实现的 MIPS 指令集的版本支持指令，这些指令在编译时预测分支，并在分支行为与预测不同时会取消分支延迟插槽中的指令。这使得更容易填充分支延迟插槽。

3. _FP result stalls_—Stalls because of RAW hazards for an FP operand

> 3. _fp 结果失速_-安装，因为 FP 操作数的原始危害

4. _FP structural stalls_—Delays because of issue restrictions arising from conflicts for functional units in the FP pipeline

> 4. _fp 结构失速_-由于 fp 管道中功能单位的冲突引起的问题限制

Figure C.43 An FP multiply issued at clock 0 is followed by a single FP add issued between clocks 1 and 7. The second column indicates whether an instruction of the specified type stalls when it is issued _n_ cycles later, where _n_ is the clock cycle number in which the U stage of the second instruction occurs. The stage or stages that cause a stall are in bold. Note that this table deals with only the interaction between the multiply and _one_ add issued between clocks 1 and 7. In this case, the add will stall if it is issued four or five cycles after the multiply; otherwise, it issues without stalling. Notice that the add will be stalled for two cycles if it issues in cycle 4 because on the next clock cycle it will still conflict with the multiply; if, however, the add issues in cycle 5, it will stall for only 1 clock cycle, because that will eliminate the conflicts.

> 图 C.43 在时钟 0 处发出的 fp 倍数之后是时钟 1 和 7 之间发出的单个 fp 添加。第二列指示指定类型失速的指令在发出 *n* cycles 时是否 *n* 是 *n*，其中 *n* 是 *n* 第二个指令的 U 阶段的循环编号。导致摊位的舞台或阶段以粗体。请注意，该表仅处理时钟 1 和 7 之间发出的倍数之间的相互作用。在这种情况下，如果在乘后发出四个或五个循环，则添加时间将失速；否则，它就不会停滞不前发出。请注意，如果在第 4 周期中发行，则添加的添加时间将停滞不前，因为在下一个时钟周期中，它仍将与倍数发生冲突。但是，如果在第 5 周期中的添加问题，它将仅停滞 1 个时钟周期，因为这将消除冲突。

Figure C.44 A multiply issuing after an add can always proceed without stalling, because the shorter instruction clears the shared pipeline stages before the longer instruction reaches them.

> 图 C.44 添加后始终可以进行乘数发出的倍数发行，而无需停滞，因为较短的说明会在更长的指令到达之前清除共享管道阶段。

[Figure C.47](#_bookmark533) shows the pipeline CPI breakdown for the R4000 pipeline for the 10 SPEC92 benchmarks. [Figure C.48](#_bookmark534) shows the same data but in tabular form.

> [图 C.47](#_bookmark533) 显示了 10 个 SPEC92 基准的 R4000 管道的管道 CPI 分解。[图 C.48](#_bookmark534) 显示了相同的数据，但以表格形式显示。

From the data in [Figures C.47](#_bookmark533) and [C.48](#_bookmark534), we can see the penalty of the deeper pipelining. The R4000’s pipeline has much longer branch delays than the classic five-stage pipeline. The longer branch delay substantially increases the cycles spent on branches, especially for the integer programs with a higher branch frequency. This is the reason that almost all subsequent processors with moderate to deep pipelines (8–16 stages are typical today) employ dynamic branch predictors.

> 从[图 C.47](#_bookmark533) 和 [c.48](#_bookmark534) 中的数据中，我们可以看到更深的管道的罚款。R4000 的管道比经典的五阶段管道的分支延迟更长。较长的分支延迟大大增加了在分支上花费的周期，尤其是对于具有较高分支频率的整数程序。这就是几乎所有随后的处理器中等到深度管道(如今典型的 8-16 个阶段)的原因。

Figure C.45 An FP divide can cause a stall for an add that starts near the end of the divide. The divide starts at cycle 0 and completes at cycle 35; the last 10 cycles of the divide are shown. Because the divide makes heavy use of the rounding hardware needed by the add, it stalls an add that starts in any of cycles 28–33. Notice that the add starting in cycle 28 will be stalled until cycle 36. If the add started right after the divide, it would not conflict, because the add could complete before the divide needed the shared stages, just as we saw in [Figure C.44](#_bookmark532) for a multiply and add. As in the earlier figure, this example assumes _exactly_ one add that reaches the U stage between clock cycles 26 and 35.

> 图 C.45 FP 鸿沟可能会导致添加的档位，该添加距离在鸿沟的末端附近。鸿沟从周期 0 开始，并在 35 周期完成；显示了鸿沟的最后 10 个周期。由于鸿沟大量使用了添加所需的圆形硬件，因此它停滞了一个从任何周期开始的 28-33。请注意，在第 28 周期开始的添加开始直到周期 36。如果添加在分隔之后开始，则不会发生冲突，因为添加可以在需要共享阶段之前完成，就像我们在图 C 中所见一样.44](#*bookmark532)用于乘以并添加。如前图所示，此示例假设\_exactly *添加到达时钟周期 26 和 35 之间的 U 级。

Figure C.46 A double-precision add is followed by a double-precision divide. If the divide starts one cycle after the add, the divide stalls, but after that there is no conflict.

> 图 C.46 双重精确的添加后，其次是双精度鸿沟。如果划分在添加后开始一个周期，则分隔阶段，但之后没有冲突。

An interesting effect observed in the FP programs is that the latency of the FP functional units leads to more result stalls than the structural hazards, which arise both from the initiation interval limitations and from conflicts for functional units from different FP instructions. Thus, reducing the latency of FP operations should be the first target, rather than more pipelining or replication of the functional units. Of course, reducing the latency would probably increase the structural stalls, because many potential structural stalls are hidden behind data hazards.

> 在 FP 程序中观察到的一个有趣的效果是，FP 功能单元的潜伏期比结构性危害更大，这既是由于启动间隔限制和来自不同 FP 指令的功能单元的冲突而产生的。因此，减少 FP 操作的潜伏期应该是第一个目标，而不是更多的功能单元的管道复制或复制。当然，减少潜伏期可能会增加结构性摊位，因为许多潜在的结构摊位都隐藏在数据危险后面。

Figure C.48 The total pipeline CPI and the contributions of the four major sources of stalls are shown. The major contributors are FP result stalls (both for branches and for FP inputs) and branch stalls, with loads and FP structural stalls adding less.

> 图 C.48 显示了总管道 CPI 和四个主要摊位来源的贡献。主要的贡献者是 FP 结果失速(分支和 FP 输入)和分支摊位，负载和 FP 结构失速较少。
