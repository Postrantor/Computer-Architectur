## Computer Architecture of Warehouse-Scale Computers

> ##仓库规模计算机的计算机架构

Networks are the connective tissue that binds 50,000–100,000 servers together. Analogous to the memory hierarchy of [Chapter 2](#_bookmark46), WSCs use a hierarchy of networks. [Figure 6.5](#_bookmark278) shows one example. Ideally, the combined network would provide nearly the performance of a custom high-end switch for 100,000 servers at about the cost per port of a commodity switch designed for 50 servers. As we will see in [Section 6.6](#cross-cutting-issues-3), networks for WSCs are an area of active innovation.

> 网络是将 50,000-100,000 台服务器结合在一起的结缔组织。类似于[第 2 章](#_ bookmark46)的内存层次结构，WSC 使用网络层次结构。[图 6.5](#_ bookmark278)显示了一个示例。理想情况下，组合网络将以大约为 50 台服务器设计的商品开关的费用，几乎为 100,000 台服务器提供自定义高端开关的性能。正如我们将在[第 6.6 节](＃交叉切割 - 发行-3)中看到的那样，WSC 的网络是主动创新领域。

The structure that holds the servers is a rack. Although the width of racks varies per WSC—some are the classic 19-in. wide rack; others are two or three times wider—the height tends to be no higher than 6–7 ft since people must service them. Such a rack has roughly 40–80 servers. Because it is often convenient to connect the network cables at the top of the rack, this switch is commonly called a _Top of Rack_ (_ToR_) switch. (Some WSCs have racks with multiple ToR switches.) Typically, the bandwidth within the rack is much higher than between racks, so it matters less where the software places the sender and the receiver if they are within the same rack. This flexibility is ideal from a software perspective.

> 保持服务器的结构是机架。尽管架子的宽度每 WSC 各不相同，但有些是经典的 19 英寸。宽架；其他人则宽两次或三倍 - 由于人们必须为其服务，因此高度往往不超过 6-7 英尺。这样的机架大约有 40-80 台服务器。因为通常将网络电缆连接在机架顶部的网络电缆通常很方便，所以此开关通常称为 rack_(_tor_)开关的_top。(某些 WSC 具有带有多个 TOR 开关的机架。)通常，机架内的带宽远高于机架之间的架子，因此如果软件在同一机架内，则软件将发件人和接收器放置的位置较小。从软件的角度来看，这种灵活性是理想的选择。

![](./media/image310.png)

> ！[](./ Media/image310.png)

Figure 6.5 Hierarchy of switches in a WSC. Based on Figure 1.1 in Barroso, L.A., Clidaras, J., Ho€lzle, U., 2013. The datacenter as a computer: an introduction to the design of warehouse-scale machines. Synth. Lect. Comput. Architect. 8 (3), 1–154.

> 图 6.5 WSC 中开关的层次结构。根据图 1.1 的图 1.1，洛杉矶巴罗索，Clidaras，J.，Ho€lzle，U.，2013 年。作为计算机的数据中心：仓库规模机器设计简介。合成器。lect。计算。工程师。8(3)，1-154。

These switches often offer 4–16 uplinks, which leave the rack to go to the next higher switch in the network hierarchy. Thus, the bandwidth leaving the rack is 6–24 times smaller than the bandwidth within the rack. This ratio is called _oversubscription_. However, large oversubscription means programmers must be aware of the performance consequences when placing senders and receivers in different racks. This increased software-scheduling burden is another argument for network switches designed specifically for the data center.

> 这些开关通常提供 4-16 个上行链路，这使机架进入网络层次结构中的下一个更高的开关。因此，离开机架的带宽比机架内的带宽小 6-24 倍。该比率称为_overSubscription_。但是，大量超额订购意味着程序员必须意识到将发件人和接收器放在不同机架中时的性能后果。对于专门为数据中心设计的网络交换机而言，这种增加的软件安排负担是另一个论点。

The switch that connects an array of racks is considerably more expensive than the ToR switch. This cost is due in part because of the higher connectivity and in part because the bandwidth through the switch must be much greater to reduce the oversubscription problem. [Barroso et al. (2013)](#_bookmark925) reported that a switch having 10 times the _bisection bandwidth_—basically, the worst-case internal bandwidth—of a rack switch costs about 100 times as much. One reason is that the cost of switch bandwidth for _n_ ports can grow as _n_<sup>2</sup>. [Sections 6.6](#cross-cutting-issues-3) and [6.7](#_bookmark300) describe the networking above the ToR switch in great detail.

> 连接架子阵列的开关比 TOR 开关要贵得多。这一成本部分是由于连通性较高，部分原因是通过开关的带宽必须更大得多以减少超级标准问题。[Barroso 等。(2013)](#_ bookmark925)报告说，一个开关具有 10 倍_bisection 带宽_的开关 - 基本上是最糟糕的内部带宽 - 机架开关的成本约为 100 倍。一个原因之一是，_n_端口的开关带宽的成本可以随着_n_ <sup> 2 </sup>而增长。[第 6.6 节](＃cross-Cutting-issues-3)和[6.7](#_ bookmark300)在 Tor 开关上方描述网络上方的网络。

### Storage

> ＃＃＃ 贮存

A natural design is to fill a rack with servers, minus whatever space needed for the switches. This design leaves open the question of where the storage is placed. From a hardware construction perspective, the simplest solution would be to include disks inside the rack and rely on Ethernet connectivity for access to information on the disks of remote servers. An expensive alternative would be to use network-attached storage (NAS), perhaps over a storage network like InfiniBand. In the past, WSCs generally relied on local disks and provided storage software that handled connectivity and dependability. For example, GFS used local disks and maintained replicas to overcome dependability problems. This redundancy covered not only local disk failures but also power failures to racks and to whole clusters. The flexibility of GFS’s eventual consistency lowers the cost of keeping replicas consistent, which also reduces the network bandwidth requirements of the storage system.

> 自然设计是用服务器填充机架，减去开关所需的任何空间。此设计留下了放置位置的问题。从硬件构造的角度来看，最简单的解决方案是在机架内包含磁盘，并依靠以太网连接以访问远程服务器磁盘上的信息。一个昂贵的替代方法是使用网络连接存储(NAS)，也许是在像 Infiniband 这样的存储网络上使用。过去，WSC 通常依靠本地磁盘，并提供了处理连接性和可靠性的存储软件。例如，GF 使用本地磁盘并维护复制品来克服可靠性问题。这种冗余不仅涵盖了本地磁盘故障，而且涵盖了机架和整个簇的功率故障。GFS 最终一致性的灵活性降低了保持副本一致的成本，这也降低了存储系统的网络带宽要求。

Today the storage options are considerably more varied. Although some racks are balanced in terms of servers and disks, as in the past, there may also be racks deployed without local disks and some racks loaded with disks. System software today often uses RAID-like error correction codes to lower the storage cost of dependability.

> 如今，存储选项的变化要多得多。尽管有些机架在服务器和磁盘方面保持平衡，但与过去一样，也可能会在没有本地磁盘和一些装有磁盘的机架上部署机架。今天的系统软件通常使用类似 RAID 的错误校正代码来降低可靠性的存储成本。

Be aware that there is confusion about the term _cluster_ when talking about the architecture of a WSC. Using the definition in [Section 6.1](#introduction-4), a WSC is just an extremely large cluster. In contrast, [Barroso et al. (2013)](#_bookmark925) used the term cluster to mean the next-sized grouping of computers, containing many racks. In this chapter, to avoid confusion, we will use the term _array_ to mean a large collection of racks organized in rows, preserving the original definition of the word cluster to represent anything from a collection of networked computers within a rack to an entire warehouse full of networked computers.

> 请注意，在谈论 WSC 的体系结构时，术语_Cluster_一词存在混乱。使用[第 6.1 节](＃ruciest-4)中的定义，WSC 只是一个非常大的群集。相反，[Barroso 等。(2013)](#_ bookmark925)使用术语群集表示次要的计算机分组，其中包含许多机架。在本章中，为了避免混乱，我们将使用术语_array_来表示大量的行架，并保留单词群集的原始定义，以表示从机架中的网络计算机集合到整个仓库的任何内容网络计算机。

### WSC Memory Hierarchy

> ### WSC 内存层次结构

[Figure 6.6](#_bookmark279) shows the latency, bandwidth, and capacity of memory hierarchy inside a WSC, and [Figure 6.7](#_bookmark280) shows the same data visually. These figures are based on the following assumptions ([Barroso et al., 2013](#_bookmark925)):

> [图 6.6](#_ bookmark279)在 WSC 内显示了内存层次结构的延迟，带宽和容量，[图 6.7](#_ bookmark280)在视觉上显示了相同的数据。这些数字基于以下假设([Barroso 等，2013](#_ bookmark925))：

Figure 6.6 Latency, bandwidth, and capacity of the memory hierarchy of a WSC (Barroso et al., 2013). [Figure 6.7](#_bookmark280) plots this same information.

> 图 6.6 WSC 的记忆层次结构的潜伏期，带宽和容量(Barroso 等，2013)。[图 6.7](#_ bookmark280)绘制相同的信息。

Figure 6.7 Graph of latency, bandwidth, and capacity of the memory hierarchy of a WSC for data in [Figure 6.6](#_bookmark279) ([Barroso et al., 2013](#_bookmark925)).

> 图 6.7 在[图 6.6](#_ bookmark279)中，WSC 的记忆层次结构的延迟，带宽和容量的图表([Barroso et al。，2013](#_ bookmark925))。

Each server contains 16 GiB of memory with a 100-ns access time and transfers at 20 GB/s, 128 GiB of Flash with 100-μs latency and transfers at 1 GB/s, and 2 TB of disk that offer a 10-ms access time and transfer at 200 MB/s. There are two sockets per board, and they share one 1 Gbit/s Ethernet port.

> 每台服务器包含 16 个吉布的内存，具有 100 ns 的访问时间，以 20 GB/s 的速度转移，128 GIB 闪光灯带有 100μmS 延迟和 1 GB/s 的转移，以及 2 tb 的磁盘，提供 10 毫秒访问时间并以 200 MB/s 的速度转移。每个板有两个插座，它们共享一个 1 Gbit/s 以太网端口。

In this example, every pair of racks includes one rack switch and holds 80 servers. Networking software plus switch overhead increases the latency to DRAM to 100 μs and the disk access latency to 11 ms. Thus, the total storage capacity of a rack is roughly 1 TB of DRAM, 20 TB of Flash, and 160 TB of disk storage. The 1 Gbit/s Ethernet limits the remote bandwidth to DRAM, Flash, or disk within the rack to 100 MB/s.

> 在此示例中，每对机架都包含一个机架开关，并容纳 80 台服务器。网络软件加开关开销将 DRAM 的延迟增加到 100μs，并且磁盘访问延迟到 11 毫秒。因此，机架的总存储容量大约为 1 tb 的 DRAM，20 TB 的闪光灯和 160 TB 的磁盘存储。1 GBIT/S 以太网将远程带宽限制在机架中的 DRAM，FLASH 或磁盘为 100 MB/s。

The array is 30 racks, so storage capacity of an array goes up by a factor of 30: 30 TB of DRAM, 600 TB of Flash, and 4.8 PB of disk. The array switch hardware and software increases latency to DRAM within an array to 500 μs, to 600 μs for Flash, and disk latency to 12 ms. The bandwidth of the array switch limits the remote bandwidth to either array DRAM, array Flash, or array disk to 10 MB/s.

> 阵列为 30 个架子，因此阵列的存储容量增加了 30：30 tb 的 DRAM，600 TB 的闪光灯和 4.8 pb 的磁盘。阵列开关硬件和软件将阵列内的延迟延迟至 500μs，闪光灯为 600μs，磁盘延迟至 12 毫秒。阵列开关的带宽将远程带宽限制为阵列 DRAM，ARRAY FLASH 或 ARRAY 磁盘至 10 MB/s。

[Figures 6.6](#_bookmark279) and [6.7](#_bookmark280) show that network overhead dramatically increases latency between local DRAM and Flash, rack DRAM and Flash, or array DRAM and Flash, but all still have more than 10 times better latency than accessing the local disk. The network collapses the difference in bandwidth between rack DRAM, Flash, and disk and between array DRAM, Flash, and disk.

> [图 6.6](#_ bookmark279)和[6.7](#_ bookmark280)表明，网络高架大大增加了本地 DRAM 和 Flash，Rack Dram 和 Flash 或 Array Dram 和 Array Dram 和 Flash 之间的延迟而不是访问本地磁盘。该网络折叠了机架 DRAM，FLASH 和磁盘之间的带宽差，以及数组 DRAM，Flash 和 Disk 之间的带宽差异。

The WSC needs 40 arrays to reach 100,000 servers, so there is one more level in the networking hierarchy. [Figure 6.8](#_bookmark281) shows the conventional Layer 3 routers to connect the arrays together and to the Internet.

> WSC 需要 40 个阵列才能达到 100,000 台服务器，因此网络层次结构中还有一个级别。[图 6.8](#_ bookmark281)显示了传统的层 3 个路由器，将数组连接到 Internet。

Most applications fit into a single array within a WSC. Those that need more than one array use _sharding_ or _partitioning_, meaning that the dataset is split into independent pieces and then distributed to different arrays. As an analogy, it’s like picking up registration packets for a conference with one person handling names A to M and another doing N to Z. Operations on the whole dataset are sent to the servers hosting the pieces, and the results are coalesced by the client computer.

> 大多数应用程序适合 WSC 内的单个数组。那些需要多个数组的人使用_sharding_或_ partitioning_，这意味着数据集分为独立的零件，然后分布在不同的数组中。就像一个类比一样，这就像在会议上拾起注册包，其中一个人将名称 a 到 m，另一个处理 n 到 z。整个数据集的操作都发送到托管零件的服务器，结果由客户合并电脑。

Example What is the average memory latency assuming that 90% of accesses are local to the server, 9% are outside the server but within the rack, and 1% are outside the rack but within the array?

> 示例假设服务器本地 90％的访问权限，9％在服务器外，但在机架内，有 1％在机架外，但是在数组中，则有 90％的内存延迟是多少？

![](./media/image311.png)

> ！[](./ Media/image311.png)

Thus, for block transfers outside a single server, it doesn’t even matter whether the data are in memory or on disk because the rack switch and array switch are the bottlenecks. These performance limits affect the design of WSC software and inspire the need for higher-performance switches (see [Section 6.6](#cross-cutting-issues-3)).

> 因此，对于单个服务器之外的块传输，由于机架开关和阵列开关是瓶颈，数据在内存中还是在磁盘上都无关紧要。这些性能限制会影响 WSC 软件的设计，并激发了对高性能开关的需求(请参阅[第 6.6 节](＃Cross-Cutting-cutting-issues-3))。

Figure 6.8 A Layer 3 network used to link arrays together and to the Internet ([Greenberg et al., 2009](#_bookmark955)). A load balancer monitors how busy a set of servers is and directs traffic to the less loaded ones to try to keep the servers approximately equally utilized. Another option is to use a separate _border router_ to connect the Internet to the data center Layer 3 switches. As we will see in [Section 6.6](#cross-cutting-issues-3), many modern WSCs have abandoned the conventional layered networking stack of traditional switches.

> 图 6.8 第 3 层网络用于将数组链接到 Internet([Greenberg et al。，2009](#_ bookmark955))。负载平衡器监视了一组服务器的繁忙，并将流量引导到负载较低的服务器，以试图使服务器近似使用。另一个选项是使用单独的_border 路由器_将 Internet 连接到数据中心层 3 开关。正如我们将在[第 6.6 节](＃交叉切割 - 发行-3)中看到的那样，许多现代 WSC 已放弃了传统开关的传统分层网络堆栈。

Although these examples are educational, note that computers and networking equipment can be much larger and faster than these examples from 2013 (see [Section 6.7](#_bookmark300)). Servers are being deployed in 2017 with 256–1024 GiB of DRAM, and recent switches have reduced delays to only 300 ns per hop.

> 尽管这些示例是教育意义的，但请注意，计算机和网络设备可能比 2013 年的这些示例更大，更快(请参阅[第 6.7 节](#_ bookmark300))。服务器在 2017 年以 256-1024 GIB 的 DRAM 部署，最近的开关已将延迟减少到每跳 300 ns。

Given the architecture of the IT equipment, we are now ready to see how to house, power, and cool it and to discuss the cost to build and operate the whole WSC, as compared to just the IT equipment within it.

> 鉴于 IT 设备的体系结构，与仅在其中的 IT 设备相比，我们现在准备了解如何容纳，电源和冷却它，并讨论整个 WSC 的成本。
