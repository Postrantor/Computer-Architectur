## Scheduling and Structuring Code for Parallelism

> ##平行性调度和结构代码

We have already seen that one compiler technique, loop unrolling, is useful to uncover parallelism among instructions by creating longer sequences of straight- line code. There are two other important techniques that have been developed for this purpose: _software pipelining_ and _trace scheduling_.

> 我们已经看到，通过创建更长的直线代码序列来揭示指令之间的并行性。为此目的开发了另外两种重要的技术：_software Pipelining_和_trace Scheduling_。

### Software Pipelining: Symbolic Loop Unrolling

> ###软件管道：符号循环展开

_Software pipelining_ is a technique for reorganizing loops such that each iteration in the software-pipelined code is made from instructions chosen from different iter- ations of the original loop. This approach is most easily understood by looking at the scheduled code for the unrolled loop, which appeared in the example in Section 2.2. The scheduler in this example essentially interleaves instructions from different loop iterations, so as to separate the dependent instructions that occur within a single loop iteration. By choosing instructions from different iterations, dependent computations are separated from one another by an entire loop body, increasing the possibility that the unrolled loop can be scheduled without stalls.

> _software Pipelining_是一种用于重组循环的技术，以便根据来自原始循环的不同迭代所选择的说明制定软件封面代码中的每次迭代。通过查看展开的循环的计划代码，该方法最容易理解，该代码出现在第 2.2 节中的示例中。该示例中的调度程序实质上是从不同的循环迭代中交织的指令，以分离单个循环迭代中发生的相关指令。通过从不同的迭代中选择指令，依赖计算通过整个循环主体彼此分开，从而增加了可以在没有失速的情况下安排展开的环路的可能性。

A software-pipelined loop interleaves instructions from different iterations without unrolling the loop, as illustrated in [Figure H.1](#_bookmark721). This technique is the soft- ware counterpart to what Tomasulo’s algorithm does in hardware. The software- pipelined loop for the earlier example would contain one load, one add, and one store, each from a different iteration. There is also some start-up code that is needed before the loop begins as well as code to finish up after the loop is completed. We will ignore these in this discussion, for simplicity.

> 如[图 h.1](#_ bookmark721)所示，软件中间环路交织了不同迭代中的指示，而无需展开循环。该技术与 Tomasulo 的算法在硬件中所做的相当。早期示例的软件管道循环将包含一个负载，一个添加和一个商店，每个迭代都来自不同的迭代。在循环开始之前，还需要一些启动代码以及在循环完成后完成的代码。为简单起见，我们将在讨论中忽略这些讨论。

1. Iteration

> 1.迭代

2. Iteration

> 2.迭代

3. Iteration

> 3.迭代

4. Iteration

> 4.迭代

Figure H.1 A software-pipelined loop chooses instructions from different loop iter- ations, thus separating the dependent instructions within one iteration of the original loop. The start-up and finish-up code will correspond to the portions above and below the software-pipelined iteration.

> 图 H.1 一个软件中间环路从不同的循环迭代中选择说明，从而将原始循环的一个迭代中的相关指令分开。启动和完成代码将对应于软件二级迭代上方和下方的部分。

Example Show a software-pipelined version of this loop, which increments all the elements of an array whose starting address is in R1 by the contents of F2:

> 示例显示了此循环的软件封面版本，该版本会递增一个数组的所有元素，其起始地址在 R1 中由 F2 的内容：

_Answer_ Software pipelining symbolically unrolls the loop and then selects instructions from each iteration. Since the unrolling is symbolic, the loop overhead instructions (the DADDUI and BNE) need not be replicated. Here’s the body of the unrolled loop without overhead instructions, highlighting the instructions taken from each iteration:

> _ANSWER_软件管道上的管道象征性展开循环，然后从每次迭代中选择指令。由于展开是象征性的，因此无需复制循环开销指令(DADDUI 和 BNE)。这是未经开销说明的展开环的正文，突出了每次迭代的说明：

The selected instructions from different iterations are then put together in the loop with the loop control instructions:

> 然后，通过循环控制说明将来自不同迭代的选定说明放在循环中：

This loop can be run at a rate of 5 cycles per result, ignoring the start-up and clean- up portions, and assuming that DADDUI is scheduled before the ADD.D and that the L.D instruction, with an adjusted offset, is placed in the branch delay slot. Because the load and store are separated by offsets of 16 (two iterations), the loop should run for two fewer iterations. Notice that the reuse of registers (e.g., F4, F0, and R1) requires the hardware to avoid the write after read (WAR) hazards that would occur in the loop. This hazard should not be a problem in this case, since no data-dependent stalls should occur.

> 该循环可以以每个结果的 5 个循环速率运行，忽略启动和清洁部分，并假设 DADDUI 是在 add.d 之前安排的，并且具有调整后的偏移量的 L.D 指令被放入分支延迟插槽。由于负载和存储量被 16(两个迭代)的偏移分开，因此循环应进行两次较少的迭代。请注意，寄存器的重复使用(例如 F4，F0 和 R1)需要硬件以避免在循环中发生的(战争)危害后避免写入。在这种情况下，这种危害不应该是一个问题，因为不应发生任何依赖数据的摊位。

By looking at the unrolled version we can see what the start-up code and finish-up code will need to be. For start-up, we will need to execute any instructions that cor- respond to iteration 1 and 2 that will not be executed. These instructions are the L.D for iterations 1 and 2 and the ADD.D for iteration 1. For the finish-up code, we need to execute any instructions that will not be executed in the final two iterations. These include the ADD.D for the last iteration and the S.D for the last two iterations.

> 通过查看展开的版本，我们可以看到启动代码和完成代码需要什么。对于启动，我们将需要执行对不执行的迭代 1 和 2 响应的任何指令。这些说明是迭代 1 和 2 的 L.D，以及迭代 1 的 add.D。对于完成代码，我们需要执行在最后两个迭代中不会执行的任何说明。其中包括最后两次迭代的最后两个迭代的 add.d。

Register management in software-pipelined loops can be tricky. The previous example is not too hard since the registers that are written on one loop iteration are read on the next. In other cases, we may need to increase the number of iterations between when we issue an instruction and when the result is used. This increase is required when there are a small number of instructions in the loop body and the latencies are large. In such cases, a combination of software pipelining and loop unrolling is needed.

> 在软件中循环中的注册管理可能很棘手。上一个示例并不难，因为在下一个循环迭代中写的寄存器将在下一个循环迭代中读取。在其他情况下，我们可能需要增加发布指令和使用结果时之间的迭代次数。当循环主体中有少量说明并且潜伏期很大时，需要这种增加。在这种情况下，需要组合软件管道和循环展开。

Software pipelining can be thought of as _symbolic_ loop unrolling. Indeed, some of the algorithms for software pipelining use loop-unrolling algorithms to figure out how to software-pipeline the loop. The major advantage of software pipelining over straight loop unrolling is that software pipelining consumes less code space. Software pipelining and loop unrolling, in addition to yielding a better scheduled inner loop, each reduce a different type of overhead. Loop unrolling reduces the overhead of the loop—the branch and counter update code. Software pipelining reduces the time when the loop is not running at peak speed to once per loop at the beginning and end. If we unroll a loop that does 100 iterations a constant num- ber of times, say, 4, we pay the overhead 100/4 25 times—every time the inner unrolled loop is initiated. [Figure H.2](#_bookmark722) shows this behavior graphically. Because these techniques attack two different types of overhead, the best performance can come from doing both. In practice, compilation using software pipelining is quite difficult for several reasons: Many loops require significant transformation before they can be software pipelined, the trade-offs in terms of overhead versus efficiency of the software-pipelined loop are complex, and the issue of register management creates additional complexities. To help deal with the last two of these issues, the IA-64 added extensive hardware sport for software pipelining. Although this hardware can make it more efficient to apply software pipelining, it does not eliminate the need for complex compiler support, or the need to make difficult decisions about the best way to compile a loop.

> 软件管道可以被认为是_symbolic_循环展开。实际上，一些用于软件管道使用循环量算法的算法来弄清楚如何软件循环软件。软件管道上的主要优点比直线循环展开的主要优点是，管道管道的软件消耗了更少的代码空间。软件管道和循环展开，除了产生更好的内部循环外，每种循环都减少了不同类型的开销。循环展开会减少循环的开销 - 分支和计数器更新代码。管道管道的软件将循环在开始和结束时不以峰值速度运行的时间每循环一次。如果我们展开执行 100 次迭代的循环，例如 4，我们支付了 100/4 25 次的间接费用 - 每次启动内部展开的循环。[图 H.2](#_ bookmark722)以图形方式显示了此行为。由于这些技术攻击了两种不同类型的开销，因此最好的性能可能来自两者。实际上，由于几个原因，使用软件管道汇编的汇编非常困难：许多循环需要进行重大转换，然后才能进行软件管道，而权衡的额外循环与软件专用循环的效率很复杂，并且寄存器的问题是管理层创造了其他复杂性。为了帮助解决这些问题的最后两个问题，IA-64 添加了用于软件管道的广泛硬件运动。尽管此硬件可以使应用软件管道式应用更有效，但它并不能消除对复杂编译器支持的需求，也没有必要对编译循环的最佳方法做出艰难的决定。

![](./media/image738.png)

Figure H.2 The execution pattern for (a) a software-pipelined loop and (b) an unrolled loop. The shaded areas are the times when the loop is not running with max- imum overlap or parallelism among instructions. This occurs once at the beginning and once at the end for the software-pipelined loop. For the unrolled loop it occurs _m/n_ times if the loop has a total of _m_ iterations and is unrolled _n_ times. Each block represents an unroll of _n_ iterations. Increasing the number of unrollings will reduce the start-up and clean-up overhead. The overhead of one iteration overlaps with the overhead of the next, thereby reducing the impact. The total area under the polygonal region in each case will be the same, since the total number of operations is just the execution rate multiplied by the time.

> 图 H.2(a)软件流行循环的执行模式和(b)一个展开的循环。阴影区域是循环在指令之间没有最大重叠或并行性的时间。这一次是在开始时发生的一次，并且在末尾发生了软件式循环的末端。对于展开的循环，如果循环总共有_m_迭代，并且是展开的_n_ times，则会发生_m/n_ times。每个块代表_n_迭代的展开。增加展开数量将减少启动和清理开销。一个迭代的开销与下一个迭代的开销重叠，从而减少了影响。在每种情况下，多边形区域下的总面积将相同，因为操作的总数只是执行率乘以时间。

### Global Code Scheduling

> ###全球代码调度

In Section 3.2 we examined the use of loop unrolling and code scheduling to improve ILP. The techniques in Section 3.2 work well when the loop body is straight-line code, since the resulting unrolled loop looks like a single basic block. Similarly, software pipelining works well when the body is a single basic block, since it is easier to find the repeatable schedule. When the body of an unrolled loop contains internal control flow, however, scheduling the code is much more com- plex. In general, effective scheduling of a loop body with internal control flow will require moving instructions across branches, which is global code scheduling. In this section, we first examine the challenge and limitations of global code scheduling. In [Section H.4](#hardware-support-for-exposing-parallelism-predicated-instructions) we examine hardware support for eliminating control flow within an inner loop, then we examine two compiler techniques that can be used when eliminating the control flow is not a viable approach.

> 在第 3.2 节中，我们检查了循环展开和代码调度以改善 ILP 的使用。当循环主体是直线代码时，第 3.2 节中的技术效果很好，因为所得的展开循环看起来像是一个基本块。同样，当人体是一个基本块时，软件管道上的运输效果很好，因为更容易找到可重复的时间表。但是，当展开环的主体包含内部控制流程时，安排代码的安排更为综合。通常，具有内部控制流的循环主体的有效调度将需要跨分支的移动说明，即全球代码调度。在本节中，我们首先检查全球代码调度的挑战和局限性。在[h.4](＃硬件 - 支持 - 公平 - 平行 - 预测的指导)中，我们检查了硬件支持以消除内部循环中的控制流，然后我们检查两种编译器技术，可以在消除控件时使用这些编译器技术流程不是一种可行的方法。

Global code scheduling aims to compact a code fragment with internal control structure into the shortest possible sequence that preserves the data and control dependences. The data dependences force a partial order on operations, while the control dependences dictate instructions across which code cannot be easily moved. Data dependences are overcome by unrolling and, in the case of memory operations, using dependence analysis to determine if two references refer to the same address. Finding the shortest possible sequence for a piece of code means finding the shortest sequence for the _critical path_, which is the longest sequence of dependent instructions.

> 全局代码调度旨在将内部控制结构的代码片段压缩为最短的序列，以保留数据和控制依赖性。数据依赖性迫使部分顺序对操作，而控制依赖性决定了无法轻易移动代码的指令。数据依赖是通过展开和记忆操作来克服的，使用依赖分析来确定两个引用是否参考相同地址。找到一块代码的最短序列意味着找到_ clitagion 路径_的最短序列，这是依赖指令的最长序列。

Control dependences arising from loop branches are reduced by unrolling. Global code scheduling can reduce the effect of control dependences arising from conditional nonloop branches by moving code. Since moving code across branches will often affect the frequency of execution of such code, effectively using global code motion requires estimates of the relative frequency of different paths. Although global code motion cannot guarantee faster code, if the frequency infor- mation is accurate, the compiler can determine whether such code movement is likely to lead to faster code.

> 循环分支产生的控制依赖性通过展开减少。全局代码调度可以通过移动代码来减少条件非环分支产生的控制依赖的效果。由于跨分支的移动代码通常会影响执行此类代码的频率，因此有效地使用全局代码运动需要估计不同路径的相对频率。尽管全局代码运动无法保证更快的代码，但是如果频率信息准确，则编译器可以确定该代码移动是否可能导致代码更快。

Global code motion is important since many inner loops contain conditional statements. [Figure H.3](#_bookmark723) shows a typical code fragment, which may be thought of as an iteration of an unrolled loop, and highlights the more common control flow.

> 全局代码运动很重要，因为许多内部循环都包含条件语句。[图 H.3](#_ bookmark723)显示了一个典型的代码片段，可以将其视为展开环的迭代，并突出显示更常见的控制流。

Figure H.3 A code fragment and the common path shaded with gray. Moving the assignments to B or C requires a more complex analysis than for straight-line code. In this section we focus on scheduling this code segment efficiently without hardware assistance. Predication or conditional instructions, which we discuss in the next section, provide another way to schedule this code.

> 图 H.3 代码片段和灰色阴影的常见路径。将作业转移到 B 或 C 需要比直线代码更复杂的分析。在本节中，我们将重点放在无需硬件帮助的情况下有效地安排此代码段。我们在下一节中讨论的预测或条件说明提供了另一种安排此代码的方法。

Effectively scheduling this code could require that we move the assignments to B and C to earlier in the execution sequence, before the test of A. Such global code motion must satisfy a set of constraints to be legal. In addition, the movement of the code associated with B, unlike that associated with C, is speculative: It will speed the computation up only when the path containing the code would be taken.

> 有效地安排此代码可能要求我们将作业转移到执行顺序中的 B 和 C 之前，然后在 A.进行测试之前，必须满足一组合法的约束。此外，与与 C 相关的代码相关的代码的移动是推测性的：只有在采用包含代码的路径时，它才会加快计算的速度。

To perform the movement of B, we must ensure that neither the data flow nor the exception behavior is changed. Compilers avoid changing the exception behav- ior by not moving certain classes of instructions, such as memory references, that can cause exceptions. In [Section H.5](#hardware-support-for-compiler-speculation), we will see how hardware support allows for more opportunities for speculative code motion and removes control dependences. Although such enhanced support for speculation can make it possible to explore more opportunities, the difficulty of choosing how to best compile the code remains complex.

> 要执行 B 的运动，我们必须确保数据流或异常行为都不会改变。编译器避免通过不移动某些类别的指令(例如内存引用)来改变异常行为，而这些指令可能会导致异常。在[H.5 节](＃硬件支持 - 编译器规范)中，我们将看到硬件支持如何为投机代码运动提供更多机会，并消除控制依赖。尽管这种增强的对投机的支持可以使探索更多机会成为可能，但是选择如何最好地编译代码的困难仍然是复杂的。

How can the compiler ensure that the assignments to B and C can be moved without affecting the data flow? To see what’s involved, let’s look at a typical code generation sequence for the flowchart in [Figure H.3](#_bookmark723). Assuming that the addresses for A, B, C are in R1, R2, and R3, respectively, here is such a sequence:

> 编译器如何确保可以在不影响数据流的情况下移动 B 和 C 的分配？要查看所涉及的内容，让我们看一下[图 H.3]中流程图的典型代码生成序列(#_ bookmark723)。假设 A，B，C 的地址分别在 R1，R2 和 R3 中，这是这样的序列：

Let’s first consider the problem of moving the assignment to B to before the BNEZ instruction. Call the last instruction to assign to B before the if statement

> 首先，让我们考虑将作业转移到 BNEZ 指令之前的问题。在 if 语句之前致电最后的指令将分配给 b

_i_. If B is referenced before it is assigned either in code segment X or after the if statement, call the referencing instruction _j._ If there is such an instruction _j_, then moving the assignment to B will change the data flow of the program. In particular, moving the assignment to B will cause _j_ to become data dependent on the moved version of the assignment to B rather than on _i_, on which _j_ originally depended. You could imagine more clever schemes to allow B to be moved even when the value is used: For example, in the first case, we could make a shadow copy of B before the if statement and use that shadow copy in X. Such schemes are usu- ally avoided, both because they are complex to implement and because they will

> _一世_。如果在代码段 X 中分配 B 或 IF 语句之后，请引用 B，请调用引用指令_J._如果有这样的指令_J_，则将作业转移到 B 将更改程序的数据流。特别是，将分配转移到 b 将导致_j_成为数据取决于分配的移动版本，而不是_i_，_j_最初依赖于_j_。您可以想象，即使使用该值，也可以允许 B 移动 B 的更多聪明方案：例如，在第一种情况下，我们可以在 if 语句之前制作 B 的阴影副本，并在 X 中使用该阴影副本。此类方案为避免使用，既是因为它们都可以实施复杂，并且因为他们会

slow down the program if the trace selected is not optimal and the operations end up requiring additional instructions to execute.

> 如果所选的跟踪不是最佳的，并且操作最终需要执行其他说明，请慢慢降低程序。

Moving the assignment to C up to before the first branch requires two steps. First, the assignment is moved over the join point of the else part into the portion corre- sponding to the then part. This movement makes the instructions for C control dependent on the branch and means that they will not execute if the else path, which is the infrequent path, is chosen. Hence, instructions that were data dependent on the assignment to C, and which execute after this code fragment, will be affected. To ensure the correct value is computed for such instructions, a copy is made of the instructions that compute and assign to C on the else path. Second, we can move C from the then part of the branch across the branch condition, if it does not affect any data flow into the branch condition. If C is moved to before the if test, the copy of C in the else branch can usually be eliminated, since it will be redundant.

> 将作业转移到 c 之前，在第一个分支需要两个步骤之前。首先，将作业移至 Else 零件的联接点中，以置于当时的部分。该动作使 C 控制的指令取决于分支，意味着如果选择了不经常路径的其他路径，它们将不会执行。因此，数据取决于分配给 C 的指令以及此代码片段后执行的指令将受到影响。为了确保为此类说明计算正确的值，由计算和分配给 C 上 C 上的 C 的指令制定副本。其次，如果不影响任何数据流进入分支条件，我们可以从分支条件的当时的部分移动 C。如果 C 在 IF 测试之前移动，则通常可以消除 C 中 C 的副本，因为它将是多余的。

We can see from this example that global code scheduling is subject to many constraints. This observation is what led designers to provide hardware support to make such code motion easier, and [Sections H.4](#hardware-support-for-exposing-parallelism-predicated-instructions) and [H.5](#hardware-support-for-compiler-speculation) explores such support in detail.

> 从这个示例中我们可以看到，全局代码调度受到许多约束。该观察结果是导致设计师提供硬件支持以使此类代码运动更加容易的原因，[＃H.4](＃硬件 - 支持 - 公平 - 平行式 - 预测 - 预测的结构)和[H.5](＃Hardware--支持 - 补偿器规范)详细探讨了此类支持。

Global code scheduling also requires complex trade-offs to make code motion decisions. For example, assuming that the assignment to B can be moved before the conditional branch (possibly with some compensation code on the alternative branch), will this movement make the code run faster? The answer is, possibly! Similarly, moving the copies of C into the if and else branches makes the code initially bigger! Only if the compiler can successfully move the computation across the if test will there be a likely benefit.

> 全球代码调度还需要复杂的权衡来做出代码运动决策。例如，假设对 B 的分配可以在有条件的分支之前移动(可能在替代分支上有一些补偿代码)，那么该运动是否会使代码运行更快？答案可能是！同样，将 C 的副本移至 IF 及其他分支机构最初使代码更大！只有编译器可以成功地通过 IF 测试移动计算，可能会有可能受益。

Consider the factors that the compiler would have to consider in moving the computation and assignment of B:

> 考虑编译器在移动 B 的计算和分配时必须考虑的因素：

- What are the relative execution frequencies of the then case and the else case in the branch? If the then case ismuch morefrequent, the codemotion may bebeneficial. If not, it is less likely, although not impossible, to consider moving the code.

> - 当时的情况和分支中的其他情况的相对执行频率是什么？如果当时的情况是更频繁的，则可能会呈现。如果没有，尽管不是不可能，但不可能考虑移动代码。

- What is the cost of executing the computation and assignment to B above the branch? It may be that there are a number of empty instruction issue slots in the code above the branch and that the instructions for B can be placed into these slots that would otherwise go empty. This opportunity makes the computation of B “free” at least to first order.

> - 执行计算和分配给 B 上方 B 上方的成本是多少？可能是分支上方的代码中有许多空的指令问题插槽，并且可以将 B 的指令放入这些插槽中，否则可以空白。这个机会至少将 B“免费”计算为一阶。

- How will the movement of B change the execution time for the then case? If B is at the start of the critical path for the then case, moving it may be highly beneficial.

> - B 的运动将如何改变当时的情况的执行时间？如果 b 处于当时的情况下的关键路径的开始，则将其移动可能是非常有益的。

- Is B the best code fragment that can be moved above the branch? How does it compare with moving C or other statements within the then case?

> - B 是可以在分支上方移动的最佳代码片段吗？它与当时的情况下的 C 或其他语句相比如何？

- What is the cost of the compensation code that may be necessary for the else case? How effectively can this code be scheduled, and what is its impact on execution time?

> - 赔偿代码的成本是什么？该代码的安排如何有效，对执行时间有什么影响？

As we can see from this _partial_ list, global code scheduling is an extremely complex problem. The trade-offs depend on many factors, and individual decisions to globally schedule instructions are highly interdependent. Even choos- ing which instructions to start considering as candidates for global code motion is complex!

> 从这个_partial_列表中可以看到，全局代码调度是一个极其复杂的问题。权衡取决于许多因素，并且个人决策全球安排说明是高度相互依存的。即使选择哪些指令开始考虑作为全球代码运动的候选人也很复杂！

To try to simplify this process, several different methods for global code sched- uling have been developed. The two methods we briefly explore here rely on a simple principle: Focus the attention of the compiler on a straight-line code seg- ment representing what is estimated to be the most frequently executed code path. Unrolling is used to generate the straight-line code, but, of course, the complexity arises in how conditional branches are handled. In both cases, they are effectively straightened by choosing and scheduling the most frequent path.

> 为了简化此过程，已经开发了几种全局代码调度的方法。我们在这里简要探索的两种方法取决于一个简单的原则：将编译器的注意力集中在直线代码段上，代表估计是最常见的代码路径。展开用于生成直线代码，但是，当然，复杂性在处理条件分支的处理方式中产生。在这两种情况下，它们都可以通过选择和调度最常见的路径来有效拉直。

##### _Trace Scheduling: Focusing on the Critical Path_

> ##### _trace 调度：关注关键路径_

Trace scheduling is useful for processors with a large number of issues per clock, where conditional or predicated execution (see [Section H.4](#hardware-support-for-exposing-parallelism-predicated-instructions)) is inappropriate or unsupported, and where simple loop unrolling may not be sufficient by itself to uncover enough ILP to keep the processor busy. Trace scheduling is a way to orga- nize the global code motion process, so as to simplify the code scheduling by incur- ring the costs of possible code motion on the less frequent paths. Because it can generate _significant_ overheads on the designated infrequent path, it is best used where profile information indicates significant differences in frequency between different paths and where the profile information is highly indicative of program behavior independent of the input. Of course, this limits its effective applicability to certain classes of programs.

> 跟踪调度对于每个时钟有大量问题的处理器很有用，有条件或预性执行(请参阅[[＃H.4](＃硬件 - 支持 - 公平 - 平行 - 平行式预测 - 构造))是不合适的或不合适的，或者不合适的，而且，在简单的循环展开本身可能不足以发现足够的 ILP 以使处理器忙碌。跟踪调度是一种实现全局代码运动过程的方法，以简化代码调度，从而在较不频繁的路径上查找可能的代码运动的成本。因为它可以在指定的不频繁路径上生成_simentific_的开销，因此最好使用剖面信息表示不同路径之间的频率显着差异，而该配置文件信息高度指示了程序行为与输入无关。当然，这将其有效适用于某些类别的程序。

There are two steps to trace scheduling. The first step, called _trace selection,_ tries to find a likely sequence of basic blocks whose operations will be put together into a smaller number of instructions; this sequence is called a _trace_. Loop unrol- ling is used to generate long traces, since loop branches are taken with high prob- ability. Additionally, by using static branch prediction, other conditional branches are also chosen as taken or not taken, so that the resultant trace is a straight-line sequence resulting from concatenating many basic blocks. If, for example, the pro- gram fragment shown in [Figure H.3](#_bookmark723) corresponds to an inner loop with the highlighted path being much more frequent, and the loop were unwound four times, the primary trace would consist of four copies of the shaded portion of the program, as shown in [Figure H.4](#_bookmark724).

> 有两个步骤可以追踪调度。第一步称为_ Trace 选择，_试图找到一系列可能的基本块序列，其操作将被放在较少数量的指令中；此序列称为_trace_。循环分配用于生成长轨迹，因为循环分支具有高概率。此外，通过使用静态分支预测，还选择其他条件分支作为采取或不采取的选择，因此所得的迹线是由串联许多基本块引起的直线序列。例如，如果[图 H.3](#_ bookmark723)中所示的程序片段对应于一个内环，突出显示的路径更为频繁，并且环路四次解开，则主要轨迹将包含程序的阴影部分的四个副本，如[图 H.4](#_ bookmark724)所示。

Once a trace is selected, the second process, called _trace compaction_, tries to squeeze the trace into a small number of wide instructions. Trace compaction is code scheduling; hence, it attempts to move operations as early as it can in a sequence (trace), packing the operations into as few wide instructions (or issue packets) as possible.

> 一旦选择了迹线，第二个过程称为_ Trace Compaction_，试图将迹线挤压成少量的宽阔指令。跟踪压实是代码调度；因此，它试图在序列(跟踪)中尽可能尽可能地移动操作，将操作包装到尽可能少的指令中(或发行数据包)。

The advantage of the trace scheduling approach is that it simplifies the deci- sions concerning global code motion. In particular, branches are viewed as jumps into or out of the selected trace, which is assumed to be the most probable path.

> 跟踪调度方法的优点是，它简化了有关全局代码运动的决定。特别是，分支被视为跳入或从所选痕迹中跳出来，这被认为是最可能的路径。

Figure H.4 This trace is obtained by assuming that the program fragment in [Figure H.3](#_bookmark723) is the inner loop and unwinding it four times, treating the shaded portion in [Figure H.3](#_bookmark723) as the likely path. The trace exits correspond to jumps off the frequent path, and the trace entrances correspond to returns to the trace.

> 图 H.4 通过假设[图 H.3]中的程序片段(#_ bookmark723)是内部循环，并将其放开四次，从[图 H.3](#_ bookmark723)中处理阴影部分，从而获得了此痕迹。作为可能的路径。痕量退出对应于从频繁路径上跳下的，痕迹入口对应于返回到迹线。

When code is moved across such trace entry and exit points, additional bookkeep- ing code will often be needed on the entry or exit point. The key assumption is that the trace is so much more probable than the alternatives that the cost of the book- keeping code need not be a deciding factor: If an instruction can be moved and thereby make the main trace execute faster, it is moved.

> 当在此类跟踪输入点和出口点上移动代码时，在条目或出口点上通常需要其他簿记代码。关键的假设是，该跟踪比替代方案更有可能，以至于书本保存代码的成本不必是决定因素：如果可以移动指令，从而使主跟踪执行更快，则将移动。

Although trace scheduling has been successfully applied to scientific code with its intensive loops and accurate profile data, it remains unclear whether this approach is suitable for programs that are less simply characterized and less loop intensive. In such programs, the significant overheads of compensation code may make trace scheduling an unattractive approach, or, at best, its effective use will be extremely complex for the compiler.

> 尽管痕量调度已通过其密集的循环和准确的配置数据成功地应用于科学代码，但尚不清楚这种方法是否适用于不太简单的特征和较少循环密集型的程序。在这样的计划中，薪酬代码的重要开销可能会使跟踪计划成为一种没有吸引力的方法，或者充其量对于编译器而言，其有效使用将非常复杂。

##### _Superblocks_

> ##### _superblocks_

One of the major drawbacks of trace scheduling is that the entries and exits into the middle of the trace cause significant complications, requiring the compiler to gen- erate and track the compensation code and often making it difficult to assess the cost of such code. _Superblocks_ are formed by a process similar to that used for traces, but are a form of extended basic blocks, which are restricted to a single entry point but allow multiple exits.

> 痕量调度的主要缺点之一是，进入痕量中间的条目和退出会导致重大并发症，要求编译器对薪酬代码进行综述和跟踪，并经常使得难以评估此类代码的成本。_superblocks_由类似于痕迹的过程形成，但是扩展基本块的一种形式，该过程仅限于单个入口点，但允许多个出口。

Because superblocks have only a single entry point, compacting a superblock is easier than compacting a trace since only code motion across an exit need be considered. In our earlier example, we would form superblocks that contained only one entrance; hence, moving C would be easier. Furthermore, in loops that have a single loop exit based on a count (for example, a for loop with no loop exit other than the loop termination condition), the resulting superblocks have only one exit as well as one entrance. Such blocks can then be scheduled more easily.

> 由于超级块只有一个入口点，因此压实超级块要比压实跟踪更容易，因为只需要考虑跨出口的代码运动。在我们之前的示例中，我们将形成仅包含一个入口的超级块。因此，移动 C 会更容易。此外，在具有基于计数的单个循环出口的循环中(例如，除循环终止条件以外没有循环出口的循环)，所得的超块只有一个出口和一个入口。然后可以更轻松地安排此类块。

How can a superblock with only one entrance be constructed? The answer is to use _tail duplication_ to create a separate block that corresponds to the portion of the trace after the entry. In our previous example, each unrolling of the loop would create an exit from the superblock to a residual loop that handles the remaining iterations. [Figure H.5](#_bookmark725) shows the superblock structure if the code fragment from [Figure H.3](#_bookmark723) is treated as the body of an inner loop and unrolled four times. The residual loop handles any iterations that occur if the superblock is exited, which, in turn, occurs when the unpredicted path is selected. If the expected frequency of the residual loop were still high, a superblock could be created for that loop as well. The superblock approach reduces the complexity of bookkeeping and sched- uling versus the more general trace generation approach but may enlarge code size more than a trace-based approach. Like trace scheduling, superblock scheduling may be most appropriate when other techniques (e.g., if conversion) fail. Even in such cases, assessing the cost of code duplication may limit the usefulness of the approach and will certainly complicate the compilation process.

> 如何仅构建一个入口的超级块？答案是使用_tail Replication_创建一个单独的块，该块与条目后的跟踪部分相对应。在我们的上一个示例中，循环的每个展开都会创建从超级块出口到处理剩余迭代的残差循环。[图 H.5](#_ bookmark725)显示了[图 H.3](#_ bookmark723)的代码片段是否被视为内部环的主体和四次展开的主体。残留循环处理如果退出超级块，则发生任何迭代，而这又在选择不预测的路径时发生。如果残差环路的预期频率仍然很高，则也可以为该循环创建一个超块。SuperBlock 方法降低了簿记和调度的复杂性与更通用的痕量生成方法的复杂性，但比基于跟踪的方法更大的代码大小可能会扩大代码大小。像跟踪调度一样，当其他技术(例如，如果转换)失败时，超级封锁调度可能最合适。即使在这种情况下，评估代码复制的成本也可能限制方法的实用性，并且肯定会使编译过程变得复杂。

Loop unrolling, software pipelining, trace scheduling, and superblock sched- uling all aim at trying to increase the amount of ILP that can be exploited by a pro- cessor issuing more than one instruction on every clock cycle. The effectiveness of

> 循环展开，软件管道调整，跟踪调度和超级屏幕调度都旨在尝试增加在每个时钟周期内发出多个指令的专业人士可以利用的 ILP 的数量。有效性

Figure H.5 This superblock results from unrolling the code in [Figure H.3](#_bookmark723) four times and creating a superblock.

> 图 H.5 此超块由[图 H.3](#_ bookmark723)中的代码传输四次并创建一个超块而引起的。

each of these techniques and their suitability for various architectural approaches are among the hottest topics being actively pursued by researchers and designers of high-speed processors.

> 这些技术中的每一种及其对各种建筑方法的适用性都是高速处理器的研究人员和设计师积极追求的最热主题之一。
