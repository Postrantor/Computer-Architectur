## The Development of SIMD Supercomputers, Vector Computers, Multimedia SIMD Instruction Extensions, and Graphical Processor Units ([Chapter 4](#_bookmark165))

> ## SIMD 超级计算机，矢量计算机，多媒体 SIMD 指令扩展程序和图形处理器单元的开发（[[第 4 章]（#_ bookmark165））

In this historical section, we start with perhaps the most infamous supercomputer, the Illiac IV, as a representative of the early SIMD (Single Instruction, Multiple Data) architectures and then move to perhaps the most famous supercomputer, the Cray-1, as a representative of vector architectures. The next step is Multimedia SIMD Extensions, which got its name in part due to an advertising campaign involving the “Bunny People,” a disco-dancing set of workers in cleansuits on a semiconductor fabrication line. We conclude with the history of GPUs, which is not quite as colorful.

> 在这个历史部分中，我们也许是最臭名昭著的超级计算机 Illiac IV，作为早期 SIMD（单个指令，多个数据）架构的代表，然后移至最著名的超级计算机 Cray-1 作为一个矢量体系结构的代表。下一步是 Multimedia Simd Extensions，其名称部分是由于广告活动涉及“ Bunny People”，这是一套迪斯科舞蹈，这是一套在半导体制造线上穿着清洁套件的工人。我们以 GPU 的历史结束，这并不那么丰富多彩。

### SIMD Supercomputers

> ### SIMD 超级计算机

_The cost of a general multiprocessor is, however, very high and further design options were considered which would decrease the cost without seriously degrad- ing the power or efficiency of the system. The options consist of recentralizing one of the three major components._ … _Centralizing the [control unit] gives rise to the basic organization of [an]_ … _array processor such as the Illiac IV._

> _一般多处理器的成本非常高，并且考虑了进一步的设计选择，这将降低成本，而不会严重降低系统的功率或效率。选项包括最近和三个主要组件之一。

Bouknight et al. [1972]

> Bouknight 等。[1972]

… _with Iliac IV, programming the machine was very difficult and the architecture probably was not very well suited to some of the applications we were trying to run. The key idea was that I did not think we had a very good match in Iliac IV between applications and architecture._

> …_与 iLiac iv，编程机器非常困难，并且该体系结构可能不太适合我们试图运行的某些应用程序。关键的想法是，我认为我们在应用程序和架构之间的 ILIAC IV 中没有很好的匹配。

David Kuck _Software designer for the Illiac IV and early pioneer in parallel software_

> David Kuck Software 设计师的 ILIAC IV 和平行软件早期先驱

David Kuck _An oral history conducted in 1991 by Andrew Goldstein, IEEE History Center, New Brunswick, N.J._

> 大卫·库克（David Kuck）_ 1991 年由安德鲁·戈德斯坦（Andrew Goldstein），新不伦瑞克省 IEEE 历史中心进行的安德鲁·戈德斯坦（Andrew Goldstein）

The SIMD model was one of the earliest models of parallel computing, dating back to the first large-scale multiprocessor, the Illiac IV. Rather than pipelining the data computation as in vector architectures, these machines had an array of functional units; hence, they might be considered array processors.

> SIMD 模型是最早的并行计算模型之一，其历史可以追溯到第一个大规模多处理器 Illiac IV。这些机器没有像向量体系结构那样管道数据计算，而是具有一系列功能单元。因此，它们可能被视为数组处理器。

The earliest ideas on SIMD-style computers are from Unger [1958] and Slot- nick, Borck, and McReynolds [1962]. Slotnick’s Solomon design formed the basis of the Illiac IV, perhaps the most infamous of the supercomputer projects. Although successful in pushing several technologies that proved useful in later projects, it failed as a computer. Costs escalated from the $8 million estimate in 1966 to $31 million by 1972, despite construction of only a quarter of the planned multiprocessor. (In 2011 dollars, that was an increase from $54M to $152M.) Actual performance was at best 15 MFLOPS versus initial predictions of 1000 MFLOPS for the full system [Hord 1982]. Delivered to NASA Ames Research in 1972, the computer required three more years of engineering before it was usable. These events slowed investigation of SIMD, but Danny Hillis [1985] resus- citated this style in the Connection Machine, which had 65,536 1-bit processors. The basic trade-off in SIMD multiprocessors is performance of a processor ver- sus number of processors. SIMD supercomputers of the 1980s emphasized a large degree of parallelism over performance of the individual processors. The Connec- tion Multiprocessor 2, for example, offered 65,536 single-bit-wide processors, while the Illiac IV planned for 64 64-bit processors. Massively parallel SIMD mul- tiprocessors relied on interconnection or communication networks to exchange data between processing elements.

> SIMD 风格计算机的最早想法来自 Unger [1958]和 Slot-Nick，Borck 和 McReynolds [1962]。Slotnick 的所罗门设计构成了 Illiac IV 的基础，这也许是超级计算机项目中最臭名昭著的。尽管成功推动了几种在后来项目中有用的技术，但它是计算机的失败。尽管建造了计划的多处理器，但成本从 1966 年的 800 万美元估计升至 1972 年的 3100 万美元。（在 2011 年的美元中，这是从 5400 万美元增加到 1.52 亿美元。）实际性能最多为 15 mflops，而整个系统的 1000 mflops 的初始预测[Hord 1982]。该计算机于 1972 年交付给 NASA AMES Research，需要在可用的工程上再进行三年的工程。这些事件减慢了对 SIMD 的调查，但 Danny Hillis [1985]在连接机中恢复了这种风格，该风格有 65,536 个 1 位处理器。SIMD 多处理器中的基本权衡是处理器数量的处理器的性能。1980 年代的 SIMD 超级计算机强调了大量的平行性，而不是单个处理器的性能。例如，连接多处理器 2 提供了 65,536 个单位宽的处理器，而 Illiac IV 计划为 64 位 64 位处理器计划。大规模并行的 Simd Mul-tip 处理器依靠互连或通信网络来交换处理元素之间的数据。

After being resurrected in the 1980s, first by Thinking Machines and then by MasPar, the SIMD model faded away as supercomputers for two main reasons. First, it is too inflexible. A number of important problems were not data parallel, and the architecture did not scale down in a competitive fashion; that is, small-scale SIMD multiprocessors often have worse cost-performance compared with that of the alternatives. Second, SIMD could not take advantage of the tremendous per- formance and cost advantages of SISD (Single Instruction, Single Data) micropro- cessor technology of the 1980s, which was doubling in performance every 18 months. Instead of leveraging this low-cost technology, designers of SIMD multiprocessors had to build custom processors for their multiprocessors.

> 在 1980 年代复活，首先是通过思考机器，然后是 Maspar 复活，Simd 模型由于两个主要原因而逐渐消失为超级计算机。首先，它太僵化了。许多重要的问题不是平行数据，并且体系结构并未以竞争方式缩小。也就是说，与替代方案相比，小规模的 SIMD 多处理器通常具有较差的成本效果。其次，SIMD 无法利用 1980 年代 SISD（单个指令，单个数据）微型技术的巨大表现和成本优势，这每 18 个月的性能每增加一倍。Simd 多处理器的设计师不必利用这种低成本的技术，而是为其多处理器构建自定义处理器。

### Vector Computers

> ###矢量计算机

_I’m certainly not inventing vector processors. There are three kinds that I know of existing today. They are represented by the Illiac-IV, the (CDC) Star processor, and the TI (ASC) processor. Those three were all pioneering processors._ … _One of the problems of being a pioneer is you always make mistakes and I never, never want to be a pioneer. It’s always best to come second when you can look at the mistakes the pioneers made._

> _我当然不会发明矢量处理器。我今天知道三种。它们由 Illiac-IV，（CDC）星形处理器和 Ti（ASC）处理器表示。这三个都是开创性的处理器。当您可以查看先驱者犯的错误时，最好是第二位。

Seymour Cray _Public lecture at Lawrence Livermore Laboratories on the introduction of the Cray-1 (1976)_

> Seymour cray _ Public 在 Lawrence Livermore 实验室的演讲，关于 Cray-1 的引入（1976）_

The first vector processors were the Control Data Corporation (CDC) STAR-100 (see Hintz and Tate [1972]) and the Texas Instruments ASC (see Watson [1972]), both announced in 1972. Both were memory-memory vector processors. They had relatively slow scalar units—the STAR used the same units for scalars and vectors—making the scalar pipeline extremely deep. Both processors had high start-up overhead and worked on vectors of several hundred to several thousand elements. The crossover between scalar and vector could be over 50 elements. It appears that not enough attention was paid to the role of Amdahl’s law on these two processors.

> 第一个矢量处理器是控制数据公司（CDC）Star-100（参见 Hintz and Tate [1972]）和 Texas Instruments ASC（见 Watson [1972]），两者均在 1972 年宣布。两者都是存储器模式矢量处理器。他们具有相对较慢的标量单元 - 恒星使用相同的单元作为标量和向量，使标量管道非常深。两个处理器都有很高的启动开销，并在数百到几千个元素的媒介上工作。标量和向量之间的交叉可能超过 50 个元素。看来，对这两个处理器的法律对 Amdahl 定律的作用没有足够的关注。

Seymour Cray, who worked on the 6600 and the 7600 at CDC, founded Cray Research and introduced the Cray-1 in 1976 (see Russell [1978]). The Cray-1 used a vector-register architecture to lower start-up overhead significantly and to reduce memory bandwidth requirements. He also had efficient support for non-unit stride and invented chaining. Most importantly, the Cray-1 was the fastest scalar proces- sor in the world at that time. This matching of good scalar and vector performance was probably the most significant factor in making the Cray-1 a success. Some customers bought the processor primarily for its outstanding scalar performance. Many subsequent vector processors are based on the architecture of this first commercially successful vector processor. Baskett and Keller [1977] provided a good evaluation of the Cray-1.

> 西摩·克雷（Seymour Cray）在疾病预防控制中心（CDC）创立了 Cray Research，并在 1976 年介绍了 Cray-1（见 Russell [1978]）。Cray-1 使用矢量注册体系结构可显着降低启动开销，并减少内存带宽要求。他还有效地支持了非单元大步并发明了链接。最重要的是，cray-1 是当时世界上最快的标量法。良好的标量和向量性能的这种匹配可能是使 Cray-1 成功的最重要因素。一些客户主要是因为其出色的标量性能购买了处理器。随后的许多矢量处理器基于此第一个商业成功的矢量处理器的体系结构。Baskett 和 Keller [1977]对 Cray-1 进行了良好的评估。

In 1981, CDC started shipping the CYBER 205 (see Lincoln [1982]). The 205 had the same basic architecture as the STAR but offered improved performance all around as well as expandability of the vector unit with up to four lanes, each with multiple functional units and a wide load-store pipe that provided multiple words per clock. The peak performance of the CYBER 205 greatly exceeded the perfor- mance of the Cray-1; however, on real programs, the performance difference was much smaller.

> 1981 年，CDC 开始运送网络 205（见 Lincoln [1982]）。205 具有与星星相同的基本体系结构，但提供了提高的性能以及最多四个车道的向量单元的扩展性，每个车道都有多个功能单元和一个宽的负载店管，每个时钟都提供多个单词。网络 205 的峰值性能极大地超过了 cray-1 的表现。但是，在实际程序上，性能差异要小得多。

In 1983, Cray Research shipped the first Cray X-MP (see Chen [1983]). With an improved clock rate (9.5 ns versus 12.5 ns on the Cray-1), better chaining support (allowing vector operations with RAW dependencies to operate in paral- lel), and multiple memory pipelines, this processor maintained the Cray Research lead in supercomputers. The Cray-2, a completely new design configurable with up to four processors, was introduced later. A major feature of the Cray-2 was the use of DRAM, which made it possible to have very large memories at the time. The first Cray-2, with its 256M word (64-bit words) memory, contained more memory than the total of all the Cray machines shipped to that point! The Cray-2 had a much faster clock than the X-MP, but also much deeper pipelines; however, it lacked chaining, had enormous memory latency, and had only one memory pipe per pro- cessor. In general, the Cray-2 was only faster than the Cray X-MP on problems that required its very large main memory.

> 1983 年，克雷研究（Cray Research）发了第一个 Cray X-MP（见 Chen [1983]）。以提高的时钟速率（Cray-1 上的 9.5 ns 对 12.5 ns），更好的链接支持（允许具有原始依赖性的矢量操作以在副层中运行），并且多个内存管道，该处理器在超级计算机中维持 CRAY 研究领导者。Cray-2 是一种全新的设计，可配置多达四个处理器，稍后引入。Cray-2 的主要特征是使用 DRAM，这使得当时有很大的记忆。第一个 cray-2 含有 256m 单词（64 位单词）内存，包含的内存比所有运送到该点的瓦斯机器的总数都要多！Cray-2 的时钟速度比 X-MP 快得多，但管道更深。但是，它缺乏链接，具有巨大的记忆潜伏期，并且每个专业人员只有一个记忆管。通常，Cray-2 仅比 Cray X-MP 更快，因为问题需要大量的主内存。

That same year, processor vendors from Japan entered the supercomputer mar- ketplace. First were the Fujitsu VP100 and VP200 (see Miura and Uchida [1983]), and later came the Hitachi S810 and the NEC SX/2 (see Watanabe [1987]). These processors proved to be close to the Cray X-MP in performance. In general, these three processors had much higher peak performance than the Cray X-MP. How- ever, because of large start-up overhead, their typical performance was often lower than that of the Cray X-MP. The Cray X-MP favored a multiple-processor approach, first offering a two-processor version and later a four-processor version. In contrast, the three Japanese processors had expandable vector capabilities.

> 同年，来自日本的处理器供应商进入了超级计算机。首先是 Fujitsu VP100 和 VP200（参见 Miura 和 Uchida [1983]），后来是日立 S810 和 NEC SX/2（参见 Watanabe [1987]）。这些处理器被证明与 Cray X-MP 的性能接近。通常，这三个处理器的峰值性能比 Cray X-MP 高得多。但是，由于大型启动开销，它们的典型性能通常低于 Cray X-MP。Cray X-MP 偏爱多处理方法，首先提供两处理器版本，然后提供四处理器版本。相比之下，这三个日本处理器具有可扩展的矢量功能。

In 1988, Cray Research introduced the Cray Y-MP—a bigger and faster ver- sion of the X-MP. The Y-MP allowed up to eight processors and lowered the cycle time to 6 ns. With a full complement of eight processors, the Y-MP was generally the fastest supercomputer, though the single-processor Japanese supercomputers could be faster than a one-processor Y-MP. In late 1989, Cray Research was split into two companies, both aimed at building high-end processors available in the early 1990s. Seymour Cray headed the spin-off, Cray Computer Corporation, until its demise in 1995. Their initial processor, the Cray-3, was to be implemented in gallium arsenide, but they were unable to develop a reliable and cost-effective implementation technology. Shortly before his tragic death in a car accident in 1996, Seymour Cray started yet another company to develop high-performance systems but this time using commodity components.

> 1988 年，Cray Research 介绍了 Cray Y-MP，这是 X-MP 的更大，更快的范围。Y-MP 最多允许八个处理器，并将周期时间降低到 6 ns。凭借八个处理器的完整补充，Y-MP 通常是最快的超级计算机，尽管单处理器日本超级计算机可能比单处理器 Y-MP 更快。1989 年末，Cray Research 分为两家公司，均旨在建造 1990 年代初期的高端处理器。西摩·克雷（Seymour Cray）领导着衍生电脑公司（Cray Computer Corporation），直到 1995 年去世。其最初的处理器 Cray-3 将在 Arsenide 中实施，但他们无法开发可靠且具有成本效益的实施技术。西摩·克雷（Seymour Cray）在 1996 年发生的一场车祸中悲惨死亡前不久，创立了另一家开发高性能系统的公司，但这次使用商品组件。

Cray Research focused on the C90, a new high-end processor with up to 16 processors and a clock rate of 240 MHz. This processor was delivered in 1991. In 1993, Cray Research introduced their first highly parallel processor, the T3D, employing up to 2048 Digital Alpha21064 microprocessors. In 1995, they announced the availability of both a new low-end vector machine, the J90, and a high-end machine, the T90. The T90 was much like the C90, but with a clock that was twice as fast (460 MHz), using three-dimensional packaging and optical clock distribution.

> Cray Research 的重点是 C90，这是一个新的高端处理器，最多 16 个处理器，时钟速率为 240 MHz。该处理器于 1991 年交付。1993 年，Cray Research 介绍了他们的第一个高度平行的处理器 T3D，该处理器采用了 2048 年的数字 Alpha21064 微处理器。1995 年，他们宣布了新的低端矢量机，J90 和高端机器 T90 的可用性。T90 非常类似于 C90，但使用三维包装和光学时钟分布，时钟的速度是两倍（460 MHz）。

In 1995, Cray Research was acquired by Silicon Graphics. In 1998, it released the SV1 system, which grafted considerably faster CMOS processors onto the J90 memory system. It also added a data cache for vectors to each CPU to help meet the increased memory bandwidth demands. Silicon Graphics sold Cray Research to Tera Computer in 2000, and the joint company was renamed Cray Inc.

> 1995 年，Cray 研究由 Silicon Graphics 获得。1998 年，它发布了 SV1 系统，该系统将 CMOS 处理器移植到 J90 存储器系统上。它还为每个 CPU 添加了向量的数据缓存，以帮助满足增加的内存带宽需求。Silicon Graphics 于 2000 年将 Cray Research 出售给 TERA Computer，并将联合公司更名为 Cray Inc.。

The Japanese supercomputer makers continued to evolve their designs. In 2001, the NEC SX/5 was generally held to be the fastest available vector super- computer, with 16 lanes clocking at 312 MHz and with up to 16 processors sharing the same memory. The NEC SX/6, released in 2001, was the first commercial single-chip vector microprocessor, integrating an out-of-order quad-issue superscalar processor, scalar instruction and data caches, and an eight-lane vector unit on a single die [Kitagawa et al. 2003]. The Earth Simulator is constructed from 640 nodes connected with a full crossbar, where each node comprises eight SX-6 vector microprocessors sharing a local memory. The SX-8, released in 2004, reduces the number of lanes to four but increases the vector clock rate to 2 GHz. The scalar unit runs at a slower 1 GHz clock rate, a common pattern in vector machines where the lack of hazards simplifies the use of deeper pipelines in the vector unit.

> 日本超级计算机制造商继续发展他们的设计。在 2001 年，NEC SX/5 通常被认为是最快的矢量超级计算机，16 个车道为 312 MHz，最多 16 个处理器共享相同的内存。NEC SX/6 于 2001 年发行，是第一个商业单芯片矢量微处理器，它集成了一个零件 Quad-Iss SuperScalar 处理器，标量指令和数据缓存，以及一个八车道矢量单元[Kitagawa 等。2003]。地球模拟器是由与完整横杆连接的 640 个节点构造的，每个节点包含八个 SX-6 矢量微处理器共享本地内存。SX-8 于 2004 年发布，将车道的数量减少到四个，但将矢量时钟速率提高到 2 GHz。标量单元以较慢的 1 GHz 时钟速率运行，这是向量机器中常见的模式，缺乏危险可以简化矢量单元中更深的管道的使用。

In 2002, Cray Inc. released the X1 based on a completely new vector ISA. The X1 SSP processor chip integrates an out-of-order superscalar with scalar caches running at 400 MHz and a two-lane vector unit running at 800 MHz. When four SSP chips are ganged together to form an MSP, the resulting peak vector perfor- mance of 12.8 GFLOPS is competitive with the contemporary NEC SX machines. The X1E enhancement, delivered in 2004, raises the clock rates to 565 and 1130 MHz, respectively. Many of the ideas were borrowed from the Cray T3E design, which is a MIMD (Multiple Instruction, Multiple Data) computer that uses off-the- shelf microprocessors. X1 has a new instruction set with a larger number of reg- isters and with memory distributed locally with the processor in shared address space. The out-of-order scalar unit and vector units are decoupled, so that the scalar unit can get ahead of the vector unit. Vectors become shorter when the data are blocked to utilize the MSP caches, which is not a good match to an eight-lane vec- tor unit. To handle these shorter vectors, each processor with just two vector lanes can work on a different loop.

> 2002 年，克雷公司（Cray Inc.）基于全新的矢量 ISA 发布了 X1。X1 SSP 处理器芯片集成了一个级别超量表，标量库以 400 MHz 运行，并以 800 MHz 运行的两车道矢量单元。当将四个 SSP 芯片组合在一起以形成 MSP 时，由 12.8 Gflops 的最终峰值向量的穿孔与当代 NEC SX 机器具有竞争力。2004 年交付的 X1E 增强功能分别提高了 565 和 1130 MHz 的时钟率。许多想法都是从 Cray T3E 设计中借来的，Cray T3E Design 是使用现成的微处理器的 MIMD（多个指令，多个数据）计算机。X1 具有一个新的指令集，其中包含大量的 iSters，并且内存在共享地址空间中与处理器本地分布。逐级标量单元和向量单元被解耦，以便标量单元可以领先于矢量单元。当数据被阻止以利用 MSP 缓存时，向量变短，这与八车道 vector 单元不匹配。为了处理这些较短的向量，每个带有两个向量车道的处理器都可以在不同的循环中工作。

The Cray X2 was announced in 2007, and it may prove to be the last Cray vec- tor architecture to be built, as it’s difficult to justify the investment in new silicon given the size of the market. The processor has a 1.3 GHz clock rate and 8 vector lanes for a processor peak performance of 42 GFLOP/sec for single precision. It includes both L1 and L2 caches. Each node is a 4-way SMP with up to 128 GBytes of DRAM, and the maximum size is 8K nodes.

> Cray X2 于 2007 年宣布，它可能被证明是要建造的最后一个 Cray vector 构造，因为鉴于市场规模，很难证明对新硅的投资是合理的。该处理器具有 1.3 GHz 时钟速率和 8 个向量车道，用于单个精度为 42 GFLOP/SEC 的处理器峰性能。它包括 L1 和 L2 缓存。每个节点是一个 4 向 SMP，最多为 128 gbytes DRAM，最大尺寸为 8K 节点。

The NEC SX-9 has up to 16 processors per node, with each processor having 8 lanes and running at 3.2 GHz. It was announced in 2008. The peak double pre- cision vector performance is 102 GFLOP/sec. The 16 processor SMP can have 1024 GBytes of DRAM. The maximum size is 512 nodes.

> NEC SX-9 每个节点最多有 16 个处理器，每个处理器都有 8 个车道，并以 3.2 GHz 运行。它于 2008 年宣布。峰值双重前矢量性能为 102 GFLOP/秒。16 个处理器 SMP 可以具有 1024 GBYTES DRAM。最大尺寸为 512 个节点。

The basis for modern vectorizing compiler technology and the notion of data dependence was developed by Kuck and his colleagues [1974] at the University of Illinois. Padua and Wolfe [1986] gave a good overview of vectorizing compiler technology.

> 库克（Kuck）和他的同事[1974]在伊利诺伊大学（University of Illinois）开发了现代矢量化编译器技术和数据依赖概念的基础。Padua 和 Wolfe [1986]很好地概述了编译器技术。

### Multimedia SIMD Instruction Extensions

> ### Multimedia Simd 指令扩展

_What could a computer hardware company_ … _possibly have in common with disco dancing. A lot, if one goes by an advertisement campaign released by the world’s largest microprocessor company_ … _Intel, in 1997._

> _计算机硬件公司可以做什么……_ _可能与 Disco Dancing 有什么共同点。很多人，如果一个人参加了世界上最大的微处理器公司_…_Intel，1997 年发布的广告活动。

IBS Center for Management Research

> IBS 管理研究中心

_“Dancing Its Way Towards Leadership,” 2002_

> _“朝领导力跳舞”，2002 年

Going through the history books, the 1957 TX-2 had partitioned ALUs to support media of the time, but these ideas faded away to be rediscovered 30 years later in the personal computer era. Since every desktop microprocessor by definition has its own graphical displays, as transistor budgets increased it was inevitable that support would be added for graphics operations. Many graphics systems use 8 bits to represent each of the 3 primary colors plus 8 bits for a transparency of a pixel. The addition of speakers and microphones for teleconferencing and video games suggested support of sound as well. Audio samples need more than 8 bits of pre- cision, but 16 bits are sufficient.

> 经过历史书籍，1957 年的 TX-2 划分了 Alus 来支持当时的媒体，但是这些想法在 30 年后在个人计算机时代重新发现了这些想法。由于根据定义，每个桌面微处理器都有其自己的图形显示，随着晶体管预算的增加，不可避免的是为图形操作添加支持。许多图形系统使用 8 位代表 3 个原色中的每一个以及 8 位，以使像素的透明度。扬声器和麦克风用于电信和视频游戏也建议支持声音。音频样品需要超过 8 位的预割，但是 16 位足够。

Every microprocessor has special support so that bytes and half words take up less space when stored in memory, but due to the infrequency of arithmetic oper- ations on these data sizes in typical integer programs, there is little support beyond data transfers. The Intel i860 was justified as a graphical accelerator within the company. Its architects recognized that many graphics and audio appli- cations would perform the same operation on vectors of these data [Atkins 1991; Kohn 1989]. Although a vector unit was beyond the transistor budget of the i860 in 1989, by partitioning the carry chains within a 64-bit ALU, it could perform simultaneous operations on short vectors of eight 8-bit operands, four 16-bit oper- ands, or two 32-bit operands. The cost of such partitioned ALUs was small. Applications that lend themselves to such support include MPEG (video), video games (3D graphics), digital photography, and teleconferencing (audio and image processing).

> 每个微处理器都有特殊的支持，因此在存储中存储时，字节和半词的空间更少，但是由于在典型的整数程序中这些数据尺寸的算术操作不足，因此除了数据传输之外，几乎没有支持。英特尔 i860 被认为是公司内部的图形加速器。它的建筑师认识到，许多图形和音频应用将对这些数据的向量执行相同的操作[Atkins 1991;Kohn 1989]。尽管矢量单元超出了 1989 年 i860 的晶体管预算，但通过对 64 位 ALU 内的携带链进行划分，它可以同时在八个 8 位操作数，四个 16 位操作系统的短矢量上进行同时操作。或两个 32 位操作数。这种分区的 Alus 的成本很小。支持这种支持的应用程序包括 MPEG（视频），视频游戏（3D 图形），数字摄影和电信（音频和图像处理）。

Like a virus, over time such multimedia support has spread to nearly every desktop microprocessor. HP was the first successful desktop RISC to include such support, but soon every other manufacturer had their own take on the idea in the 1990s.

> 像病毒一样，随着时间的流逝，这种多媒体支持已经传播到几乎每个桌面微处理器。惠普是第一个成功提供此类支持的台式机 RISC，但很快其他每家制造商都在 1990 年代对这个想法有自己的看法。

These extensions were originally called _subword parallelism_ or _vector_. Since Intel marketing used SIMD to describe the MMX extension of the 80x86 announced in 1996, that became the popular name, due in part to a successful tele- vision advertising campaign involving disco dancers wearing clothing modeled after the cleansuits worn in semiconductor fabrication lines.

> 这些扩展名称最初称为_subword Parallelism_或_vector_。由于 Intel Marketing 使用 SIMD 来描述 1996 年宣布的 80x86 的 MMX 扩展，因此成为流行的名称，部分原因是成功的远视广告活动涉及迪斯科舞者，涉及迪斯科舞者穿着戴着服装的服装，这是在半导体制造线上穿着的清洁套件。

### Graphical Processor Units

> ###图形处理器单元

_It’s been almost three years since GPU computing broke into the mainstream of HPC with the introduction of NVIDIA’s CUDA API in September 2007. Adoption of the technology since then has proceeded at a surprisingly strong and steady pace. Many organizations that began with small pilot projects a year or two ago have moved on to enterprise deployment, and GPU accelerated machines are now represented on the TOP500 list starting at position two. The relatively rapid adoption of CUDA by a community not known for the rapid adoption of much of anything is a noteworthy signal. Contrary to the accepted wisdom that GPU computing is more difficult, I believe its success thus far signals that it is no more complicated than good CPU programming. Further, it more clearly and succinctly expresses the parallelism of a large class of problems leading to code that is easier to maintain, more scalable and better positioned to map to future many-core architectures._

> _自 2007 年 9 月 NVIDIA 的 CUDA API 引入了 GPU 计算闯入 HPC 的主流以来已有将近三年的时间。此后采用了该技术的采用，以惊人的强劲而稳定的速度进行。许多从一两年前开始的小型飞行员项目开始的组织已转移到企业部署，而 GPU 加速机器现在在 TOP500 列表中从位置第二位开始。一个值得注意的信号是一个不迅速采用任何事物而闻名的社区相对迅速采用的 CUDA。与公认的 GPU 计算更加困难的公认智慧相反，我认为其成功表明它并不比出色的 CPU 编程更复杂。此外，它更清晰，更简洁地表达了导致代码的大量问题的并行性，这些问题更易于维护，更可扩展和更好的位置，以映射到未来的多核体系结构。

Vincent Natol

> Vincent Natol

_“Kudos for CUDA,” HPCwire (2010)_

> _“ cuda 的 Kudos”，HPCwire（2010）_

3D graphics pipeline hardware evolved from the large expensive systems of the early 1980s to small workstations and then to PC accelerators in the mid- to late 1990s. During this period, three major transitions occurred:

> 3D 图形管道硬件从 1980 年代初的大型昂贵系统演变为小型工作站，然后在 1990 年代中期至后期演变为 PC 加速器。在此期间，发生了三个重大转变：

- Performance-leading graphics subsystems declined in price from $50,000 to $200.

> - 性能领先的图形子系统的价格从 50,000 美元下降到 200 美元。

- Performance increased from 50 million pixels per second to 1 billion pixels per second and from 100,000 vertices per second to 10 million vertices per second.

> - 性能从每秒 5000 万像素增加到每秒 10 亿像素，从每秒 100,000 个顶点增加到每秒 1000 万个顶点。

- Native hardware capabilities evolved from wireframe (polygon outlines) to flat-shaded (constant color) filled polygons, to smooth-shaded (interpolated color) filled polygons, to full-scene anti-aliasing with texture mapping and rudimentary multitexturing.

> - 天然硬件功能从线框（多边形轮廓）到扁平阴影（恒定）填充的多边形，再到光滑的（插值颜色）填充的多边形，再到全幕抗叠利，并带有纹理映射和质切的多工业。

### Scalable GPUs

> ###可扩展 GPU

Scalability has been an attractive feature of graphics systems from the beginning. Workstation graphics systems gave customers a choice in pixel horse-power by vary- ing the number of pixel processor circuit boards installed. Prior to the mid-1990s PC graphics scaling was almost nonexistent. There was one option—the VGA controller. As 3D-capable accelerators appeared, the market had room for a range of offerings. 3dfx introduced multiboard scaling with the original SLI (Scan Line Interleave) on their Voodoo2, which held the performance crown for its time (1998). Also in 1998, NVIDIA introduced distinct products as variants on a single architecture with Riva TNT Ultra (high-performance) and Vanta (low-cost), first by speed binning and packaging, then with separate chip designs (GeForce 2 GTS and GeForce 2 MX). At present, for a given architecture generation, four or five separate GPU chip designs are needed to cover the range of desktop PC performance and price points. In addition, there are separate segments in notebook and workstation systems. After acquiring 3dfx, NVIDIA continued the multi-GPU SLI concept in 2004, starting with GeForce 6800—providing multi-GPU scalability transparently to the programmer and to the user. Functional behavior is identical across the scaling range; one application will run unchanged on any implementation of an architectural family.

> 从一开始，可伸缩性一直是图形系统的吸引力。Workstation 图形系统通过改变安装的像素处理器电路板的数量，为客户提供了像素马功率的选择。在 1990 年代中期之前，PC 图形缩放几乎不存在。有一个选项 -  VGA 控制器。随着 3D 能力的加速器的出现，市场有一系列产品的空间。3DFX 在其 Voodoo2 上使用原始 SLI（扫描线路）引入了多层缩放，该量表（1998 年）都保持了性能冠。同样在 1998 年，NVIDIA 在带有 Riva TNT Ultra（高性能）和 Vanta（低成本）的单个体系结构上引入了不同的产品，首先是通过速度装箱和包装，然后采用单独的芯片设计（GeForce 2 GTS 和 GEForce 2MX）。目前，对于给定的建筑生成，需要四到五个独立的 GPU 芯片设计来涵盖台式 PC 性能和价格点的范围。此外，笔记本和工作站系统中还有单独的段。在获得 3DFX 后，NVIDIA 在 2004 年继续使用 Multi-GPU SLI 概念，从 GeForce 6800 开始 - 向程序员和用户提供多 GPU 可伸缩性。在整个缩放范围内的功能行为相同。一项应用程序将在建筑家庭的任何实施方面都保持不变。

### Graphics Pipelines

> ###图形管道

Early graphics hardware was configurable, but not programmable by the applica- tion developer. With each generation, incremental improvements were offered; however, developers were growing more sophisticated and asking for more new features than could be reasonably offered as built-in fixed functions. The NVIDIA GeForce 3, described by Lindholm et al. [2001], took the first step toward true gen- eral shader programmability. It exposed to the application developer what had been the private internal instruction set of the floating-point vertex engine. This coin- cided with the release of Microsoft’s DirectX 8 and OpenGL’s vertex shader exten- sions. Later GPUs, at the time of DirectX 9, extended general programmability and floating-point capability to the pixel fragment stage and made texture available at the vertex stage. The ATI Radeon 9700, introduced in 2002, featured a program- mable 24-bit floating-point pixel fragment processor programmed with DirectX 9 and OpenGL. The GeForce FX added 32-bit floating-point pixel processors. This was part of a general trend toward unifying the functionality of the different stages, at least as far as the application programmer was concerned. NVIDIA’s GeForce 6800 and 7800 series were built with separate processor designs and separate hard- ware dedicated to the vertex and to the fragment processing. The XBox 360 intro- duced an early unified processor GPU in 2005, allowing vertex and pixel shaders to execute on the same processor.

> 早期图形硬件是可配置的，但不能由应用程序开发人员编程。每一代人都提供了增量的改进；但是，开发人员的发展越来越复杂，并且要求提供更多的新功能，而不是可以合理地作为内置固定功能提供的。Nvidia geforce 3，由 Lindholm 等人描述。[2001]，迈出了真正的 General General Pender 可编程性的第一步。它暴露于应用程序开发人员的浮点顶点引擎的私人内部指令集。这与 Microsoft 的 DirectX 8 和 OpenGL 的顶点着色器扩展有关。后来，GPU 在 DirectX 9 时，将一般的可编程性和浮点功能扩展到像素片段阶段，并在顶点阶段提供纹理。2002 年推出的 ATI Radeon 9700 配备了一个程序中的 24 位浮点像素片段处理器，该处理器使用 DirectX 9 和 OpenGL 编程。GeForce FX 添加了 32 位浮点像素处理器。这是统一不同阶段功能的一般趋势的一部分，至少就申请程序员而言。NVIDIA 的 GEFORCE 6800 和 7800 系列是采用单独的处理器设计构建的，并独立于顶点和片段处理。Xbox 360 在 2005 年引入了早期统一的处理器 GPU，使顶点和像素着色器可以在同一处理器上执行。

### GPGPU: An Intermediate Step

> ### gpgpu：一个中级步骤

As DirectX 9-capable GPUs became available, some researchers took notice of the raw performance growth path of GPUs and began to explore the use of GPUs to solve complex parallel problems. DirectX 9 GPUs had been designed only to match the features required by the graphics API. To access the computational resources, a programmer had to cast their problem into native graphics operations. For example, to run many simultaneous instances of a pixel shader, a triangle had to be issued to the GPU (with clipping to a rectangle shape if that was what was desired). Shaders did not have the means to perform arbitrary scatter operations to memory. The only way to write a result to memory was to emit it as a pixel color value and configure the framebuffer operation stage to write (or blend, if desired) the result to a two-dimensional framebuffer. Furthermore, the only way to get a result from one pass of computation to the next was to write all parallel results to a pixel framebuffer, then use that framebuffer as a texture map as input to the pixel fragment shader of the next stage of the computation. Mapping general computations to a GPU in this era was quite awkward. Nevertheless, intrepid researchers demonstrated a handful of useful applications with painstaking efforts. This field was called “GPGPU” for general-purpose computing on GPUs.

> 随着 DirectX 9 强大的 GPU 的可用，一些研究人员注意到 GPU 的原始性能增长路径，并开始探索 GPU 来解决复杂的平行问题。DirectX 9 GPU 的设计仅是为了匹配图形 API 所需的功能。为了访问计算资源，程序员必须将问题投入到本机图形操作中。例如，要运行许多像素着色器的同时实例，必须向 GPU 发出三角形（如果那是所需的话，则剪裁到矩形形状）。着色器没有对内存进行任意分散操作的手段。将结果写入内存的唯一方法是将其作为像素颜色值发射，并配置框架操作阶段以写入（或混合，如果需要），将结果该结果到二维 Framebuffer。此外，从一个计算传递到下一个的计算结果的唯一方法是将所有并行结果写入像素帧缓冲器，然后将该框架用作纹理映射作为计算下一个阶段的像素片段着色器的输入。在这个时代，将一般计算映射到 GPU 非常尴尬。然而，无畏的研究人员在艰苦的努力中展示了一些有用的应用。该字段称为 GPU 上通用计算的“ GPGPU”。

### GPU Computing

> ### GPU 计算

While developing the Tesla architecture for the GeForce 8800, NVIDIA realized its potential usefulness would be much greater if programmers could think of the GPU as a processor. NVIDIA selected a programming approach in which program- mers would explicitly declare the data-parallel aspects of their workload.

> 在为 GeForce 8800 开发特斯拉体系结构时，NVIDIA 意识到，如果程序员可以将 GPU 视为处理器，那么它的潜在实用性将会更大。NVIDIA 选择了一种编程方法，其中计划将明确声明其工作负载的数据并行方面。

For the DirectX 10 generation, NVIDIA had already begun work on a highef- ficiency floating-point and integer processor that could run a variety of simultaneous workloads to support the logical graphics pipeline. This processor was designed to take advantage of the common case of groups of threads executing the same code path. NVIDIA added memory load and store instructions with inte- ger byte addressing to support the requirements of compiled C programs. It intro- duced the thread block (cooperative thread array), grid of thread blocks, and barrier synchronization to dispatch and manage highly parallel computing work. Atomic memory operations were added. NVIDIA developed the CUDA C/C++ compiler, libraries, and runtime software to enable programmers to readily access the new data-parallel computation model and develop applications.

> 对于 DirectX 10 代，NVIDIA 已经开始在高效率的浮点和整数处理器上进行工作，该处理器可以运行各种同时工作量以支持逻辑图形管道。该处理器旨在利用执行相同代码路径的线程组的常见情况。NVIDIA 添加了内存负载，并使用 Integer Byte 地址存储指令，以支持编译 C 程序的要求。它介绍了螺纹块（合作线程数组），螺纹块的网格和屏障同步，以调度和管理高度平行的计算工作。添加了原子记忆操作。NVIDIA 开发了 CUDA C/C ++ 编译器，库和运行时软件，以使程序员能够轻松访问新的数据并行计算模型并开发应用程序。

To create a vendor-neutral GPU programming language, a large number of com- panies are creating compilers for the OpenCL language, which has many of the fea- tures of CUDA but which runs on many more platforms. In 2011, the performance is much higher if you write CUDA code for GPUs than if you write OpenCL code.

> 为了创建一种供应商中立的 GPU 编程语言，许多公司正在为 OpenCl 语言创建编译器，该编译器具有 CUDA 的许多功能，但在更多平台上运行。在 2011 年，如果您为 GPU 编写 CUDA 代码要比编写 OpenCL 代码，则性能要高得多。

AMD’s acquisition of ATI, the second leading GPU vendor, suggests a spread of GPU computing. The AMD Fusion architecture, announced just as this edition was being finished, is an initial merger between traditional GPUs and traditional CPUs. NVIDIA also announced Project Denver, which combines an ARM scalar processor with NVIDIA GPUs in a single address space. When these systems are shipped, it will be interesting to learn just how tightly integrated they are and the impact of integration on performance and energy of both data parallel and graphics applications.

> AMD 对 ATI 的收购是第二个领先的 GPU 供应商，这表明 GPU 计算的传播。AMD Fusion Architecture 宣布在此版本完成后，是传统 GPU 和传统 CPU 之间的初步合并。NVIDIA 还宣布了丹佛项目，该项目将 ARM 标量处理器与 NVIDIA GPU 结合在单个地址空间中。当这些系统发货时，学习它们的集成程度以及集成对数据并行和图形应用程序的性能和能量的影响将很有趣。
