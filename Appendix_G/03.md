## Vector Memory Systems in More Depth

To maintain an initiation rate of one word fetched or stored per clock, the memory system must be capable of producing or accepting this much data. As we saw in [Chapter 4](#_bookmark165), this usually done by spreading accesses across multiple independent memory banks. Having significant numbers of banks is useful for dealing with vec- tor loads or stores that access rows or columns of data.

> 为了维持一个单词以每个时钟获取或存储的单词的启动率，内存系统必须能够产生或接受这一数据。正如我们在[第 4 章](#_bookmark165)中看到的那样，这通常是通过在多个独立的内存库中传播访问来完成的。拥有大量银行对于处理访问行或数据列的 vector 载荷或商店很有用。

The desired access rate and the bank access time determined how many banks were needed to access memory without stalls. This example shows how these tim- ings work out in a vector processor.

> 所需的访问率和银行访问时间确定需要多少银行来访问没有摊位的内存。此示例显示了这些时间如何在矢量处理器中奏效。

Example Suppose we want to fetch a vector of 64 elements starting at byte address 136, and a memory access takes 6 clocks. How many memory banks must we have to support one fetch per clock cycle? With what addresses are the banks accessed? When will the various elements arrive at the CPU?

> 示例假设我们想从字节地址 136 开始获取 64 个元素的向量，并且内存访问需要 6 个时钟。每个时钟周期必须支持一个内存库？银行访问了哪些地址？各个元素什么时候到达 CPU？

_Answer_ Six clocks per access require at least 6 banks, but because we want the number of banks to be a power of 2, we choose to have 8 banks. Figure G.7 shows the timing for the first few sets of accesses for an 8-bank system with a 6-clock-cycle access latency.

> _answer_每个访问的六个时钟至少需要 6 个银行，但是由于我们希望银行数量为 2 个，因此我们选择拥有 8 个银行。图 G.7 显示了具有 6 个锁定周期访问延迟的 8 银行系统的前几组访问的时间。

The timing of real memory banks is usually split into two different components, the access latency and the bank cycle time (or _bank busy time_). The access latency is the time from when the address arrives at the bank until the bank returns a data value, while the busy time is the time the bank is occupied with one request. The access latency adds to the start-up cost of fetching a vector from memory (the total memory latency also includes time to traverse the pipelined interconnection networks that transfer addresses and data between the CPU and memory banks). The bank busy time governs the effective bandwidth of a memory system because a processor can- not issue a second request to the same bank until the bank busy time has elapsed. For simple unpipelined SRAM banks as used in the previous examples, the access latency and busy time are approximately the same. For a pipelined SRAM bank, however, the access latency is larger than the busy time because each element access only occupies one stage in the memory bank pipeline. For a DRAM bank, the access latency is usually shorter than the busy time because a DRAM needs extra time to restore the read value after the destructive read oper- ation. For memory systems that support multiple simultaneous vector accesses or allow nonsequential accesses in vector loads or stores, the number of mem- ory banks should be larger than the minimum; otherwise, memory bank con- flicts will exist.

> 真实内存库的时间通常分为两个不同的组件，即访问延迟和银行周期时间(或_bank 忙碌时间_)。访问延迟是地址到达银行到银行返回数据值的时间，而繁忙时间是银行被占用的时间。访问延迟增加了从内存中获取向量的启动成本(总内存延迟还包括遍历管道的互连网络的时间，这些互连网络在 CPU 和内存库之间传输地址和数据)。银行忙碌的时间控制着内存系统的有效带宽，因为处理器可以在银行忙碌的时间过去之前向同一银行发出第二个请求。对于以前示例中使用的简单脱纤维 SRAM 银行，访问延迟和繁忙时间大致相同。但是，对于管道的 SRAM 银行，访问延迟大于繁忙的时间，因为每个元素访问仅在内存库管道中占据一个阶段。对于 DRAM 银行，访问延迟通常比繁忙的时间短，因为 DRAM 需要额外的时间来恢复破坏性读取操作后的读取值。对于支持多个同时进行矢量访问或允许在向量负载或商店中的非序列访问的内存系统，内存库的数量应大于最小值；否则，将存在内存库。

Figure G.7 Memory addresses (in bytes) by bank number and time slot at which access begins. Each memory bank latches the element address at the start of an access and is then busy for 6 clock cycles before returning a value to the CPU. Note that the CPU cannot keep all 8 banks busy all the time because it is limited to supplying one new address and receiving one data item each cycle.

> 图 G.7 内存地址(在字节中)按访问开始的银行编号和时间插槽。每个内存库在访问开始时锁定元素地址，然后在将值返回到 CPU 之前忙于 6 个时钟周期。请注意，CPU 不能一直保持所有 8 家银行，因为它仅限于提供一个新的地址并在每个周期接收一个数据项。

Memory bank conflicts will not occur within a single vector memory instruc- tion if the stride and number of banks are relatively prime with respect to each other and there are enough banks to avoid conflicts in the unit stride case. When there are no bank conflicts, multiword and unit strides run at the same rates. Increasing the number of memory banks to a number greater than the minimum to prevent stalls with a stride of length 1 will decrease the stall frequency for some other strides. For example, with 64 banks, a stride of 32 will stall on every other access, rather than every access. If we originally had a stride of 8 and 16 banks, every other access would stall; with 64 banks, a stride of 8 will stall on every eighth access. If we have multiple memory pipelines and/or multiple processors sharing the same memory system, we will also need more banks to prevent conflicts. Even machines with a single memory pipeline can experience memory bank conflicts on unit stride accesses between the last few elements of one instruction and the first few elements of the next instruction, and increasing the number of banks will reduce the prob- ability of these inter-instruction conflicts. In 2011, most vector supercomputers spread the accesses from each CPU across hundreds of memory banks. Because bank conflicts can still occur in non-unit stride cases, programmers favor unit stride accesses whenever possible.

> 如果银行的步幅和数量相对彼此相对较好，并且有足够的银行可以避免在单位步伐案件中避免冲突，则记忆银行冲突将不会发生在单个矢量内存的指导中。当没有银行冲突时，多词和单位大步以相同的速度运行。将记忆库的数量增加到大于最小值的数量，以防止长度为 1 的摊位，将减少其他一些步伐的失速频率。例如，拥有 64 个银行，大步 32 将停滞在其他所有访问权限上，而不是每个访问权限。如果我们最初的大步迈出了 8 和 16 个银行，那么其他所有访问权限都会停滞不前。拥有 64 家银行，每次第八次进入访问权限将停滞不前。如果我们有多个内存管道和/或多个共享同一内存系统的处理器，我们还将需要更多的银行来防止冲突。即使是单个内存管道的机器也可以在一项指令的最后几个元素和下一个指令的前几个元素之间遇到内存库冲突，而增加银行数量将降低这些相互关系的概率。指示冲突。2011 年，大多数向量超级计算机将每个 CPU 的访问权限传播到数百个存储库中。由于银行冲突仍然可以在非单位步步案件中发生，因此程序员在可能的情况下偏爱单位大步访问。

A modern supercomputer may have dozens of CPUs, each with multiple mem- ory pipelines connected to thousands of memory banks. It would be impractical to provide a dedicated path between each memory pipeline and each memory bank, so, typically, a multistage switching network is used to connect memory pipelines to memory banks. Congestion can arise in this switching network as different vec- tor accesses contend for the same circuit paths, causing additional stalls in the memory system.

> 现代超级计算机可能具有数十个 CPU，每个 CPU 都有多个内存管道连接到数千个内存库。在每个内存管道和每个内存库之间提供专门的路径是不切实际的，因此，通常，多阶段交换网络用于将内存管道连接到内存库。由于不同的 vector 访问对相同的电路路径的竞争，因此在此开关网络中可能会出现拥堵，从而导致内存系统中的其他失速。
