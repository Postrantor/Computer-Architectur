## Effectiveness of Compiler Vectorization

> ##编译器矢量化的有效性

Two factors affect the success with which a program can be run in vector mode. The first factor is the structure of the program itself: Do the loops have true data dependences, or can they be restructured so as not to have such dependences? This factor is influenced by the algorithms chosen and, to some extent, by how they are coded. The second factor is the capability of the compiler. While no compiler can vectorize a loop where no parallelism among the loop iterations exists, there is tre- mendous variation in the ability of compilers to determine whether a loop can be vectorized. The techniques used to vectorize programs are the same as those discussed in [Chapter 3](#_bookmark93) for uncovering ILP; here, we simply review how well these techniques work.

> 有两个因素影响可以在矢量模式下运行程序的成功。第一个因素是程序本身的结构：循环是否具有真实的数据依赖性，或者可以重组以使其具有这种依赖性？该因素受到所选算法的影响，并在某种程度上受到编码的方式。第二个因素是编译器的功能。虽然没有编译器可以矢量化循环，在循环迭代之间没有并行性，但编译器确定是否可以将循环进行矢量化的能力存在差异。用于矢量化程序的技术与[第 3 章](#_bookmark93)中讨论的技术相同。在这里，我们简单地回顾了这些技术的工作方式。

There is tremendous variation in how well different compilers do in vectorizing programs. As a summary of the state of vectorizing compilers, consider the data in Figure G.9, which shows the extent of vectorization for different processors using a test suite of 100 handwritten FORTRAN kernels. The kernels were designed to test vectorization capability and can all be vectorized by hand; we will see several examples of these loops in the exercises.

> 不同的编译器在矢量化程序中的表现有很大差异。作为矢量化编译器状态的摘要，请考虑图 G.9 中的数据，该数据显示了使用 100 个手写 Fortran 内核的测试套件的不同处理器的矢量化程度。内核旨在测试矢量化能力，并且都可以手工倒数。我们将在练习中看到这些循环的几个示例。

Figure G.9 Result of applying vectorizing compilers to the 100 FORTRAN test kernels. For each processor we indicate how many loops were completely vectorized, partially vectorized, and unvectorized. These loops were collected by [Callahan,](#_bookmark705) [Dongarra, and Levine \[1988]](#_bookmark705). Two different compilers for the Cray X-MP show the large dependence on compiler technology.

> 图 G.9 将矢量化编译器应用于 100 个 FORTRAN 测试核的结果。对于每个处理器，我们指出了多少个循环被完全矢量化，部分矢量化和未矢量化。这些循环由 [Callahan，](#_bookmark705)[Dongarra 和 Levine \ [1988 ]](#_bookmark705)收集。Cray X-MP 的两个不同的编译器显示了对编译器技术的巨大依赖性。

In this section, we look at performance measures for vector processors and what they tell us about the processors. To determine the performance of a processor on a vector problem we must look at the start-up cost and the sustained rate. The simplest and best way to report the performance of a vector processor on a loop is to give the execution time of the vector loop. For vector loops, people often give the MFLOPS (millions of floating-point operations per second) rating rather than execution time. We use the notation R*<sub>n</sub>* for the MFLOPS rating on a vector of length _n_. Using the measurements T*<sub>n</sub>* (time) or R*<sub>n</sub>* (rate) is equivalent if the number of FLOPS is agreed upon. In any event, either measurement should include the overhead.

> 在本节中，我们研究了矢量处理器的绩效指标及其对处理器的信息。为了确定处理器在向量问题上的性能，我们必须查看启动成本和持续费用。报告向量处理器在循环中的性能的最简单和最佳方法是给出向量循环的执行时间。对于矢量循环，人们经常给予 MFLOP(每秒数百万个浮点操作)评级而不是执行时间。我们将符号 r* <ub> n </sub>*用于长度_n_的向量上的 mflops 额定值。如果同意拖鞋的数量，则使用测量值 T* <sub> n </sub>*(时间)或 r* <ub> n </sub>*(速率)是等效的。无论如何，任何一个测量都应包括开销。

In this section, we examine the performance of VMIPS on a DAXPY loop (see [Chapter 4](#_bookmark165)) by looking at performance from different viewpoints. We will continue to compute the execution time of a vector loop using the equation developed in Section G.2. At the same time, we will look at different ways to measure perfor- mance using the computed time. The constant values for T<sub>loop</sub> used in this section introduce some small amount of error, which will be ignored.

> 在本节中，我们通过从不同角度查看性能来研究 Daxpy 循环(请参阅[第 4 章](#_bookmark165))上 VMIP 的性能。我们将继续使用 G.2 节中开发的方程来计算向量循环的执行时间。同时，我们将研究使用计算时间来测量 performence 的不同方法。本节中使用的 t <sub>循环的常数值引入了一些误差，这将被忽略。

### Measures of Vector Performance

> ###矢量性能度量

Because vector length is so important in establishing the performance of a proces- sor, length-related measures are often applied in addition to time and MFLOPS. These length-related measures tend to vary dramatically across different processors

> 由于矢量长度在建立过程的性能中非常重要，因此除了时间和 MFLOPS 外，通常还采用了与长度相关的措施。这些与长度相关的措施在不同的处理器上往往变化很大

and are interesting to compare. (Remember, though, that `time` is always the mea- sure of interest when comparing the relative speed of two processors.) Three of the most important length-related measures are

> 比较有趣。(但是，请记住，在比较两个处理器的相对速度时，_time_始终是感兴趣的。)三个最重要的长度相关度量是

- R<sub>∞</sub>—The MFLOPS rate on an infinite-length vector. Although this measure may be of interest when estimating peak performance, real problems have lim- ited vector lengths, and the overhead penalties encountered in real problems will be larger.

> -r <ub>∞</sub>  - 无限长度矢量上的 mflops 速率。尽管在估计峰值性能时可能会引起这种措施，但实际问题具有限定的矢量长度，而在实际问题中遇到的高架惩罚将更大。

- N<sub>1/2</sub>—The vector length needed to reach one-half of R<sub>∞</sub>. This is a good mea- sure of the impact of overhead.

> -n <ub> 1/2 </sub>  - 达到 R <sub>∞</sub>的一半所需的矢量长度。这是对开销的影响的很好的选择。

- N<sub>v</sub>—The vector length needed to make vector mode faster than scalar mode. This measures both overhead and the speed of scalars relative to vectors.

> -n <sub> v </sub>  - 比标量模式更快地使矢量模式所需的向量长度。这可以测量相对于向量的标量的开销和标量的速度。

Let’s look at these measures for our DAXPY problem running on VMIPS. When chained, the inner loop of the DAXPY code in convoys looks like Figure G.10 (assuming that Rx and Ry hold starting addresses).

> 让我们看一下在 VMIP 上运行的 Daxpy 问题的这些措施。链接时，车队中 Daxpy 代码的内部循环看起来像图 G.10(假设 RX 和 RY 保留起始地址)。

Chaining allows the loop to run in three chimes (and no less, since there is one memory pipeline); thus, T<sub>chime</sub> 3. If T<sub>chime</sub> were a complete indication of per- formance, the loop would run at an MFLOPS rate of 2/3 clock rate (since there are 2 FLOPS per iteration). Thus, based only on the chime count, a 500 MHz VMIPS would run this loop at 333 MFLOPS assuming no strip-mining or start-up overhead. There are several ways to improve the performance: Add addi- tional vector load-store units, allow convoys to overlap to reduce the impact of start-up overheads, and decrease the number of loads required by vector-register allocation. We will examine the first two extensions in this section. The last optimization is actually used for the Cray-1, VMIPS’s cousin, to boost the per- formance by 50%. Reducing the number of loads requires an interprocedural optimization; we examine this transformation in Exercise G.6. Before we exam- ine the first two extensions, let’s see what the real performance, including overhead, is.

> 链条使循环可以以三个铃声运行(而且由于有一个内存管道，因此也可以不少。因此，t <sub> chime </sub> 3.如果 t <sub> chime </sub>是完整的表述，则循环将以 2/3 时钟速率运行(因为有每次迭代 2 个拖鞋)。因此，仅基于核计数，假设没有剥离或启动开销，则 500 MHz VMIP 将以 333 MFLOPS 运行此循环。有几种改善性能的方法：添加附加矢量负载店单元，使车队重叠以减少启动开销的影响，并减少向量注册分配所需的负载数量。我们将研究本节中的前两个扩展。最后的优化实际上用于 Cray-1 Vmips 的表弟，以提高 50％的能力。减少负载的数量需要重骨外科优化；我们研究了练习 G.6 中的这种转变。在检查前两个扩展之前，让我们看看包括开销在内的真实性能是什么。

Figure G.10 The inner loop of the DAXPY code in chained convoys.

> 图 G.10 链式车队中 Daxpy 代码的内环。

### The Peak Performance of VMIPS on DAXPY

> ### VMIP 在 Daxpy 上的峰值性能

First, we should determine what the peak performance, R<sub>∞</sub>, really is, since we know it must differ from the ideal 333 MFLOPS rate. For now, we continue to use the simplifying assumption that a convoy cannot start until all the instructions in an earlier convoy have completed; later we will remove this restriction. Using this simplification, the start-up overhead for the vector sequence is simply the sum of the start-up times of the instructions:

> 首先，我们应该确定峰值性能 R <sub>∞</sub>的确是什么，因为我们知道它必须与理想的 333 Mflops 速率不同。目前，我们继续使用简化的假设，即在较早的车队中的所有指示完成之前，车队无法启动。稍后我们将删除此限制。使用此简化，向量序列的启动开销只是指令的启动时间的总和：

Using MVL 64, T<sub>loop</sub> 15, T<sub>start</sub> 49, and T<sub>chime</sub> 3 in the performance equation, and assuming that `n` is not an exact multiple of 64, the time for an _n_- element operation is

> 使用 MVL 64，T <sub> Loop </sub> 15，T <sub>开始</sub> 49 和 T <sub> chime </sub> 3 中的</sub> 3，并假设_n_不是准确的 64 的倍数，_n_-元素操作的时间为

The sustained rate is actually over 4 clock cycles per iteration, rather than the the- oretical rate of 3 chimes, which ignores overhead. The major part of the difference is the cost of the start-up overhead for each block of 64 elements (49 cycles versus 15 for the loop overhead).

> 实际上，持续速率实际上超过了 4 个时钟周期，而不是忽略开销的 3 个音调的口音速率。差异的主要部分是每个块的 64 个元素的启动开销成本(49 个周期与循环开销 15)。

The performance without the start-up overhead, which is the peak performance given the vector functional unit structure, is now 1.33 times higher. In actuality, the gap between peak and sustained performance for this benchmark is even larger!

> 鉴于向量功能单位结构的峰值性能，没有启动开销的性能是高 1.33 倍。实际上，此基准测试的峰值和持续性能之间的差距更大！

### Sustained Performance of VMIPS on the Linpack Benchmark

> ### VMIP 在 Linpack 基准上的持续性能

The Linpack benchmark is a Gaussian elimination on a 100 100 matrix. Thus, the vector element lengths range from 99 down to 1. A vector of length `k` is used `k` times. Thus, the average vector length is given by:

> Linpack 基准测试是 100 矩阵上的高斯消除。因此，向量元素长度从 99 降至 1。使用_K_的矢量_k_ times。因此，平均向量长度由以下方式给出：

Now we can obtain an accurate estimate of the performance of DAXPY using a vector length of 66:

> 现在，我们可以使用矢量长度为 66：准确地估计达克斯皮的性能：

The peak number, ignoring start-up overhead, is 1.64 times higher than this estimate of sustained performance on the real vector lengths. In actual practice, the Linpack benchmark contains a nontrivial fraction of code that cannot be vectorized. Although this code accounts for less than 20% of the time before vectorization, it runs at less than one-tenth of the performance when counted as FLOPS. Thus, Amdahl’s law tells us that the overall performance will be significantly lower than the performance estimated from analyzing the inner loop.

> 忽略启动开销的峰值数量是实际矢量长度上持续性能的估计值的 1.64 倍。在实际实践中，linpack 基准中包含一个无法矢量化的代码的非平凡部分。尽管此代码在矢量化之前的时间不到 20％，但在被计为 flops 时，它的运行量不到表现的十分之一。因此，Amdahl 的定律告诉我们，总体绩效将大大低于分析内部循环所估计的性能。

Since vector length has a significant impact on performance, the N<sub>1/2</sub> and N<sub>v</sub> measures are often used in comparing vector machines.

> 由于矢量长度对性能有重大影响，因此通常在比较向量机器时使用 N <sub> 1/2 </sub>和 N <sub> V </sub>测量值。

Example What is N<sub>1/2</sub> for just the inner loop of DAXPY for VMIPS with a 500 MHz clock?

> 示例什么是 n <sub> 1/2 </sub>仅适用于具有 500 MHz 时钟的 VMIP 的 Daxpy 的内环？

_Answer_ Using R<sub>∞</sub> as the peak rate, we want to know the vector length that will achieve about 125 MFLOPS. We start with the formula for MFLOPS assuming that the measurement is made for N<sub>1/2</sub> elements:

> _answer_使用 r <sub>∞</sub>作为峰值速率，我们想知道将达到约 125 mflops 的向量长度。我们从 MFLOPS 的公式开始，假设对 N <ub> 1/2 </sub>元素进行了测量：

For the DAXPY loop, vector mode is faster than scalar as long as the vector has at least two elements. This number is surprisingly small.

> 对于 Daxpy 循环，只要矢量至少具有两个元素，向量模式比标量更快。这个数字非常小。

### DAXPY Performance on an Enhanced VMIPS

> ### Daxpy 性能在增强的 VMIP 上

DAXPY, like many vector problems, is memory limited. Consequently, perfor- mance could be improved by adding more memory access pipelines. This is the major architectural difference between the Cray X-MP (and later processors) and the Cray-1. The Cray X-MP has three memory pipelines, compared with the Cray-1’s single memory pipeline, and the X-MP has more flexible chaining. How does this affect performance?

> 像许多向量问题一样，Daxpy 是内存有限的。因此，可以通过添加更多内存访问管道来改进孔隙。这是 Cray X-MP(以及后来的处理器)和 Cray-1 之间的主要架构差异。与 Cray-1 的单个内存管道相比，Cray X-MP 具有三个内存管道，X-MP 具有更灵活的链接。这如何影响性能？

Example What would be the value of T<sub>66</sub> for DAXPY on VMIPS if we added two more memory pipelines?

> 示例，如果我们添加了另外两个内存管道，则 t <ub> 66 </sub>对于 daxpy 的值是多少？

_Answer_ With three memory pipelines, all the instructions fit in one convoy and take one chime. The start-up overheads are the same, so

> _answer_带有三个内存管道，所有说明都适合一个车队，并拨打一个铃声。启动开销是相同的，所以

With three memory pipelines, we have reduced the clock cycle count for sustained performance from 326 to 194, a factor of 1.7. Note the effect of Amdahl’s law: We improved the theoretical peak rate as measured by the number of chimes by a factor of 3, but only achieved an overall improvement of a factor of 1.7 in sustained performance.

> 使用三个内存管道，我们将持续性能的时钟周期计数从 326 降低到 194，为 1.7。请注意 Amdahl 定律的效果：我们提高了理论上的峰值速率，这是通过铃声数量衡量的 3 倍，但仅在持续性能方面的总体提高了 1.7 倍。

Another improvement could come from allowing different convoys to overlap and also allowing the scalar loop overhead to overlap with the vector instructions. This requires that one vector operation be allowed to begin using a functional unit before another operation has completed, which complicates the instruction issue logic. Allowing this overlap eliminates the separate start-up overhead for every convoy except the first and hides the loop overhead as well.

> 允许不同的车队重叠并允许标量环上的开销与矢量说明重叠。这要求允许一个向量操作在另一个操作完成之前开始使用功能单元，这使指令问题逻辑复杂化。允许这种重叠消除除第一个车队以外的每个车队的单独启动开销，并将循环盖在头顶上。

To achieve the maximum hiding of strip-mining overhead, we need to be able to overlap strip-mined instances of the loop, allowing two instances of a convoy as well as possibly two instances of the scalar code to be in execution simulta- neously. This requires the same techniques we looked at in [Chapter 3](#_bookmark93) to avoid WAR hazards, although because no overlapped read and write of a single vector element is possible, copying can be avoided. This technique, called `tailgating_, was used in the Cray-2. Alternatively, we could unroll the outer loop to create several instances of the vector sequence using different register sets (assuming sufficient registers), just as we did in [Chapter 3](#_bookmark93). By allowing maximum overlap of the convoys and the scalar loop overhead, the start-up and loop overheads will only be seen _once` per vector sequence, independent of the number of convoys and the instructions in each convoy. In this way, a processor with vector registers can have both low start-up overhead for short vectors and high peak performance for very long vectors.

> 为了实现脱衣开采开销的最大隐藏，我们需要能够重叠循环的带状式台式实例，从而使两个车队的两个实例以及标量代码的两个实例同时执行。这需要我们在[第 3 章](#_bookmark93)中查看的相同技术以避免战争危害，尽管由于无法进行单个向量元素的重叠读写和写入，因此可以避免复制。该技术称为_tailgating_，在 cray-2 中使用。另外，就像我们在[第 3 章]中一样，我们可以使用不同的寄存器集(假设足够的寄存器)来展开外循环以创建矢量序列的几个实例(假设足够的寄存器)(#_kmark93)。通过允许车队的最大重叠和标量循环开销，每个矢量序列只能看到启动和循环开销，与车队的数量和每个车队中的指令无关。这样，带有向量寄存器的处理器既可以具有较低的启动开销，又可以用于短量矢量，而长期向量的峰值性能很高。

Example What would be the values of R<sub>∞</sub> and T<sub>66</sub> for DAXPY on VMIPS if we added two more memory pipelines and allowed the strip-mining and start-up overheads to be fully overlapped?

> 示例，如果我们添加了更多的存储器管道，并且允许 daxpy 的 r <sub>∞</sub>和 t <sub> 66 </sub>的值是什么完全重叠？

Adding the extra memory pipelines and more flexible issue logic yields an improvement in peak performance of a factor of 4. However, T<sub>66</sub> 130, so for shorter vectors the sustained performance improvement is about 326/

> 添加额外的内存管道和更灵活的问题逻辑可以提高峰值性能为 4。

Using these measures we also can find N<sub>1/2</sub> and N<sub>v</sub>, which give us another way of looking at the start-up overhead for vectors and the ratio of vector to scalar speed. A wide variety of measures of performance of vector processors is useful in under- standing the range of performance that applications may see on a vector processor.

> 使用这些度量，我们还可以找到 N <sub> 1/2 </sub>和 n <sub> v </sub>，这为我们提供了另一种查看向量的启动开销的方式以及向量与向量的比率标量速度。矢量处理器性能的各种衡量标准可用于了解应用程序在矢量处理器上可能看到的性能范围。
