## A Modern Vector Supercomputer: The Cray X1

> ##现代矢量超级计算机：cray x1

The Cray X1 was introduced in 2002, and, together with the NEC SX/8, represents the state of the art in modern vector supercomputers. The X1 system architecture supports thousands of powerful vector processors sharing a single global memory. The Cray X1 has an unusual processor architecture, shown in [Figure G.11](#_bookmark697). A large Multi-Streaming Processor (MSP) is formed by ganging together four Single- Streaming Processors (SSPs). Each SSP is a complete single-chip vector micropro- cessor, containing a scalar unit, scalar caches, and a two-lane vector unit. The SSP scalar unit is a dual-issue out-of-order superscalar processor with a 16 KB instruc- tion cache and a 16 KB scalar write-through data cache, both two-way set associa- tive with 32-byte cache lines. The SSP vector unit contains a vector register file, three vector arithmetic units, and one vector load-store unit. It is much easier to pipeline deeply a vector functional unit than a superscalar issue mechanism, so the X1 vector unit runs at twice the clock rate (800 MHz) of the scalar unit (400 MHz). Each lane can perform a 64-bit floating-point add and a 64-bit floating-point multiply each cycle, leading to a peak performance of 12.8 GFLOPS per MSP.

> Cray X1 于 2002 年引入，并与 NEC SX/8 一起代表现代矢量超级计算机中的最新状态。X1 系统体系结构支持成千上万的强大矢量处理器共享单个全局内存。Cray X1 具有不寻常的处理器体系结构，如[图 G.11](#_ bookmark697)。通过将四个单流处理器(SSP)组合在一起来形成大型多流处理器(MSP)。每个 SSP 都是一个完整的单芯片矢量微型辅助器，其中包含标量单元，标量缓存和两个车道矢量单元。SSP 标量单元是具有 16 kb 的指令缓存和 16 kb 标量的数据缓存的双级超级量表处理器，均为 32 个字节 cache 线路。SSP 矢量单元包含一个向量寄存器文件，三个向量算术单元和一个向量载荷店单元。与超级标准单元相比，深入矢量功能单元的管道要容易得多，因此 X1 矢量单元以标量单元(400 MHz)的时钟速率(800 MHz)的两倍(800 MHz)运行。每个车道可以执行 64 位浮点添加，每个循环 64 位浮点乘以每个周期，从而导致每 MSP 的峰值性能为 12.8 GFLOPS。

All previous Cray machines could trace their instruction set architecture (ISA) lineage back to the original Cray-1 design from 1976, with 8 primary registers each for addresses, scalar data, and vector data. For the X1, the ISA was redesigned from scratch to incorporate lessons learned over the last 30 years of compiler and micro- architecture research. The X1 ISA includes 64 64-bit scalar address registers and 64 64-bit scalar data registers, with 32 vector data registers (64 bits per element) and 8 vector mask registers (1 bit per element). The large increase in the number of registers allows the compiler to map more program variables into registers to reduce memory traffic and also allows better static scheduling of code to improve run time overlap of instruction execution. Earlier Crays had a compact variable- length instruction set, but the X1 ISA has fixedlength instructions to simplify superscalar fetch and decode.

> 所有以前的 Cray 机器都可以将其指令集体系结构(ISA)谱系追溯到 1976 年的原始 Cray-1 设计，每个主要寄存器都用于地址，标量数据和向量数据。对于 X1，ISA 从头开始重新设计，以结合过去 30 年的编译器和微观建筑研究中学习的经验教训。X1 ISA 包括 64 位 64 位标量地址寄存器和 64 位 64 位标量数据寄存器，其中有 32 个向量数据寄存器(每个元素 64 位)和 8 个向量蒙版寄存器(每个元素 1 位)。寄存器数量的大量增加使编译器可以将更多程序变量映射到寄存器中，以减少内存流量，还可以更好地静态代码调整代码，以改善指令执行的运行时间重叠。较早的 Crays 具有紧凑的可变长度指令集，但是 X1 ISA 具有固定长度指令，可以简化 SuperScalar 提取和解码。

Figure G.11 Cray MSP module. (From [Dunnigan et al. \[2005\]](#_bookmark707).)

> 图 G.11 Cray MSP 模块。(摘自[Dunnigan 等人。\ [2005 \]](#_ bookmark707)。

Four SSP chips are packaged on a multichip module together with four cache chips implementing an external 2 MB cache (Ecache) shared by all the SSPs. The Ecache is two-way set associative with 32-byte lines and a write-back policy. The Ecache can be used to cache vectors, reducing memory traffic for codes that exhibit temporal locality. The ISA also provides vector load and store instruction variants that do not allocate in cache to avoid polluting the Ecache with data that is known to have low locality. The Ecache has sufficient bandwidth to supply one 64-bit word per lane per 800 MHz clock cycle, or over 50 GB/sec per MSP.

> 将四个 SSP 芯片包装在 Multichip 模块上，以及四个缓存芯片，这些芯片实现了所有 SSP 共享的外部 2 MB 缓存(ECACHE)。ECACHE 是带有 32 字节线的双向套件关联和一个书面策略。ECACHE 可用于缓存向量，减少显示时间局部性的代码的内存流量。ISA 还提供了向量负载和存储指令变体，这些变体不会在缓存中分配，以避免使用已知具有较低位置的数据污染 Ecache。ECACHE 具有足够的带宽，每 800 MHz 时钟周期每条车道或每 MSP 超过 50 GB/sec。

At the next level of the X1 packaging hierarchy, shown in [Figure G.12](#_bookmark698), four MSPs are placed on a single printed circuit board together with 16 memory con- troller chips and DRAM to form an X1 node. Each memory controller chip has eight separate Rambus DRAM channels, where each channel provides 1.6 GB/ sec of memory bandwidth. Across all 128 memory channels, the node has over 200 GB/sec of main memory bandwidth.

> 在[图 G.12](#_ bookmark698)所示的 X1 包装层次结构的下一个级别上，将四个 MSP 放在单个印刷电路板上，以及 16 个存储器控制器芯片和 DRAM，以形成 X1 节点。每个内存控制器芯片都有八个独立的 Rambus DRAM 通道，每个通道提供 1.6 GB/ sec 的内存带宽。在所有 128 个内存通道中，节点具有超过 200 GB/sec 的主内存带宽。

An X1 system can contain up to 1024 nodes (4096 MSPs or 16,384 SSPs), connected via a very high-bandwidth global network. The network connections are made via the memory controller chips, and all memory in the system is directly accessible from any processor using load and store instructions. This provides much faster global communication than the message-passing protocols used in cluster-based systems. Maintaining cache coherence across such a large number of high-bandwidth shared-memory nodes would be challenging. The approach taken in the X1 is to restrict each Ecache to cache data only from the local node DRAM. The memory controllers implement a directory scheme to maintain

> X1 系统可以包含高达 1024 个节点(4096 个 MSP 或 16,384 SSP)，该节点通过非常高的全局网络连接。网络连接是通过内存控制器芯片进行的，并且系统中的所有内存都可以使用负载和存储指令直接从任何处理器访问。与基于群集的系统中使用的消息通信相比，这提供了更快的全局通信。在如此大量的高带宽共享内存节点上保持缓存连贯性将是具有挑战性的。X1 中采用的方法是将每个 Ecache 限制为仅从局部节点 DRAM 中缓存数据。内存控制器实施了目录方案以维护

![](./media/image734.png)

Figure G.12 Cray X1 node. (From [Tanqueray \[2002\]](#_bookmark716).)

> 图 G.12 Cray X1 节点。(来自[tanqueray \ [2002 \]](#_ bookmark716)。

coherency between the four Ecaches on a node. Accesses from remote nodes will obtain the most recent version of a location, and remote stores will invalidate local Ecaches before updating memory, but the remote node cannot cache these local locations.

> 节点上四个 Ecaches 之间的相干性。从远程节点访问将获得位置的最新版本，并且在更新内存之前，远程商店将使本地 Ecaches 无效，但是远程节点不能缓存这些本地位置。

Vector loads and stores are particularly useful in the presence of long-latency cache misses and global communications, as relatively simple vector hardware can generate and track a large number of in-flight memory requests. Contemporary superscalar microprocessors support only 8 to 16 outstanding cache misses, whereas each MSP processor can have up to 2048 outstanding memory requests (512 per SSP). To compensate, superscalar microprocessors have been moving to larger cache line sizes (128 bytes and above) to bring in more data with each cache miss, but this leads to significant wasted bandwidth on non-unit stride accesses over large datasets. The X1 design uses short 32-byte lines throughout to reduce bandwidth waste and instead relies on supporting many independent cache misses to sustain memory bandwidth. This latency tolerance together with the huge memory bandwidth for non-unit strides explains why vector machines can provide large speedups over superscalar microprocessors for certain codes.

> 向量负载和存储在存在长期缓存错过和全局通信的情况下特别有用，因为相对简单的矢量硬件可以生成和跟踪大量飞行的内存请求。当代超量表微处理器仅支持 8 至 16 个杰出的缓存遗失，而每个 MSP 处理器最多可以有 2048 个出色的内存请求(每 SSP 512)。为了进行补偿，超级计算机已经移至较大的高速缓存线大小(128 个字节及以上)，以引入更多数据，每次高速缓存失误都会导致在大型数据集上的非单元步幅访问中大量浪费的带宽。X1 设计在整个整个过程中都使用短 32 字节线来减少带宽浪费，而依赖于支持许多独立的缓存失误来维持内存带宽。这种延迟的耐受性以及非单位进步的巨大内存带宽解释了为什么向量机可以在某些代码的超尺度微处理器上提供大加速器。

### Multi-Streaming Processors

> ###多流处理器

The Multi-Streaming concept was first introduced by Cray in the SV1, but has been considerably enhanced in the X1. The four SSPs within an MSP share Ecache, and there is hardware support for barrier synchronization across the four SSPs within an MSP. Each X1 SSP has a two-lane vector unit with 32 vector registers each holding 64 elements. The compiler has several choices as to how to use the SSPs within an MSP.

> 多流概念首先是由 Cray 在 SV1 中引入的，但在 X1 中得到了相当大的增强。MSP 共享 ECACHE 中的四个 SSP，并且在 MSP 中的四个 SSP 上都有硬件支持对屏障同步。每个 X1 SSP 都有一个两车道矢量单元，每个 XSP 具有 32 个矢量寄存器，每个载体都保持 64 个元素。关于如何在 MSP 中使用 SSP 的编译器有多种选择。

The simplest use is to gang together four two-lane SSPs to emulate a single eight-lane vector processor. The X1 provides efficient barrier synchronization primitives between SSPs on a node, and the compiler is responsible for generating the MSP code. For example, for a vectorizable inner loop over 1000 elements, the compiler will allocate iterations 0–249 to SSP0, iterations 250–499 to SSP1, iter- ations 500–749 to SSP2, and iterations 750–999 to SSP3. Each SSP can process its loop iterations independently but must synchronize back with the other SSPs before moving to the next loop nest.

> 最简单的用途是将四个两车道 SSP 组合在一起以模拟单个八车道矢量处理器。X1 在节点上的 SSP 之间提供了有效的屏障同步原语，并且编译器负责生成 MSP 代码。例如，对于超过 1000 个元素的可矢量性内部环，编译器将迭代 0–249 为 SSP0，迭代 250-499 为 SSP1，迭代 500-749 和 SSP2，并将 750-999 分配给 SSP2。每个 SSP 都可以独立处理其循环迭代，但必须在移至下一个循环巢之前与其他 SSP 同步。

If inner loops do not have many iterations, the eight-lane MSP will have low efficiency, as each SSP will have only a few elements to process and execution time will be dominated by start-up time and synchronization overheads. Another way to use an MSP is for the compiler to parallelize across an outer loop, giving each SSP a different inner loop to process. For example, the following nested loops scale the upper triangle of a matrix by a constant:

> 如果内部循环没有太多迭代，则八车道 MSP 的效率较低，因为每个 SSP 只有几个要处理的元素，并且执行时间将由启动时间和同步开销主导。使用 MSP 的另一种方法是使编译器在外循环中并行化，从而使每个 SSP 都有不同的内部循环进行处理。例如，以下嵌套环按常数缩放矩阵的上三角形：

Consider the case where MAX_ROWS and MAX_COLS are both 100 elements. The vector length of the inner loop steps down from 100 to 1 over the iterations of the outer loop. Even for the first inner loop, the loop length would be much less than the maximum vector length (256) of an eight-lane MSP, and the code would therefore be inefficient. Alternatively, the compiler can assign entire inner loops to a single SSP. For example, SSP0 might process rows 0, 4, 8, and so on, while SSP1 processes rows 1, 5, 9, and so on. Each SSP now sees a longer vector. In effect, this approach parallelizes the scalar overhead and makes use of the individual scalar units within each SSP.

> 考虑 max_rows 和 max_cols 都是 100 个元素的情况。内环的矢量长度从外回路的迭代中从 100 下降到 1。即使对于第一个内部循环，循环长度也将远小于八车道 MSP 的最大向量长度(256)，因此代码效率低下。或者，编译器可以将整个内部循环分配给单个 SSP。例如，SSP0 可能处理行 0、4、8 等，而 SSP1 处理行 1、5、9 等。现在每个 SSP 都看到一个更长的向量。实际上，这种方法使标量顶间接下来并使用每个 SSP 中的单个标量单元。

Most application code uses MSPs, but it is also possible to compile code to use all the SSPs as individual processors where there is limited vector parallelism but significant thread-level parallelism.

> 大多数应用程序代码都使用 MSP，但是也可以编译代码将所有 SSP 用作有限的矢量并行性但具有重要的线程级并行性的单个处理器。

### Cray X1E

> ### cray x1e

In 2004, Cray announced an upgrade to the original Cray X1 design. The X1E uses newer fabrication technology that allows two SSPs to be placed on a single chip, making the X1E the first multicore vector microprocessor. Each physical node now contains eight MSPs, but these are organized as two logical nodes of four MSPs each to retain the same programming model as the X1. In addition, the clock rates were raised from 400 MHz scalar and 800 MHz vector to 565 MHz scalar and 1130 MHz vector, giving an improved peak performance of 18 GFLOPS.

> 2004 年，克雷宣布对原始 Cray X1 设计进行升级。X1E 使用较新的制造技术，该技术允许将两个 SSP 放在单个芯片上，从而使 X1E 成为第一个多核矢量微处理器。现在每个物理节点包含八个 MSP，但是将它们组织为两个逻辑节点，分别为四个 MSP，以保留与 X1 相同的编程模型。此外，将时钟速率从 400 MHz 标量和 800 MHz 矢量提高到 565 MHz 标量和 1130 MHz 矢量，从而提高了 18 GFLOPS 的峰值性能。
