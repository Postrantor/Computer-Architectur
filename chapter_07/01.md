## Introduction

> ＃＃ 介绍

Gordon Moore not only predicted the amazing growth of transistors per chip in 1965, but the opening chapter quote shows that he also predicted its demise

> 戈登·摩尔（Gordon Moore）不仅预测了 1965 年每芯片晶体管的惊人增长，而且开幕章节表明他还预测了它的灭亡

50 years later. As evidence, [Figure 7.1](#_bookmark325) shows that even the company he founded—which for decades proudly used Moore’s Law as a guideline for capital investment—is slowing its development of new semiconductor processes.

> 50 年后。作为证据，[图 7.1]（#\_ bookmark325）表明，即使是他创立的公司（数十年来自豪地使用摩尔法律作为资本投资的指南）也在减慢其新的半导体流程的发展。

During the semiconductor boom time, architects rode Moore’s Law to create novel mechanisms that could turn the cornucopia of transistors into higher perfor- mance. The resources for a five-stage pipeline, 32-bit RISC processor—which needed as little as 25,000 transistors in the 1980s—grew by a factor of 100,000 to enable features that accelerated general-purpose code on general-purpose processors, as earlier chapters document:

> 在半导体的繁荣时间里，建筑师骑着摩尔定律，创造出可以将晶体管的聚宝盆变成更高的性能的新型机制。五阶段管道，32 位 RISC 处理器的资源（1980 年代仅需要 25,000 个晶体管）的资源增加了 100,000 倍，以实现在通用处理器上加速通用代码的功能，如前章文档：

- 1st-level, 2nd-level, 3rd-level, and even 4th-level caches

> - 第一级，第二级，第三级，甚至是 4 级缓存

- 512-bit SIMD floating-point units

> -512 位 SIMD 浮点单位

- 15 + stage pipelines

> -15 + 舞台管道

- Branch prediction

> - 分支预测

- Out-of-order execution

> - 排序执行

- Speculative prefetching

> - 投机性预取

- Multithreading

> - 多线程

- Multiprocessing

> - 多处理

These sophisticated architectures targeted million-line programs written in effi- cient languages like C++. Architects treated such code as black boxes, generally without understanding either the internal structure of the programs or even what they were trying to do. Benchmark programs like those in SPEC2017 were just artifacts to measure and accelerate. Compiler writers were the people at the hardware-software interface, which dates back to the RISC revolution in the 1980s, but they have limited understanding of the high-level application behavior; that’s why compilers cannot even bridge the semantic gap between C or C++ and the architecture of GPUs.

> 这些复杂的体系结构针对的是以 C ++ 等有效语言编写的百万行计划。建筑师处理了像黑匣子这样的代码，通常不了解程序的内部结构，甚至不了解他们试图做的事情。像 Spec2017 这样的基准计划只是衡量和加速的工件。编译器作家是硬件软件界面的人，其历史可以追溯到 1980 年代的 RISC 革命，但他们对高级应用程序行为的了解有限。这就是为什么编译器甚至无法弥合 C 或 C ++ 之间的语义差距以及 GPU 的体系结构的原因。

Figure 7.1 Time before new Intel semiconductor process technology measured in nm. The _y_-axis is log scale. Note that the time stretched previously from about 24 months per new process step to about 30 months since 2010.

> 图 7.1 新英特尔半导体工艺技术在 NM 中测得的时间。_y_-axis 是日志刻度。请注意，以前从新过程步骤大约 24 个月延长到自 2010 年以来约 30 个月的时间。

As [Chapter 1](#_bookmark2) described, Dennard scaling ended much earlier than Moore’s Law. Thus more transistors switching now means more power. The energy budget is not increasing, and we’ve already replaced the single inefficient processor with multiple efficient cores. Hence, we have nothing left up our sleeves to continue major improvements in cost-performance and energy efficiency for general- purpose architectures. Because the energy budget is limited (because of electromi- gration, mechanical and thermal limits of chips), if we want higher performance (higher operations/second), we need to lower the energy per operation.

> 如[第 1 章]（#\_ bookmark2）所述，丹纳德缩放比摩尔定律早得多。因此，现在更多的晶体管切换意味着更多的功率。能源预算没有增加，我们已经用多个有效的核心代替了单个效率低下的处理器。因此，我们没有什么可以继续袖手旁观，可以继续在成本效率和能源效率方面取得重大改善。由于能源预算受到限制（由于电气，机械和热限制的芯片），因此，如果我们想要更高的性能（较高的操作/秒），我们需要降低每次操作的能量。

[Figure 7.2](#_bookmark326) is another take on the relative energy costs of memory and logic mentioned in [Chapter 1](#_bookmark2), this time calculated as overhead for an arithmetic instruc- tion. Given this overhead, minor twists to existing cores may get us 10% improve- ments, but if we want order-of-magnitude improvements while offering programmability, we need to increase the number of arithmetic operations per instruction from one to hundreds. To achieve that level of efficiency, we need a drastic change in computer architecture from general-purpose cores to _domain- specific architectures (DSAs)._

> [图 7.2]（#_ bookmark326）是[第 1 章]（#_ bookmark2）中提到的记忆和逻辑的相对能量成本的另一种看法，这次是算术乐器的开销。鉴于此开销，对现有核心的次要扭曲可能会使我们提高 10％的改善，但是如果我们希望在提供可编程性的同时提高速度级别，则我们需要将每个说明的算术操作数量增加到数百个。为了达到这种效率，我们需要从通用核心到* domain-特定体系结构（DSA）的计算机体系结构进行巨大变化。*

Thus, just as the field switched from uniprocessors to multiprocessors in the past decade out of necessity, desperation is the reason architects are now working on DSAs. The new normal is that a computer will consist of standard processors to run conventional large programs such as operating systems along with domain- specific processors that do only a narrow range of tasks, but they do them extremely well. Thus such computers will be much more heterogeneous than the homogeneous multicore chips of the past.

> 因此，正如在过去十年中，由于必要时，该领域从单层处理器转换为多处理器一样，绝望也是建筑师现在在 DSA 上工作的原因。新的常态是，计算机将由标准处理器组成，可以运行常规的大型程序，例如操作系统以及域 - 特定处理器，这些处理器仅执行狭窄的任务，但它们的功能非常出色。因此，这样的计算机将比过去的均匀多芯片更异质。

Figure 7.2 Energy costs in picoJoules for a 90 nm process to fetch instructions or access a data cache compared to the energy cost of arithmetic operations ([Qadeer et al., 2015](#_bookmark993)).

> 图 7.2 与算术操作的能源成本相比，Picojoules 的能源成本用于 90 nm 的过程，以获取指令或访问数据缓存（[[Qadeer 等，2015]（#\_ bookmark993））。

Part of the argument is that the preceding architecture innovations from the past few decades that leveraged Moore’s Law (caches, out-of-order execution, etc.) may not be a good match to some domains—especially in terms of energy usage—so their resources can be recycled to make the chip a better match to the domain. For example, caches are excellent for general-purpose architectures, but not necessarily for DSAs; for applications with easily predictable memory access patterns or huge data sets like video that have little data reuse, multilevel caches are overkill, hording area and energy that could be put to better use. There- fore the promise of DSAs is both improved silicon efficiency and better energy efficiency, with the latter typically being the more important attribute today.

> 论点的一部分是，过去几十年来，利用摩尔定律（缓存，订购执行等）的架构创新可能与某些领域（尤其是在能源使用方面 - 因此）可能并不是一个很好的匹配。他们的资源可以回收利用，使芯片与域更好匹配。例如，缓存非常适合通用体系结构，但不一定对 DSA 进行。对于具有易于预测的内存访问模式的应用程序或诸如很少数据重用的视频集之类的应用程序，多级缓存是过度的，可以更好地利用的杀伤力，部落区域和能量。因此，DSA 的希望既提高了硅效率，又是更好的能源效率，后者通常是当今更重要的属性。

Architects probably won’t create a DSA for a large C++ program like a com- piler as found in the SPEC2017 benchmark. Domain-specific algorithms are almost always for small compute-intensive kernels of larger systems, such as for object recognition or speech understanding. DSAs should focus on the subset and not plan to run the entire program. In addition, changing the code of the bench- mark is no longer breaking the rules; it is a perfectly valid source of speedup for DSAs. Consequently, if they are going to make useful contributions, architects interested in DSA must now shed their blinders and learn application domains and algorithms.

> 建筑师可能不会为 Spec2017 基准中发现的大型 C ++ 程序创建 DSA。域特异性算法几乎总是用于大型系统的小型计算密集型内核，例如对象识别或语音理解。DSA 应专注于子集，而不是计划运行整个程序。此外，更改台式的代码不再打破规则。它是 DSA 的速度的完全有效的来源。因此，如果他们要做出有用的贡献，对 DSA 感兴趣的建筑师现在必须丢掉他们的盲人并学习应用域和算法。

In addition to needing to expand their areas of expertise, a challenge for domain-specific architects is to find a target whose demand is large enough to jus- tify allocating dedicated silicon on an SOC or even a custom chip. The _nonrecur- ring engineering (NRE)_ costs of a custom chip and supporting software are amortized over the number of chips manufactured, so it is unlikely to make eco- nomic sense if you need only 1000 chips.

> 除了需要扩大其专业知识领域外，针对特定领域的建筑师的挑战是找到一个目标，该目标的需求足够大，可以在 SOC 甚至定制芯片上分配专用的硅。定制芯片和支持软件的成本\_nonRecur-Ring 工程（NRE）在制造的芯片数量上被摊销，因此，如果您只需要 1000 个芯片，则不太可能具有环保意义。

One way to accommodate smaller volume applications is to use reconfigurable chips such as FPGAs because they have lower NRE than custom chips _and_ because several different applications may be able to reuse the same reconfigurable hard- ware to amortize its costs (see [Section 7.5](#microsoft-catapult-a-flexible-data-center-accelerator)). However, since the hardware is less efficient than custom chips, the gains from FPGAs are more modest.

> 容纳较小批量应用程序的一种方法是使用可重构芯片（例如 FPGA），因为它们的 NRE 低于自定义芯片*和*，因为几个不同的应用程序可能能够重复使用相同的可重新配置的硬性 - 以摊销其成本（请参见[7.5]（请参阅[[7.5]（请参阅[[7.5]（请参阅[[7.5]）＃microsoft-catapult-a-flexible-data-center-accelerator）。但是，由于硬件的效率不如自定义芯片，因此 FPGA 的收益更为适中。

Another DSA challenge is how to port software to it. Familiar programming environments like the C++ programming language and compiler are rarely the right vehicles for a DSA.

> DSA 的另一个挑战是如何向其移植软件。熟悉的编程环境（例如 C ++ 编程语言和编译器）很少是 DSA 的正确工具。

The rest of this chapter provides five guidelines for the design of DSAs and then a tutorial on our example domain, which is _deep neural networks_ (_DNNs_). We chose DNNs because they are revolutionizing many areas of computing today. Unlike some hardware targets, DNNs are applicable to a wide range of problems, so we can reuse a DNN-specific architecture for solutions in speech, vision, lan- guage, translation, search ranking, and many more areas.

> 本章的其余部分为 DSA 的设计提供了五个指南，然后提供了有关我们示例域的教程，即 *Deep Neural Networks*（_DNNS_）。我们之所以选择 DNN，是因为它们正在彻底改变当今计算的许多领域。与某些硬件目标不同，DNN 适用于广泛的问题，因此我们可以在语音，视觉，语言，翻译，搜索排名和更多领域的语音，视觉，语言，语言，翻译，搜索排名和更多领域的解决方案中重复使用 DNN 特定的架构。

We follow with four examples of DSAs: two custom chips for the data center that accelerate DNNs, an FPGA for the data center that accelerates many domains, and an image-processing unit designed for _personal mobile devices_ (_PMDs_). We then compare the cost-performance of the DSAs along with CPUs and GPUs using DNN benchmarks, and conclude with a prediction of an upcoming renaissance for computer architecture.

> 我们遵循 DSA 的四个示例：数据中心的两个自定义芯片，这些芯片加速了 DNN，这是一个加速许多域的数据中心的 FPGA，以及为 *personal Mobile Devices*（_PMDS_）设计的图像处理单元。然后，我们使用 DNN 基准比较了 DSA 与 CPU 和 GPU 的成本绩效，并以预测即将进行的计算机架构文艺复兴时期的预测。
