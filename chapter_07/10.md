## Concluding Remarks

> ##总结

In this chapter, we’ve seen several commercial examples of the recent shift from the traditional goal of improving general-purpose computers so that all programs benefit to accelerating a subset of programs with DSAs.

> 在本章中，我们已经看到了几个商业示例，这些示例最近从改进通用计算机的传统目标转变，以便所有程序都受益于加速使用 DSA 的程序。

Both versions of Catapult preserved data-center homogeneity by designing a small, low-power FPGA board that could fit inside a server. The hope is that the flexibility of FPGAs will allow Catapult to be useful to many current applica- tions and the new ones that appeared after deployment. Catapult runs search rank and CNNs faster than GPUs, offering a 1.5–1.75 gain in performance/TCO for ranking over CPUs.

> 这两个版本的弹射器都保留了数据中心的均匀性，它通过设计一个适合服务器内部的小型低功耗 FPGA 板。希望 FPGA 的灵活性将使弹射器对许多当前应用程序和部署后出现的新应用程序有用。弹射器的搜索排名和 CNN 的运行速度比 GPU 的速度快，在 CPU 上排名的性能/TCO 的增长率为 1.5-1.75。

The TPU project actually began with FPGAs but abandoned them when the designers concluded that the FPGAs of that time were not competitive in perfor- mance compared to the GPUs. They also believed the TPU would use much less power than GPUs, while being as fast or faster, potentially making the TPU much better than FPGAs and GPUs. Finally, the TPU was not the device that broke data center homogeneity at Google because some servers in its data centers already had GPUs. The TPU basically followed in the footsteps of the GPU and was just another type of accelerator.

> TPU 项目实际上是从 FPGA 开始的，但是当设计师得出结论认为，与 GPU 相比，当时的 FPGA 在演奏中没有竞争力。他们还认为，TPU 的功率将比 GPU 少得多，同时快速或更快，可能使 TPU 比 FPGA 和 GPU 好得多。最后，TPU 不是在 Google 上打破数据中心同质性的设备，因为其数据中心中的一些服务器已经具有 GPU。TPU 基本上跟随 GPU 的脚步，只是另一种类型的加速器。

The nonrecurring engineering costs were likely much higher for the TPU than for Catapult, but the rewards were also greater: both performance and performance/ watt were much higher for an ASIC than for an FPGA. The risk was that the TPU was appropriate only for DNN inference, but as we mentioned, DNNs are an attrac- tive target because they can potentially be used for many applications. In 2013

> TPU 的非重新工程成本可能比弹射器高得多，但是回报也更高：ASIC 的性能和性能/瓦特都比 FPGA 高得多。风险是 TPU 仅适用于 DNN 推断，但是正如我们提到的那样，DNN 是一个吸引人的目标，因为它们可能可用于许多应用。2013 年

Google’s management took a leap of faith by trusting that the DNN requirements in 2015 and beyond would justify investment in the TPU.

> Google 的管理层通过相信 2015 年及以后的 DNN 要求将证明对 TPU 的投资是合理的，从而实现了信心。

The deterministic execution model of both Catapult and the TPU is a better match to the response-time deadline of user-facing applications than are the time-varying optimizations of CPUs and GPUs (caches, out-of-order execution, multithreading, multiprocessing, prefetching, etc.) that help average throughput more than latency. The lack of such features helps explain why, despite having myriad ALUs and a big memory, the TPU is relatively small and low powered. This achievement suggests a “Cornucopia Corollary” to Amdahl’s Law: _low uti- lization of a huge, cheap resource can still deliver high, cost-effective performance_.

> 弹射器和 TPU 的确定性执行模型与 CPU 和 GPU 的时间变化优化（caches，caches，doutder-Orderecution，MultineReading，MultineReading，MultinProcessing，多处理，多处理，多处理，多处理，多处理，多处理，多处理预摘要等）比延迟更有助于平均吞吐量。缺乏此类功能有助于解释为什么尽管有多种 Alus 和巨大的记忆，但 TPU 的功率相对较小和低功率。这项成就暗示了 Amdahl 定律的“聚宝盆推论”：\_LOW UTI-LIZATION 具有巨大，便宜的资源仍然可以提供高，具有成本效益的性能。

In summary, the TPU succeeded for DNNs because of the large matrix unit; the substantial software-controlled on-chip memory; the ability to run whole inference models to reduce dependence on host CPU; a single-threaded, deterministic exe- cution model that proved to be a good match to 99th-percentile response-time limits; enough flexibility to match the DNNs of 2017 as well as of 2013; the omis- sion of general-purpose features that enabled a small and low-power die despite the larger datapath and memory; the use of 8-bit integers by the quantized applications; and the fact that applications were written using TensorFlow, which made it easy to port them to the DSA at high-performance rather than having to rewrite them in order for them to run well on the very different hardware.

> 总而言之，由于矩阵较大的单元，TPU 成功获得了 DNN。大量软件控制的片上内存；运行整个推理模型以减少对主机 CPU 的依赖的能力；一个单线程，确定性的审查模型，被证明是与第 99 级响应时间限制的良好匹配；足够的灵活性与 2017 年和 2013 年的 DNN 匹配；尽管数据和内存较大，但通用功能的限制使小型和低功能都可以死亡。通过量化应用程序使用 8 位整数；以及应用程序使用 TensorFlow 编写的事实，这使其很容易以高性能将其移植到 DSA，而不是必须重写它们以使其在截然不同的硬件上运行良好。

Pixel Visual Core demonstrated the constraints of designing a DSA for a PMD in terms of die size and power. Unlike the TPU, it is a separate processor from the host that fetches its own instructions. Despite being aimed primarily at computer vision, Pixel Visual Core can run CNNs one to two orders of magnitude better in performance/watt than the K80 GPU and the Haswell CPU.

> Pixel Visual Core 展示了在模具大小和功率方面为 PMD 设计 DSA 的限制。与 TPU 不同，它是与主机单独的处理器，可以获取自己的说明。尽管主要针对的是计算机视觉，但像素视觉核心的性能/瓦特可以比 K80 GPU 和 Haswell CPU 更好地运行 CNN。

It’s too early to render judgment on the Intel Crest, although its enthusiastic announcement by the Intel CEO signals a shift in the computing landscape.

> 现在对英特尔波雷斯特（Intel Crest）做出判断还为时过早，尽管英特尔首席执行官的热情宣布信号是计算景观的转变。

##### _An Architecture Renaissance_

> ##### _建筑文艺复兴时期_

For at least the past decade, architecture researchers have been publishing innova- tions based on simulations using limited benchmarks claiming improvements for general-purpose processors of _10% or less_ while companies are now reporting gains for DSA hardware products of _10 times or more_.

> 至少在过去的十年中，建筑研究人员一直基于模拟来发布创新，使用有限的基准测试，声称对\_10％或更少的通用处理器进行改进，而公司现在正在报告\_10 次或更多\_10 次或更多\_10 的 DSA 硬件产品。

We think that is a sign that the field is undergoing a transformation, and we expect to see a renaissance in architecture innovation in the next decade because of

> 我们认为这是一个迹象表明该领域正在经历转型，我们希望在未来十年内看到建筑创新的文艺复兴

- the historic end of both Dennard scaling and Moore’s Law, which means improving cost-energy-performance will require innovation in computer architecture;

> - 丹纳德·比尔（Dennard Scaling）和摩尔定律（Moore）定律的历史性结局，这意味着提高成本能量的绩效将需要计算机架构的创新；

- the productivity advances in building hardware from both Agile hardware development and new hardware design languages that leverage advances in modern programming languages;

> - 从敏捷硬件开发和新的硬件设计语言中构建硬件的生产力进步，这些语言利用现代编程语言的进步；

- the reduced cost of hardware development because of free and open instruction sets, open-source IP blocks, and commercial IP blocks (which so far is where most DSAs are found);

> - 由于免费和开放的指令集，开源 IP 块和商业 IP 块（到目前为止，大多数 DSA 的位置），硬件开发成本的降低；

- the improvements mentioned above in productivity and cost of development means researchers can afford to demonstrate their ideas by building them in FPGAs or even in custom chips, instead of trying to convince skeptics with simulators; and

> - 上面提到的生产力和发展成本的改进意味着研究人员可以通过在 FPGA 甚至定制筹码中构建它们来证明其想法，而不是试图用模拟器说服怀疑论者；和

- the potential upside of DSAs and their synergy with domain-specific program- ming languages.

> - DSA 的潜在上行及其与特定领域的程序和语言的协同作用。

We believe that many architecture researchers will build DSAs that will raise the bar still higher than those discussed in this chapter. And we can’t wait to see what the computer architecture world will look like by the next edition of this book!

> 我们认为，许多建筑研究人员将构建 DSA，这些 DSA 将提高比本章讨论的标准更高。我们迫不及待地想看看本书的下一版本的计算机架构世界将是什么样的！
