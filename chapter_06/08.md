## Historical Perspectives and References

Section M.8 (available online) covers the development of clusters that were the foundation of WSC and of utility computing. (Readers interested in learning more should start with [Barroso et al. (2013)](#_bookmark925) and the blog postings of James Hamilton at _[http://perspectives.mvdirona.com](http://perspectives.mvdirona.com/)_ plus his talks at the annual Amazon Re-Invent conference.)

## Case Studies and Exercises by Parthasarathy Ranganathan

### Case Study 1: Total Cost of Ownership Influencing Warehouse-Scale Computer Design Decisions

##### _Concepts illustrated by this case study_

- Total Cost of Ownership (TCO)
- Influence of Server Cost and Power on the Entire WSC
- Benefits and Drawbacks of Low-Power Servers

Total cost of ownership is an important metric for measuring the effectiveness of a warehouse-scale computer (WSC). TCO includes both the CAPEX and OPEX described in Section 6.4, and reflects the ownership cost of the entire datacenter to achieve a certain level of performance. In considering different servers, networks, and storage architectures, TCO is often the most important comparison metric used by datacenter owners to decide which options are best; however, TCO is a multidimensional computation that takes into account many different factors. The goal of this case study is to take a detailed look into WSCs, to see how different architectures influence TCO, and to understand how TCO drives operator deci- sions. This case study will use the numbers from Figures 6.13 and 6.14 and Section 6.4, and assumes that the described WSC achieves the operator’s target level of performance. TCO is often used to compare different server options that have mul- tiple dimensions. The exercises in this case study examine how such comparisons are made in the context of WSCs and the complexity involved in making the decisions.

1. \[5/5/10\] &lt;6.2, 6.4 &gt;In this chapter, data-level parallelism has been discussed as a way for WSCs to achieve high performance on large problems. Conceivably, even greater performance can be obtained by using high-end servers; however, higher performance servers often come with a nonlinear price increase.
2. \[5\] &lt;6.4 &gt;Assuming servers that are 10% faster at the same utilization, but are 20% more expensive, what is the CAPEX for the WSC?
3. \[5\] &lt;6.4 &gt;If those servers also use 15% more power, what is the OPEX of the warehouse-scale computer?
4. \[10\] &lt;6.2, 6.4 &gt;Given the speed improvement and power increase, what must the cost of the new servers be to be comparable to the original cluster? (_Hint:_ Based on this TCO model, you may have to change the critical load of the facility.)
5. \[5/10\] &lt;6.4, 6.6, 6.8 &gt;To achieve a lower OPEX, one appealing alternative is to use low-power versions of servers to reduce the total electricity required to run the servers; however, similar to high-end servers, low-power versions of high-end components also have nonlinear trade-offs.
6. \[5\] &lt;6.4, 6.6, 6.8 &gt;If low-power server options offered 15% lower power at the same performance but are 20% more expensive, are they a good trade-off?
7. \[10\] &lt;6.4, 6.6, 6.8 &gt;At what cost do the servers become comparable to the original cluster? What if the price of electricity doubles?

<!-- -->

1. \[5/10/15\] &lt;6.4, 6.6 &gt;Servers that have different operating modes offer opportuni- ties for dynamically running different configurations in the cluster to match work- load usage. Use the data in [Figure 6.35](#_bookmark316) for the power/performance modes for a given low-power server.
2. \[5\] &lt;6.4, 6.6 &gt;If a server operator decided to save power costs by running all servers at medium performance, how many servers would be needed to achieve the same level of performance?
3. \[10\] &lt;6.4, 6.6 &gt;What are the CAPEX and OPEX of such a configuration?

Figure 6.35 Power–performance modes for low-power servers.

1. \[15\] &lt;6.4, 6.6 &gt;If there was an alternative where you could purchase a server that is 20% cheaper but _x_% slower and uses _y_% less power, find the perfor- mance–power curve that provides a TCO comparable to the baseline server.
2. \[Discussion\] &lt;6.4 &gt;Discuss the trade-offs and benefits of the two options in Exer- cise 6.3, assuming a constant workload being run on the servers.
3. \[Discussion\] &lt;6.2, 6.4 &gt;Unlike high-performance computing (HPC) clusters, WSCs often experience significant workload fluctuation throughout the day. Dis- cuss the trade-offs and benefits of the two options in Exercise 6.3, this time assum- ing a workload that varies.
4. \[Discussion\] &lt;6.4, 6.7 &gt;The TCO model presented so far abstracts away a signif- icant amount of lower level details. Discuss the impact of these abstractions to the overall accuracy of the TCO model. When are these abstractions safe to make? In what cases would greater detail provide significantly different answers?

### Case Study 2: Resource Allocation in WSCs and TCO

##### _Concepts illustrated by this case study_

- Server and Power Provisioning within a WSC
- Time Variance of Workloads
- Effects of Variance on TCO
  Some of the key challenges to deploying efficient WSCs are provisioning resources properly and utilizing them to their fullest capacity. This problem is com- plex due to the size of WSCs as well as the potential variance of the workloads being run. The exercises in this case study show how different uses of resources can affect TCO. Assume data from Figures 6.13 and 6.14 as appropriate.

1. \[5/5/10\] &lt;6.4 &gt;One of the challenges in provisioning a WSC is determining the proper power load, given the facility size. As described in the chapter, nameplate power is often a peak value that is rarely encountered.
2. \[5\] &lt;6.4 &gt;Estimate how the per-server TCO changes if the nameplate server power is 200 W and the cost is $3000.
3. \[5\] &lt;6.4 &gt;Also consider a higher power, but cheaper server option whose power is 300 W and costs $2000.
4. \[10\] &lt;6.4 &gt;How does the per-server TCO change if the actual average power usage of the servers is only 70% of the nameplate power?

<!-- -->

1. \[15/10\] &lt;6.2, 6.4 &gt;One assumption in the TCO model is that the critical load of the facility is fixed, and the amount of servers fits that critical load. In reality, due to the variations of server power based on load, the critical power used by a facility can vary at any given time. Operators must initially provision the datacenter based on its critical power resources and an estimate of how much power is used by the datacenter components.
2. \[15\] &lt;6.2, 6.4 &gt;Extend the TCO model to initially provision a WSC based on a server with a nameplate power of 300 W, but also calculate the actual monthly critical power used and TCO assuming the server averages 40% utilization and so consumes only 225 W. How much capacity is left unused?
3. \[10\] &lt;6.2, 6.4 &gt;Repeat this exercise with a 500-W server that averages 20% utilization and consumes only 300 W.
4. \[10\] &lt;6.4, 6.5 &gt;WSCs are often used in an interactive manner with end users, as mentioned in Section 6.5. This interactive usage often leads to time-of-day fluctu- ations, with peaks correlating to specific time periods. For example, for Netflix rentals there is a peak during the evening periods of 8–10 p.m.; the entirety of these time-of-day effects is significant. Compare the per-server TCO of a datacenter with a capacity to match the utilization at 4 a.m. compared to 9 p.m.
5. \[Discussion/15\] &lt;6.4, 6.5 &gt;Discuss some options to better utilize the excess servers during the off-peak hours or find ways to save costs. Given the interactive nature of WSCs, what are some of the challenges to aggressively reducing power usage?
6. \[Discussion/25\] &lt;6.4, 6.6, 6.8 &gt;Propose one possible way to improve TCO by focusing on reducing server power. What are the challenges to evaluating your pro- posal? Estimate the TCO improvements based on your proposal. What are some advantages and drawbacks?

### Exercises

1. \[10/10/10\] &lt;6.1, 6.2 &gt;One of the important enablers of WSC is ample request- level parallelism, in contrast to instruction- or thread-level parallelism. This ques- tion explores the implication of different types of parallelism on computer archi- tecture and system design.
2. \[10\] &lt;6.1 &gt;Discuss scenarios where improving the instruction- or thread-level parallelism would provide greater benefits than those achievable through request-level parallelism.
3. \[10\] &lt;6.1, 6.2 &gt;What are the software design implications of increasing request-level parallelism?
4. \[10\] &lt;6.1, 6.2 &gt;What are potential drawbacks of increasing request-level parallelism?

<!-- -->

1. \[Discussion/15/15\] &lt;6.2, 6.3 &gt;When a cloud computing service provider receives jobs consisting of multiple Virtual Machines (VMs) (e.g., a MapReduce job), many scheduling options exist. The VMs can be scheduled in a round-robin man- ner to spread across all available processors and servers, or they can be consoli- dated to use as few processors as possible. Using these scheduling options, if a job with 24 VMs was submitted and 30 processors were available in the cloud (each able to run up to 3 VMs), round-robin would use 24 processors, while con- solidated scheduling would use 8 processors. The scheduler can also find available processor cores at different scopes: socket, server, rack, and an array of racks.
2. \[Discussion\] &lt;6.2, 6.3 &gt;Assuming that the submitted jobs are all compute- heavy workloads, possibly with different memory bandwidth requirements, what are the pros and cons of round-robin versus consolidated scheduling in terms of power and cooling costs, performance, and reliability?
3. \[15\] &lt;6.2, 6.3 &gt;Assuming that the submitted jobs are all I/O-heavy workloads, what are the pros and cons of round-robin versus consolidated scheduling, at different scopes?
4. \[15\] &lt;6.2, 6.3 &gt;Assuming that the submitted jobs are network-heavy work- loads, what are the pros and cons of round-robin versus consolidated schedul- ing, at different scopes?
5. \[15/15/10/10\] &lt;6.2, 6.3 &gt;MapReduce enables large amounts of parallelism by having data-independent tasks run on multiple nodes, often using commodity hard- ware; however, there are limits to the level of parallelism. For example, for redun- dancy MapReduce will write data blocks to multiple nodes, consuming disk and, potentially, network bandwidth. Assume a total dataset size of 300 GB, a network bandwidth of 1 Gb/s, a 10 s/GB map rate, and a 20 s/GB reduce rate. Also assume that 30% of the data must be read from remote nodes, and each output file is written to two other nodes for redundancy. Use Figure 6.6 for all other parameters.
6. \[15\] &lt;6.2, 6.3 &gt;Assume that all nodes are in the same rack. What is the expected runtime with 5 nodes? 10 nodes? 100 nodes? 1000 nodes? Discuss the bottlenecks at each node size.
7. \[15\] &lt;6.2, 6.3 &gt;Assume that there are 40 nodes per rack and that any remote read/write has an equal chance of going to any node. What is the expected run- time at 100 nodes? 1000 nodes?
8. \[10\] &lt;6.2, 6.3 &gt;An important consideration is minimizing data movement as much as possible. Given the significant slowdown of going from local to rack to array accesses, software must be strongly optimized to maximize locality. Assume that there are 40 nodes per rack, and 1000 nodes are used in the MapRe- duce job. What is the runtime if remote accesses are within the same rack 20% of the time? 50% of the time? 80% of the time?
9. \[10\] &lt;6.2, 6.3 &gt;Given the simple MapReduce program in Section 6.2, discuss some possible optimizations to maximize the locality of the workload.

<!-- -->

1. \[20/20/10/20/20/20\] &lt;6.2, 6.3 &gt;WSC programmers often use data replication to overcome failures in the software. Hadoop HDFS, for example, employs three-way replication (one local copy, one remote copy in the rack, and one remote copy in a separate rack), but it’s worth examining when such replication is needed.
2. \[20\] &lt;6.2 &gt;Let us assume that Hadoop clusters are relatively small, with 10 nodes or less, and with dataset sizes of 10 TB or less. Using the failure fre- quency data in Figure 6.1, what kind of availability does a 10-node Hadoop cluster have with one-, two-, and three-way replications?
3. \[20\] &lt;6.2 &gt;Assuming the failure data in Figure 6.1 and a 1000-node Hadoop cluster, what kind of availability does it have with one-, two-, and three-way replications? What can you reason about the benefits of replication, at scale?
4. \[10\] &lt;6.2, 6.3 &gt;The relative overhead of replication varies with the amount of data written per local compute hour. Calculate the amount of extra I/O traffic and network traffic (within and across rack) for a 1000-node Hadoop job that sorts 1 PB of data, where the intermediate results for data shuffling are written to the HDFS.
5. \[20\] &lt;6.2, 6.3 &gt;Using Figure 6.6, calculate the time overhead for two- and three- wayreplications. Using the failure rates shown in Figure 6.1, compare the expected execution times for no replication versus two- and three-way replications.
6. \[20\] &lt;6.2, 6.3 &gt;Now consider a database system applying replication on logs, assuming each transaction on average accesses the hard disk once and generates 1 KB of log data. Calculate the time overhead for two- and three-way replica- tions. What if the transaction is executed in-memory and takes 10 μs?
7. \[20\] &lt;6.2, 6.3 &gt;Now consider a database system with ACID consistency that requires two network round trips for two-phase commitment. What is the time overhead for maintaining consistency as well as replications?
8. \[15/15/20/Discussion\] &lt;6.1, 6.2, 6.8 &gt;Although request-level parallelism allows many machines to work on a single problem in parallel, thereby achieving greater overall performance, one of the challenges is how to avoid dividing the problem too finely. If we look at this problem in the context of service level agreements (SLAs), using smaller problem sizes through greater partitioning can require increased effort to achieve the target SLA. Assume an SLA of 95% of queries respond at 0.5 s or faster, and a parallel architecture similar to MapReduce that can launch multiple redundant jobs to achieve the same result. For the following questions, assume the query–response time curve shown in [Figure 6.36](#_bookmark317). The curve shows the latency of response, based on the number of queries per second, for a baseline server as well as a “small” server that uses a slower processor model.

Figure 6.36 Query–response time curve.

1. \[15\] &lt;6.1, 6.2, 6.8 &gt;How many servers are required to achieve this SLA, assuming the query-response time curve shown in Figure 6.36 and the WSC receiving 30,000 queries per second? How many “small” servers are required to achieve this SLA, given this response-time probability curve? Looking only at server costs, how much cheaper must the “small” servers be than the normal servers to achieve a cost advantage for the target SLA?
2. \[15\] &lt;6.1, 6.2, 6.8 &gt;Often, “small” servers are also less reliable due to cheaper components. Using the numbers from Figure 6.1, assume that the number of events due to flaky machines and bad memories increases by 30%. How many “small” servers are required now? How much cheaper must those servers be than the standard servers?
3. \[20\] &lt;6.1, 6.2, 6.8 &gt;Now assume a batch processing environment. The “small” servers provide 30% of the overall performance of the regular servers. Still assuming the reliability numbers from Exercise 6.15 part (b), how many “small” nodes are required to provide the same expected throughput of a 2400-node array of standard servers, assuming perfect linear scaling of performance to node size and an average task length of 10 min per node? What if the scaling is 85%? 60%?
4. \[Discussion\] &lt;6.1, 6.2, 6.8 &gt;Often the scaling is not a linear function, but instead a logarithmic function. A natural response may be instead to purchase larger nodes that have more computational power per node to minimize the array size. Discuss some of the trade-offs with this architecture.
5. \[10/10/15/Discussion\] &lt;6.3, 6.8 &gt;One trend in high-end servers is toward the inclusion of nonvolatile flash memory in the memory hierarchy, either through solid-state disks (SSDs) or PCI Express-attached cards. Typical SSDs have a band- width of 250 MB/s and latency of 75 μs, whereas PCIe cards have a bandwidth of 600 MB/s and latency of 35 μs.
6. \[10\] Take Figure 6.7 and include these points in the local server hierarchy. Assuming that identical performance scaling factors like DRAM are accessed at different hierarchy levels, how do these flash memory devices compare when accessed across the rack? Across the array?
7. \[10\] Discuss some software-based optimizations that can utilize the new level of the memory hierarchy.
8. \[15\] As discussed in “Fallacies and Pitfalls” (Section 6.8), replacing all disks with SSDs is not necessarily a cost-effective strategy. Consider a WSC operator that uses it to provide cloud services. Discuss some scenarios where using SSDs or other flash memory would make sense.
9. \[Discussion\] Recently, some vendors have discussed new memory tech- nologies that are much faster than flash. As an example, look up the spec- ifications for Intel 3D X-point memory and discuss how it would factor in Figure 6.7.

<!-- -->

1. \[20/20/Discussion\] &lt;6.3 &gt; _Memory Hierarchy_: Caching is heavily used in some WSC designs to reduce latency, and there are multiple caching options to satisfy varying access patterns and requirements.
2. \[20\] Let’s consider the design options for streaming rich media from the Web (e.g., Netflix). First we need to estimate the number of videos, number of encode formats per video, and concurrent viewing users. Assume a streaming video pro- vider that has 12,000 titles for online streaming, each title having at least four encode formats (at 500, 1000, 1600, and 2200 kbps). Let’s also assume that there are 100,000 concurrent viewers for the entire site, and an average video is 75 min long (accounting for both 30-min shows and 2-h videos). Estimate the total storage capacity, I/O and network bandwidths, and video-streaming-related computation requirements.
3. \[20\] What are the access patterns and reference locality characteristics per user, per video, and across all videos? (_Hint_: Random versus sequential, good versus poor temporal and spatial locality, relatively small versus large working set size.)
4. \[Discussion\] What movie storage options exist by using DRAM, SSD, and hard drives? Compare them in performance and TCO. Would new memory technol- ogies like those in Problem 6.17(d) be useful?

<!-- -->

1. \[Discussion/20/Discussion/Discussion\] &lt;6.3 &gt;Consider a social networking web- site with 100 million active users posting updates about themselves (in text and pictures) as well as browsing and interacting with updates in their social networks. To provide low latency, Facebook and many other websites use memcached as a caching layer before the backend storage/database tiers. Assume that at any given time the average user is browsing megabytes of content, and on any given day the average user uploads megabytes of content.
2. \[20\] For the social networking website discussed here, how much DRAM is needed to host its working set? Using servers each having 96 GB DRAM, esti- mate how many local versus remote memory accesses are needed to generate a user’s home page?
3. \[Discussion\] Now consider two candidate memcached server designs, one using conventional Xeon processors and the other using smaller cores, such as Atom processors. Given that memcached requires large physical memory but has low CPU utilization, what are the pros and cons of these two designs?
4. \[Discussion\] Today’s tight coupling between memory modules and processors often requires an increase in CPU socket count in order to provide large memory support. List other designs to provide large physical memory without propor- tionally increasing the number of sockets in a server. Compare them based on performance, power, costs, and reliability.
5. \[Discussion\] The same user’s information can be stored in both the memcached and storage servers, and such servers can be physically hosted in different ways. Discuss the pros and cons of the following server layout in the WSC: (1) memcached collocated on the same storage server, (2) memcached and storage servers on separate nodes in the same rack, or (3) memcached servers on the same racks and storage servers collocated on separate racks.
6. \[5/5/10/10/Discussion/Discussion/Discussion\] &lt;6.3, 6.5, 6.6 &gt; _Datacenter Net- working_: MapReduce and WSC are a powerful combination to tackle large-scale data processing. For this problem, we will assume we sort one petabyte (1 PB) of records in 6 h using 4000 servers and 48,000 hard drives (Google discussed doing this in 2008).
7. \[5\] Derive disk bandwidth from Figure 6.6 and associated text. How manyseconds does it take to read the data into main memory and write the sorted results back?
8. \[5\] Assuming each server has two 1 Gb/s Ethernet network interface cards (NICs) and the WSC switch infrastructure is oversubscribed by a factor of 4, how many seconds does it take to shuffle the entire dataset across 4000 servers?
9. \[10\] Assuming network transfer is the performance bottleneck for petabyte sort, can you estimate what oversubscription ratio Google has in its datacenter?
10. \[10\] Now let’s examine the benefits of having 10 Gb/s Ethernet without oversubscription—for example, using a 48-port 10 Gb/s Ethernet (this was used by the 2010 Indy sort benchmark winner TritonSort). How long does it take to shuffle 1 PB of data?
11. \[Discussion\] Compare the two approaches here: (1) the massive scale-out approach with high network oversubscription ratio, and (2) a relatively small- scale system with a high-bandwidth network. What are their potential bottle- necks? What are their advantages and disadvantages, in terms of scalability and TCO?
12. \[Discussion\] Sort and many important scientific computing workloads are communication-heavy, while many other workloads are not. List three example workloads that do not benefit from high-speed networking. What EC2 instances would you recommend to use for these two classes of workloads?
13. \[Discussion\] Look up the various benchmarks in [www.sortbenchmark.org](http://www.sortbenchmark.org/) and recent winners in each category. How do these results match the insights from the discussion in part (e) above? How does the cloud instance used for the most recent winner of CloudSort compare with your answer in part (f) above?

<!-- -->

1. \[10/25/Discussion\] &lt;6.4, 6.6 &gt;Because of the massive scale of WSCs, it is very important to properly allocate network resources based on the workloads that are expected to be run. Different allocations can have significant impacts on both the performance and total cost of ownership.
2. \[10\] Using the numbers in the spreadsheet detailed in Figure 6.13, what is the oversubscription ratio at each access-layer switch? What is the impact on TCO if the oversubscription ratio is cut in half? What if it is doubled?
3. \[25\] Reducing the oversubscription ratio can potentially improve performance if a workload is network-limited. Assume a MapReduce job that uses 120 servers and reads 5 TB of data. Assume the same ratio of read/intermediate/out- put data as in Figure 6.2, Sep-09, and use Figure 6.6 to define the bandwidths of the memory hierarchy. When reading data, assume that 50% of data is read from remote disks; of that, 80% is read from within the rack and 20% is read from within the array. For intermediate data and output data, assume that 30% of the data uses remote disks; of that, 90% is within the rack and 10% is within the array. What is the overall performance improvement when reducing the over- subscription ratio by half? What is the performance if the oversubscription ratio is doubled? Calculate the TCO in each case.
4. \[Discussion\] We are seeing the trend to more cores per system. We are also see- ing the increasing adoption of optical communication (with potentially higher bandwidth and improved energy efficiency). How do you think these and other emerging technology trends will affect the design of future WSCs?

<!-- -->

1. \[5/15/15/20/25/Discussion\] &lt;6.5 &gt; _Realizing the Capability of the Cloud_: Imagine you are the site operation and infrastructure manager of an [Alexa.com](http://Alexa.com/) top site and are considering using Amazon Web Services (AWS). What factors do you need to consider in determining whether to migrate to AWS? What services and instance types could you use, and how much cost could you save? You can use Alexa and site traffic information (e.g., Wikipedia provides page view stats) to estimate the amount of traffic received by a top site, or you can take concrete examples from the Web, such as the following example: _[http://2bits.com/sites/2bits.com/files/drupal-](http://2bits.com/sites/2bits.com/files/drupal-single-server-2.8-million-page-views-a-day.pdf) [single-server-2.8-million-page-views-a-day.pdf](http://2bits.com/sites/2bits.com/files/drupal-single-server-2.8-million-page-views-a-day.pdf)._ The slides describe an Alexa \#3400 site that receives 2.8 million page views per day, using a single server. The server has two quad-core Xeon 2.5 GHz processors with 8 GB DRAM and three 15 K RPM SAS hard drives in a RAID1 configuration, and it costs about

$400 per month. The site uses caching heavily, and the CPU utilization ranges from 50% to 250% (roughly 0.5–2.5 cores busy).

1. \[5\] Looking at the available EC2 instances _([http://aws.amazon.com/ec2/](http://aws.amazon.com/ec2/instance-types/) [instance-types/](http://aws.amazon.com/ec2/instance-types/))_, what instance types match or exceed the current server configuration?
2. \[15\] Looking at the EC2 pricing information _([http://aws.amazon.com/ec2/](http://aws.amazon.com/ec2/pricing/) [pricing/](http://aws.amazon.com/ec2/pricing/))_, select the most cost-efficient EC2 instances (combinations allowed) to host the site on AWS. What is the monthly cost for EC2?
3. \[15\] Now add the costs for IP address and network traffic to the equation, and suppose the site transfers 100 GB/day in and out on the Internet. What is the monthly cost for the site now?
4. \[20\] AWS also offers a micro instance for free for 1 year to new customers and 15 GB bandwidth each for traffic going in and out across AWS. Based on your estimation of peak and average traffic from your department Web server, can you host it for free on AWS?
5. \[25\] Based on the service characteristics, if a much larger site like [Netflix.com](http://Netflix.com/) migrates its streaming and encoding infrastructure to AWS, what AWS services could be used by Netflix and for what purposes?
6. \[Discussion\] Look at similar offerings from other cloud providers (Google, Microsoft, Alibaba, etc.). How do the answers to parts (a)–(e) change?
7. \[Discussion\] “Serverless computing” allows you to build and run higher-level applications and services without thinking about specific servers. Examples include AWS Lambda, Google Cloud Functions, Microsoft Azure Functions, etc. Continuing to wear your site operation and infrastructure manager hat, when would you consider serverless computing?

<!-- -->

1. \[Discussion/Discussion/20/20/Discussion\] &lt;6.4, 6.8 &gt;Figure 6.12 shows the impact of user perceived response time on revenue, and motivates the need to achieve high-throughput while maintaining low latency.
2. \[Discussion\] Taking Web search as an example, what are the possible ways of reducing query latency?
3. \[Discussion\] What monitoring statistics can you collect to help understand where time is spent? How do you plan to implement such a monitoring tool?
4. \[20\] Assuming that the number of disk accesses per query follows a normal dis- tribution, with an average of 2 and standard deviation of 3, what kind of disk access latency is needed to satisfy a latency SLA of 0.1 s for 95% of the queries?
5. \[20\] In-memory caching can reduce the frequencies of long-latency events (e.g., accessing hard drives). Assuming a steady-state hit rate of 40%, hit latency of 0.05 s, and miss latency of 0.2 s, does caching help meet a latency SLA of 0.1 s for 95% of the queries?
6. \[Discussion\] When can cached content become stale or even inconsistent? How often can this happen? How can you detect and invalidate such content?

<!-- -->

1. \[15/15/20/Discussion\] &lt;6.4, 6.6 &gt;The efficiency of typical power supply units (PSUs) varies as the load changes; for example, PSU efficiency can be about 80% at 40% load (e.g., output 40 W from a 100-W PSU), 75% when the load is between 20% and 40%, and 65% when the load is below 20%.
2. \[15\] Assume a power-proportional server whose actual power is proportional to CPU utilization, with a utilization curve as shown in Figure 6.3. What is the average PSU efficiency?
3. \[15\] Suppose the server employs 2 _N_ redundancy for PSUs (i.e., doubles the number of PSUs) to ensure stable power when one PSU fails. What is the aver- age PSU efficiency?
4. \[20\] Blade server vendors use a shared pool of PSUs not only to provide redun- dancy but also to dynamically match the number of PSUs to the server’s actual power consumption. The HP c7000 enclosure uses up to six PSUs for a total of 16 servers. In this case, what is the average PSU efficiency for the enclosure of server with the same utilization curve?
5. \[Discussion\] Consider the impact of the different efficiency numbers in the con- text of the broader TCO discussions in Figures 6.13 and 6.14: how do the dif- ferent design impact the total TCO? Given these, how would you optimize designs for future warehouse-scale computers?

<!-- -->

1. \[5/Discussion/10/15/Discussion/Discussion/Discussion\] &lt;6.4, 6.8 &gt; _Power stranding_ is a term used to refer to power capacity that is provisioned but not used in a datacenter. Consider the data presented in [Figure 6.37](#_bookmark318) \[Fan, Weber, and Barroso, 2007\] for different groups of machines. (Note that what this paper calls a “cluster” is what we have referred to as an “array” in this chapter.)
2. \[5\] What is the stranded power at (1) the rack level, (2) the power distribution unit level, and (3) the array (cluster) level? What are the trends with oversub- scription of power capacity at larger groups of machines?
3. \[Discussion\] What do you think causes the differences between power stranding at different groups of machines?
4. \[10\] Consider an array-level collection of machines where the total machines never use more than 72% of the aggregate power (this is sometimes also referred to as the ratio between the peak-of-sum and sum-of-peaks usage). Using the cost model in the case study, compute the cost savings from comparing a datacenter provisioned for peak capacity and one provisioned for actual use.
5. \[15\] Assume that the datacenter designer chose to include additional servers at the array level to take advantage of the stranded power. Using the example config- uration and assumptions in part (a), compute how many more servers can now be included in the warehouse-scale computer for the same total power provisioning.
6. \[Discussion\] What is needed to make the optimization of part (d) work in a real- world deployment? (_Hint_: Think about what needs to happen to cap power in the rare case when all the servers in the array are used at peak power.)

Figure 6.37 Cumulative distribution function (CDF) of a real datacenter.

1. \[Discussion\] Two kinds of policies can be envisioned to manage power caps \[Ranganathan et al., 2006\]: (1) preemptive policies where power budgets are predetermined (“don’t assume you can use more power; ask before you do!”) or (2) reactive policies where power budgets are throttled in the event of a power budget violation (“use as much power as needed until told you can’t!”). Discuss the trade-offs between these approaches and when you would use each type.
2. \[Discussion\] What happens to the total stranded power if systems become more energy-proportional (assume workloads similar to that of Figure 6.4)?

<!-- -->

1. \[5/20/Discussion\] &lt;6.4, 6.7 &gt;Section 6.7 discussed the use of per-server battery sources in the Google design. Let us examine the consequences of this design.
2. \[5\] Assume that the use of a battery as a mini-server-level

   > UPS is 99.99% effi- cient and eliminates the need for a > facility-wide UPS that is only 92% efficient. Assume that > substation switching is 99.7% efficient and that the > efficiency for the PDU, step-down stages, and other electrical > breakers are 98%, 98%, and 99%, respectively. Calculate the > overall power infrastructure efficiency improvements from > using a per-server battery backup.
   >
3. \[20\] Assume that the UPS is 10% of the cost of the IT

   > equipment. Using the rest of the assumptions from the cost > model in the case study, what is the break-even point for the > costs of the battery (as a fraction of the cost of a single > server) at which the total cost of ownership for a > battery-based solution is better than that for a facility-wide > UPS?
   >
4. \[Discussion\] What are the other trade-offs between these two > approaches? In particular, how do you think the manageability > and failure model will change across these two different > designs?
5. \[5/5/Discussion\] &lt;6.4 &gt;For this exercise, consider a simplified equation for the total operational power of a WSC as follows: Total operational power = (1 + Cooling inefficiency multiplier)\*IT equipment power.
6. \[5\] Assume an 8 MW datacenter at 80% power usage, electricity costs of $0.10 per kilowatt-hour, and a cooling-inefficiency multiplier of 0.8. Compare the cost savings from (1) an optimization that improves cooling efficiency by 20%, and (2) an optimization that improves the energy efficiency of the IT equipment by 20%.
7. \[5\] What is the percentage improvement in IT equipment energy efficiency needed to match the cost savings from a 20% improvement in cooling efficiency?
8. \[Discussion/10\] What conclusions can you draw about the relative importance of optimizations that focus on server energy efficiency and cooling energy efficiency?

<!-- -->

1. \[5/5/Discussion\] &lt;6.4 &gt;As discussed in this chapter, the cooling equipment in WSCs can themselves consume a lot of energy. Cooling costs can be lowered by proactively managing temperature. Temperature-aware workload placement is one optimization that has been proposed to manage temperature to reduce cooling costs. The idea is to identify the cooling profile of a given room and map the hotter systems to the cooler spots, so that at the WSC level the requirements for overall cooling are reduced.
2. \[5\] The coefficient of performance (COP) of a computer room air conditioning unit (CRAC) is a measure of its efficiency, and is defined as the ratio of heat removed (Q) to the amount of work necessary (W) to remove that heat. The COP of a CRAC unit increases with the temperature of the air the CRAC unit pushes into the plenum. If air returns to the CRAC unit at 20°C and we remove 10 KW of heat with a COP of 1.9, how much energy do we expend in the CRAC unit? If it takes a COP of 3.1 to cool the same volume of air, but the air is returned at 25°C, how much energy do we now expend in the CRAC unit?
3. \[5\] Assume a workload distribution algorithm is able to match the hot work- loads well with the cool spots to allow the computer room air-conditioning (CRAC) unit to be run at a higher temperature to improve cooling efficiencies like in the exercise above. What is the power savings between the two cases described above?
4. \[Discussion\] Given the scale of WSC systems, power management can be a com- plex, multifaceted problem. Optimizations to improve energy efficiency can be implemented in hardware and in software, at the system level, and at the cluster level for the IT equipment or the cooling equipment, etc. It is important to con- sider these interactions when designing an overall energy-efficiency solution for the WSC. Consider a consolidation algorithm that looks at server utilization and consolidates different workload classes on the same server to increase server uti- lization (this can potentially have the server operating at a higher energy effi- ciency if the system is not energy-proportional). How would this optimization interact with a concurrent algorithm that tried to use different power states (see ACPI, Advanced Configuration Power Interface, for some examples)? What other examples can you think of where multiple optimizations can potentially conflict with one another in a WSC? How would you solve this problem?
5. \[5/10/15/20\] &lt;6.2, 6.6 &gt;Energy proportionality (sometimes also referred to as energy scale-down) is the attribute of the system to consume no power when idle, but more importantly gradually consume more power _in proportion_ to the activity level and work done. In this exercise, we will examine the sensitivity of energy consumption to different energy proportionality models. In the exercises below, unless otherwise mentioned, use the data in Figure 6.4 as the default.
6. \[5\] A simple way to reason about energy proportionality is to assume linearity between activity and power usage. Using just the peak power and idle power data from Figure 6.4 and a linear interpolation, plot the energy-efficiency trends across varying utilizations. (Energy efficiency is expressed as performance per watt.) What happens if idle power (at 0% activity) is half of what is assumed in Figure 6.4? What happens if idle power is zero?
7. \[10\] Plot the energy-efficiency trends across varying activities, but use the data from column 3 of Figure 6.4 for power variation. Plot the energy efficiency assuming that the idle power (alone) is half of what is assumed in Figure 6.4. Compare these plots with the linear model in the previous exercise. What conclusions can you draw about the consequences of focusing purely on idle power alone?
8. \[15\] Assume the system utilization mix in column 7 of Figure 6.4. For simplic- ity, assume a discrete distribution across 1000 servers, with 109 servers at 0% utilization, 80 servers at 10% utilization, etc. Compute the total performance and total energy for this workload mix using the assumptions in part (a) and part (b).
9. \[20\] One could potentially design a system that has a sublinear power versus load relationship in the region of load levels between 0% and 50%. This would have an energy-efficiency curve that peaks at lower utilizations (at the expense of higher utilizations). Create a new version of column 3 from Figure 6.4 that shows such an energy-efficiency curve. Assume the system utilization mix in column 7 of Figure 6.4. For simplicity, assume a discrete distribution across 1000 servers, with 109 servers at 0% utilization, 80 servers at 10% utilizations, etc. Compute the total performance and total energy for this workload mix.

<!-- -->

1. \[15/20/20\] &lt;6.2, 6.6 &gt;This exercise illustrates the interactions of energy propor- tionality models with optimizations such as server consolidation and energy- efficient server designs. Consider the scenarios shown in [Figures 6.38](#_bookmark319) and [6.39](#_bookmark320).
2. \[15\] Consider two servers with the power distributions shown in Figure 6.38: case A (the server considered in Figure 6.4) and case B (a less energy-proportional but more energy-efficient server than case A). Assume the system utilization mix in column 7 of Figure 6.4. For simplicity, assume a discrete distribution across 1000 servers, with 109 servers at 0% utilization, 80 servers at 10% utilizations, etc., as

Figure 6.38 Power distribution for two servers.

Figure 6.39 Utilization distributions across cluster, without and with consolidation.

shown in row 1 of Figure 6.39. Assume performance variation based on column 2 of Figure 6.4. Compare the total performance and total energy for this workload mix for the two server types.

1. \[20\] Consider a cluster of 1000 servers with data similar to the data shown in Figure 6.4 (and summarized in the first rows of Figures 6.38 and 6.39). What are the total performance and total energy for the workload mix with these assump- tions? Now assume that we were able to consolidate the workloads to model the distribution shown in case C (second row of Figure 6.39). What are the total performance and total energy now? How does the total energy compare with a system that has a linear energy-proportional model with idle power of zero watts and peak power of 662 W?
2. \[20\] Repeat part (b), but with the power model of server B, and compare with the results of part (a).

<!-- -->

1. \[10/Discussion\] &lt;6.2, 6.4, 6.6 &gt; _System-Level Energy Proportionality Trends_: Consider the following breakdowns of the power consumption of a server: CPU, 50%; memory, 23%; disks, 11%; networking/other, 16%

CPU, 33%; memory, 30%; disks, 10%; networking/other, 27%

1. \[10\] Assume a dynamic power range of 3.0 for the CPU (i.e., the power con- sumption of the CPU at idle is one-third that of its power consumption at peak). Assume that the dynamic range of the memory systems, disks, and the network- ing/other categories above are, respectively, 2.0 , 1.3 , and 1.2 . What is the overall dynamic range for the total system for the two cases?
2. \[Discussion/10\] What can you learn from the results of part (a)? How would we achieve better energy proportionality at the system level? (_Hint_: Energy propor- tionality at a system level cannot be achieved through CPU optimizations alone, but instead requires improvement across all components.)

<!-- -->

1. \[30\] &lt; 6.4 &gt;Pitt Turner IV et al. \[2008\] presented a good overview of datacenter tier classifications. Tier classifications define site infrastructure performance. For simplicity, consider the key differences as shown in [Figure 6.40](#_bookmark321) (adapted from Pitt Turner IV et al. \[2008\]). Using the TCO model in the case study as a guiding frame- work, compare the cost implications of the different tiers shown.
2. \[Discussion\] &lt;6.4 &gt;Based on the observations in Figures 6.12 and 6.13, what can you say qualitatively about the trade-offs between revenue loss from downtime and costs incurred for uptime?
3. \[15/Discussion\] &lt;6.4 &gt;Some recent studies have defined a metric called TPUE, which stands for “true PUE” or “total PUE.” TPUE is defined as PUE \* SPUE. PUE, the power utilization effectiveness, is defined in Section 6.4 as the ratio of the total facility power over the total IT equipment power. SPUE, or server PUE, is a new metric analogous to PUE, but instead applied to computing equipment. SPUE is defined as the ratio of total server input power to its useful power, where useful power is defined as the power consumed by the electronic components

Figure 6.40 Overview of data center tier classifications. (Adapted from Pitt Turner IV et al. \[2008\].).

directly involved in the computation: motherboard, disks, CPUs, DRAM, I/O cards, and so on. In other words, the SPUE metric captures inefficiencies associated with the power supplies, voltage regulators, and fans housed on a server.

1. \[15\] &lt;6.4 &gt;Consider a design that uses a higher supply temperature for the computer room air conditioning (CRAC) units. The efficiency of the CRAC unit is approximately a quadratic function of the temperature, and this design therefore improves the overall PUE, let’s assume by 7%. (Assume baseline PUE of 1.7.) However, the higher temperature at the server level triggers the on-board fan controller to operate the fan at much higher speeds. The fan power is a cubic function of speed, and the increased fan speed leads to a degradation of SPUE. Assume a fan power model:

Fan power = 284\*_ns_\*_ns_\*_ns_ — 75\*_ns_\*_ns_,

where _ns_ is the normalized fan speed =fan speed in rpm/18,000 and a baseline server power of 350 W. Compute the SPUE if the fan speed increases from (1) 10,000–12,500 rpm and (2) 10,000–18,000 rpm. Compare the PUE and TPUE in both these cases. (For simplicity, ignore the inefficiencies with power deliv- ery in the SPUE model.)

1. \[Discussion\] Part (a) illustrates that, while PUE is an excellent metric to capture the overhead of the facility, it does not capture the inefficiencies within the IT equip- ment itself. Can you identify another design where changes to the TPUE are potentially lower than the changes to traditional PUE? (_Hint_: See Exercise 6.26.)

<!-- -->

1. \[Discussion/30/Discussion\] &lt;6.2 &gt;Two benchmarks provide a good starting point for energy-efficiency accounting in servers—the SPECpower*ssj2008 benchmark (available at [\_http://www.spec.org/power_ssj2008/*](http://www.spec.org/power_ssj2008/)) and the JouleSort metric (available at _[http://sortbenchmark.org/](http://sortbenchmark.org/)_ ).
2. \[Discussion\] &lt;6.2 &gt;Look up the descriptions of the two benchmarks. How are they similar? How are they different? What would you do to improve these benchmarks to better address the goal of improving WSC energy efficiency?
3. \[30\] &lt;6.2 &gt;JouleSort measures the total system energy to perform an out-of-core sort and attempts to derive a metric that enables the comparison of systems rang- ing from embedded devices to supercomputers. Look up the description of the JouleSort metric at _[http://sortbenchmark.org](http://sortbenchmark.org/)._ Download a publicly available version of the sort algorithm and run it on different classes of machines—a laptop, a PC, a mobile phone, etc.—or with different configurations. What can you learn from the JouleSort ratings for different setups?
4. \[Discussion\] &lt;6.2 &gt;Consider the system with the best JouleSort rating from your experiments above. How would you improve the energy efficiency? For example, try rewriting the sort code to improve the JouleSort rating. What does running sort in the cloud do to energy efficiency?
5. \[10/10/15\] &lt;6.1, 6.2 &gt;Figure 6.1 is a listing of outages in an array of servers. When dealing with the large scale of WSCs, it is important to balance cluster design and software architectures to achieve the required uptime without incurring significant costs. This question explores the implications of achieving availability through hardware only.
6. \[10\] &lt;6.1, 6.2 &gt;Assuming that an operator wishes to achieve 95% availability through server hardware improvements alone, how many events of each type would have to be reduced? For now, assume that individual server crashes are completely handled through redundant machines.
7. \[10\] &lt;6.1, 6.2 &gt;How does the answer to part (a) change if the individual server crashes are handled by redundancy 50% of the time? 20% of the time? None of the time?
8. \[15\] &lt;6.1, 6.2 &gt;Discuss the importance of software redundancy to achieving a high level of availability. If a WSC operator considered buying machines that were cheaper but 10% less reliable, what implications would this have on the soft- ware architecture? What are the challenges associated with software redundancy?
9. \[Discussion\] &lt;6.1 &gt;Discuss the importance of eventual consistency in how warehouse-scale computers can scale.

<!-- -->

1. \[15\] &lt;6.1, 6.8 &gt;Look up the current prices of standard DDR4 DRAM versus DDR4 DRAM that has error-correcting code (ECC). What is the increase in price per bit for achieving the higher reliability that ECC provides? Using the DRAM prices alone, and the data provided in Section 6.8, what is the uptime per dollar of a WSC with non-ECC versus ECC DRAM?
2. \[5/Discussion\] &lt;6.1, 6.8 &gt; _WSC Reliability and Manageability Concerns_:
3. \[5\] Consider a cluster of servers costing $2000 each. Assuming

   > an annual fail- ure rate of 5%, an average of an hour of > service time per repair, and replacement parts requiring 10% > of the system cost per failure, what is the annual mainte- > nance cost per server? Assume an hourly rate of $100 per hour > for a service technician.
   >
4. \[Discussion\] Comment on the differences between this

   > manageability model versus that in a traditional enterprise > datacenter with a large number of small- or medium-sized > applications each running on its own dedicated hardware > infrastructure.
   >
5. \[Discussion\] Discuss the trade-offs in having heterogeneous > machines in a warehouse-scale computer.
6. \[Discussion\] &lt;6.4, 6.7, 6.8 &gt;The OpenCompute project at [www.opencompute.](http://www.opencompute.org/) [org](http://www.opencompute.org/) provides a community to design and share efficient designs for warehouse- scale computers. Look at some of the recently proposed designs. How do they compare with the design trade-offs discussed in this chapter? How do the designs differ from the Google case study discussed in Section 6.7?
7. \[15/15\] &lt;6.3, 6.4, 6.5 &gt;Assume that the MapReduce job from Page \#438 in Sec- tion 6.2 is executing a task with 2^40 bytes of input data, 2^37 bytes of intermediate data, and 2^30 bytes of output data. This job is entirely memory/storage bound, so its performance can be quantified by the DRAM/Disk bandwidth of Figure 6.6.
8. How much does the job cost to run on m4.16xlarge and m4.large in Figure 6.15? Which EC2 instance provides better performance? Which EC2 instance pro- vides better cost?
9. How much would the job cost if an SSD was added to the system, as in m3. medium? How do the performance and cost of m3.medium compare with the best instance from part (a) above?

<!-- -->

1. &lt;6.1, 6.4 &gt;\[5/5/10/Discussion\] Imagine you have created a web service that runs very well (responds within 100 ms latency) 99% of the time, and has performance issues 1% of the time (maybe the CPU went into a lower power state and the response took 1000 ms, etc.).
2. \[5\] Your service grows popular, and you now have 100 servers and your com- putation has to touch all these servers to handle the user request. What is the percentage of time your query is likely to have a slow response time, across 100 servers?
3. \[5\] Instead of “two nines” (99%) single server latency SLA, how many “nines” do we need to have for the single server latency SLA so that the cluster latency SLA has bad latencies only 10% of the time or lower?
4. \[10\] How do the answers to parts (a) and (b) change if we have 2000 servers?
5. \[Discussion\] Section 6.4 (page 452) discusses “tail-tolerant” designs. What kind of design optimizations would you need to make in your web service (_Hint_: Look at the “Tail at Scale” paper from Dean and Barroso \[2013\]).

<!-- -->
