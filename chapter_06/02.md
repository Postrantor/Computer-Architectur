## Programming Models and Workloads for Warehouse-Scale Computers

> ##编程模型和仓库规模计算机的工作负载

If a problem has no solution, it may not be a problem, but a fact—not to be solved, but to be coped with over time.

> 如果问题没有解决方案，那可能不是一个问题，而是一个事实 - 不是要解决，而是随着时间的流逝而应对。

Shimon Peres

> 西蒙·佩雷斯（Shimon Peres）

In addition to the public-facing Internet services such as search, video sharing, and social networking that make them famous, WSCs also run batch applications, such as converting videos into new formats or creating search indexes from web crawls.

> 除了面向公共的互联网服务（例如搜索，视频共享和使其著名的社交网络）之外，WSC 还运行了批处理应用程序，例如将视频转换为新格式或从 Web Crawls 创建搜索索引。

A popular framework for batch processing in a WSC is MapReduce ([Dean and](#_bookmark941) [Ghemawat, 2008](#_bookmark941)) and its open-source twin Hadoop. [Figure 6.2](#_bookmark274) shows the increasing popularity of MapReduce at Google over time. Inspired by the Lisp functions of the same name, Map first applies a programmer-supplied function to each logical input record. Map runs on hundreds of computers to produce an intermediate result of key-value pairs. Reduce collects the output of those distributed tasks and collapses them using another programmer-defined function. Assuming the Reduce function is commutative and associative, it can run in log N time. With appropriate software support, both functions are fast yet easy to understand and use. Within 30 min, a novice programmer can run a MapReduce task on thousands of computers.

> WSC 中批处理处理的流行框架是 MapReduce（[Dean and]（#_ bookmark941）[Ghemawat，2008]（#_ bookmark941））及其开源 twin hadoop。[图 6.2]（#_ bookmark274）显示了随着时间的推移，MapReduce 在 Google 上的受欢迎程度越来越高。受同名 LISP 函数的启发，MAP 首先将程序员供应函数应用于每个逻辑输入记录。MAP 在数百台计算机上运行，以产生键值对的中间结果。减少收集这些分布式任务的输出，并使用另一个程序员定义的函数折叠它们。假设降低功能是交换性和关联性的，则可以在日志 n 时间内运行。借助适当的软件支持，这两个功能都很快但易于理解和使用。在 30 分钟内，新手程序员可以在数千台计算机上运行 MapReduce 任务。

Figure 6.2 Monthly MapReduce usage at Google from 2004 to 2016. Over 12 years the number of MapReduce jobs increased by a factor of 3300. [Figure 6.17](#_bookmark292) on page 461 estimates that running the September 2016 workload on Amazon’s cloud computing service EC2 would cost $114 million. Updated from Dean, J., 2009. Designs, lessons and advice from building large distributed systems \[keynote address\]. In: Proceedings of 3rd ACM SIGOPS International Workshop on Large-Scale Distributed Systems and Middleware, Co-located with the 22nd ACM Symposium on Operating Systems Principles, October 11–14, 2009, Big Sky, Mont.

> 图 6.2 Google 从 2004 年至 2016 年在 Google 上使用 MAPREDUCE。EC2 的成本为 1.14 亿美元。从 Dean，J.，2009 年更新。设计，经验教训和建议，构建大型分布式系统\ [Keynote 地址\]。在：关于大规模分布式系统和中间件的第三届 ACM Sigops 国际研讨会论文集，与第 22 届 ACM 操作系统原理研讨会共同划分，2009 年 10 月 11 日至 14 日，蒙大拿州 Big Sky。

[Figure 6.2](#_bookmark274) shows the average job uses hundreds of servers. Other than a few highly tuned applications from high-performance computing, such MapReduce jobs are the most parallel applications today, whether measured in total CPU time or number of servers utilized.

> [图 6.2]（#_ bookmark274）显示了平均作业使用数百个服务器。除了从高性能计算中进行一些高度调整的应用程序之外，这种 MapReduce 作业是当今最平行的应用程序，无论是在 CPU 总时间或使用的服务器数量中测量的。

Here is a MapReduce program that calculates the number of occurrences of every English word in a large collection of documents. Following is a simplified version of that program, which shows just the inner loop and that assumes only one occurrence of all English words found in a document ([Dean and](#_bookmark941) [Ghemawat, 2008](#_bookmark941)):

> 这是一个 MAPREDUCE 程序，可以计算大量文档中每个英语单词的出现数量。以下是该程序的简化版本，它仅显示内部循环，并且仅假定文档中发现的所有英语单词的出现（[dean and]（#_ bookmark941）[Ghemawat，2008]（#_ bookmark941））：

The function EmitIntermediate used in the Map function emits each word in the document and the value one. Then the Reduce function sums all the values per word for each document using ParseInt() to get the number of occurrences per word in all documents. The MapReduce runtime environment schedules map tasks and reduce tasks to the nodes of a WSC. (The complete version of the program is found in [Dean and Ghemawat (2008)](#_bookmark941).)

> 地图功能中使用的函数发射中间体会在文档和值中发出每个单词。然后，降低函数使用 ParseInt（）将每个文档的每个单词值总和，以获取所有文档中每个单词的出现数量。MAPREDUCE 运行时环境计划映射任务，并将任务减少到 WSC 的节点。（该程序的完整版本可在[Dean and Ghemawat（2008）]（#_ bookmark941）中找到。

MapReduce can be thought of as a generalization of the single instruction stream, multiple data streams (SIMD) operation ([Chapter 4](#_bookmark165))—except that a function to be applied is passed to the data—that is followed by a function that is used in a reduction of the output from the Map task. Because reductions are commonplace even in SIMD programs, SIMD hardware often offers special operations for the reductions. For example, Intel’s AVX SIMD instructions include “horizontal” instructions that add pairs of operands that are adjacent in registers.

> 可以将 mapReduce 视为单个指令流的概括，多个数据流（SIMD）操作（[[第 4 章]（#_ bookmark165）） - 除了将要应用的函数传递给数据外，遵循了一个用于减少地图任务输出的功能。由于降低即使在 SIMD 程序中也很常见，因此 SIMD 硬件通常为减少提供特殊操作。例如，英特尔的 AVX SIMD 指令包括“水平”指令，这些说明添加了寄存器中相邻的操作数对。

To accommodate variability in performance from hundreds of computers, the MapReduce scheduler assigns new tasks based on how quickly nodes complete prior tasks. Obviously, a single slow task can hold up completion of a large MapReduce job. [Dean and Barroso (2013)](#_bookmark940) label such a situation _tail latency_. In a WSC, the solution to slow tasks is to provide software mechanisms to cope with such variability that is inherent at this scale. This approach is in sharp contrast to the solution for a server in a conventional data center, where traditionally slow tasks mean hardware is broken and needs to be replaced or that server software needs tuning and rewriting. Performance heterogeneity is the norm for 50,000– 100,000 servers in a WSC. For example, toward the end of a MapReduce program, the system will start backup executions on other nodes of the tasks that haven’t completed yet and take the result from whichever finishes first. In return for increasing resource usage a few percentage points, [Dean and Ghemawat (2008)](#_bookmark941) found that some large tasks completed 30% faster.

> 为了适应数百台计算机的性能变异性，MapReduce 调度程序根据节点完成先验任务的速度分配新任务。显然，一项缓慢的任务可以结束大型 MapReduce 作业。[Dean and Barroso（2013）]（#_ bookmark940）标记这种情况_tail Latency_。在 WSC 中，缓慢任务的解决方案是提供软件机制，以应对这种规模固有的可变性。这种方法与传统数据中心中服务器的解决方案形成鲜明对比，在传统上，慢速任务意味着硬件被打破并需要更换，或者服务器软件需要调整和重写。性能异质性是 WSC 中 50,000-100,000 台服务器的规范。例如，在 MAPREDUCE 程序结束时，系统将在尚未完成的任务的其他节点上启动备份执行，并首先从哪个完成。作为增加资源使用情况的回报，[Dean and Ghemawat（2008）]（#_ bookmark941）发现，一些大型任务的速度快 30％。

Dependability was built into MapReduce from the start. For example, each node in a MapReduce job is required to report back to the master node periodically with a list of completed tasks and with updated status. If a node does not report back by the deadline, the master node deems the node dead and reassigns the node’s work to other nodes. Given the amount of equipment in a WSC, it’s not surprising that failures are commonplace, as the prior example attests. To deliver on 99.99% availability, systems software must cope with this reality in a WSC. To reduce operational costs, all WSCs use automated monitoring software allowing one operator to be responsible for more than 1000 servers.

> 可靠性从一开始就内置在 MapReduce 中。例如，MAPREDUCE 作业中的每个节点都需要定期向主节点报告，并具有完整的任务列表和更新的状态。如果节点未按截止日期报告，则主节点认为节点已死，并将节点的工作重新分配给其他节点。鉴于 WSC 中的设备数量，如先前的示例证明，失败是司空见惯的不足为奇的。要交付 99.99％的可用性，系统软件必须在 WSC 中应对此现实。为了降低运营成本，所有 WSC 都使用自动监视软件，允许一个操作员负责 1000 多个服务器。

Programming frameworks such as MapReduce for batch processing and externally facing SaaS such as Search rely upon internal software services for their success. For example, MapReduce relies on the Google File System (GFS) ([Ghemawat et al., 2003](#_bookmark953)) or on Colossus ([Fikes, 2010](#_bookmark948)) to supply files to any computer, so that MapReduce tasks can be scheduled anywhere.

> 编程框架，例如用于批处理处理的 MapReduce 和外部面对 SaaS（例如搜索）的框架，依靠内部软件服务取得成功。例如，MapReduce 依靠 Google 文件系统（GFS）（[[Ghemawat et al。，2003]（#_ bookmark953））或 colossus（[Fikes，2010]（#_ bookmark948））向任何计算机提供文件，因此 MapReduce 任务可以在任何地方安排。

In addition to GFS and Colossus, examples of these scalable storage systems include Amazon’s key value storage system Dynamo ([DeCandia et al., 2007](#_bookmark942)) and the Google record storage system BigTable ([Chang et al., 2006](#_bookmark935)). Note that such systems often build upon each other. For example, BigTable stores its logs and data on GFS or Colossus, much as a relational database may use the file system provided by the kernel operating system.

> 除 GFS 和巨像外，这些可扩展存储系统的示例还包括亚马逊的钥匙值存储系统发电机（[Decandia 等，2007]（#_ bookmark942））和 Google 记录存储系统 Bigtable（[Chang 等，2006]（＃_Bookmark935））。请注意，这种系统通常相互依靠。例如，Bortable 将其日志和数据存储在 GFS 或 Colossus 上，就像关系数据库可以使用内核操作系统提供的文件系统一样。

These internal services usually make different decisions than similar software running on single servers. For example, rather than assuming storage is reliable, such as by using RAID storage servers, these systems often make complete replicas of the data. Replicas can help with read performance as well as with availability; with proper placement, replicas can overcome many other system failures, like those in [Figure 6.1](#_bookmark272). Systems like Colossus use error-correcting codes rather than full replicas to reduce storage costs, but the constant is cross-server redundancy rather than within-a-server or within-a-storage array redundancy. Thus, failure of the entire server or storage device doesn’t negatively affect availability of the data.

> 这些内部服务通常与在单个服务器上运行的类似软件做出不同的决策。例如，这些系统通常不假定存储是可靠的，例如使用 RAID 存储服务器，而是经常使数据完整地复制。复制品可以帮助阅读性能以及可用性；通过适当的放置，复制品可以克服许多其他系统故障，例如[图 6.1]中的失败（#_ bookmark272）。像巨像这样的系统使用错误纠正的代码而不是完整的复制品来降低存储成本，但是常数是跨服务器的冗余，而不是在服务器内部或储存阵列内部冗余内。因此，整个服务器或存储设备的故障不会对数据的可用性产生负面影响。

Another example of the different approach is that WSC storage software often uses relaxed consistency rather than following all the ACID (atomicity, consistency, isolation, and durability) requirements of conventional database systems. The insight is that it’s important for multiple replicas of data to agree _some time_, but, for most applications, they do not need to be in agreement at all times. For example, eventual consistency is fine for video sharing. Eventual consistency makes storage systems much easier to scale, which is an absolute requirement for WSCs.

> 不同方法的另一个例子是，WSC 存储软件通常使用放松的一致性，而不是遵循常规数据库系统的所有酸（原子量，一致性，隔离和耐用性）要求。洞察力是，多个数据复制品同意_some time_很重要，但是，对于大多数应用程序，它们始终不需要始终达成协议。例如，最终的一致性适用于视频共享。最终的一致性使存储系统更易于扩展，这是 WSC 的绝对要求。

The workload demands of these public interactive services all vary considerably; even a prominent global service such as Google Search varies by a factor of two depending on the time of day. When factoring in weekends, holidays, and popular times of year for some applications—such as photograph-sharing services after New Year’s Day or online shopping before Christmas—a much greater variation in server utilization becomes apparent. [Figure 6.3](#_bookmark275) shows average utilization of 5000 Google servers over a 6-month period. Note that less than 0.5% of servers averaged 100% utilization, and most servers operated between 10% and 50% utilization. Stated alternatively, just 10% of all servers were utilized more than 50%. Thus, it’s much more important for servers in a WSC to perform well while doing little than to perform efficiently only at their peak, as they rarely operate at their peak.

> 这些公共互动服务的工作量需求差异很大；即使是 Google 搜索等著名的全球服务，也有两倍的倍数，具体取决于一天中的时间。当周末，假期和一年中的流行时间用于某些应用程序（例如元旦之后的照片共享服务或圣诞节前的在线购物）时，服务器利用率的差异变得显而易见。[图 6.3]（#_ bookmark275）显示了 6 个月内 5000 台 Google 服务器的平均利用率。请注意，不到 0.5％的服务器平均使用 100％利用，大多数服务器在 10％至 50％的利用率之间运行。另外，只有 10％的服务器被使用超过 50％。因此，对于 WSC 中的服务器而言，表现良好，而做得比仅在峰值上有效地表现良好，这一点更为重要，因为它们很少在峰值上运行。

![](./media/image309.png)

> ！[]（./ Media/image309.png）

Figure 6.3 Average CPU utilization of more than 5000 servers during a 6-month period at Google. Servers are rarely completely idle or fully utilized, instead operating most of the time at between 10% and 50% of their maximum utilization. The third column from the right in [Figure 6.4](#_bookmark276) calculates percentages plus or minus 5% to come up with the weightings; thus 1.2% for the 90% row means that 1.2% of servers were between 85% and 95% utilized. From Figure 1 in Barroso, L.A., Ho€lzle, U., 2007. The case for energy-proportional computing. IEEE Comput. 40 (12), 33–37.

> 图 6.3 在 Google 的 6 个月期间，在 6 个月的时间内，CPU 的平均 CPU 利用率为 5000 多个服务器。服务器很少完全闲置或充分利用，而是在大部分时间以其最大利用率的 10％至 50％之间运行。[图 6.4]（#_ bookmark276）中右侧的第三列计算百分比或减去 5％的权重；因此，90％行的 1.2％意味着 1.2％的服务器在 85％至 95％之间。来自美国巴罗索的图 1，美国，美国，2007 年。IEEE 计算。40（12），33-37。

In summary, WSC hardware and software must cope with variability in load based on user demand and in performance and dependability because of the vagaries of hardware at this scale.

> 总而言之，WSC 硬件和软件必须根据用户需求以及性能和可靠性的负载可变性，因为此规模的硬件变化量。

Example As a result of measurements like those in [Figure 6.3](#_bookmark275), the SPECpower benchmark measures power and performance from 0% load to 100% in 10% increments (see [Chapter 1](#_bookmark2)). The overall single metric that summarizes this benchmark is the sum of all the performance measures (server-side Java operations per second) divided by the sum of all power measurements in watts. Thus, each level is assumed to be equally likely. How would the numbers summary metric change if the levels were weighted by the utilization frequencies in [Figure 6.3](#_bookmark275)?

> 例如，例如[图 6.3]中的测量结果（#_ bookmark275），SpecPower 基准测量功率和性能从 0％加载到 10％增量的 100％（请参阅[第 1 章]（#_ bookmark2））。总结此基准测试的总体单一度量是所有性能度量（服务器端 Java 操作）的总和，除以瓦特中所有功率测量的总和。因此，假定每个级别同样可能。如果[图 6.3]（#_ bookmark275）中的利用率加权级别，数字汇总度量将如何变化？

Figure 6.4 SPECpower result using the weightings from [Figure 6.3](#_bookmark275) instead of even weightings.

> 图 6.4 使用[图 6.3]（#_ bookmark275）的权重而不是权重的权重结果。

_Answer_ [Figure 6.4](#_bookmark276) shows the original weightings and the new weighting that match [Figure 6.3](#_bookmark275). These weightings reduce the performance summary by 30% from 3210 ssj_ops/watt to 2454.

> _answer_ [图 6.4]（#_ bookmark276）显示了原始权重和匹配的新权重[图 6.3]（#_ bookmark275）。这些权重将性能摘要从 3210 SSJ_OPS/watt 降低到 2454。

Given the scale, software must handle failures, which means there is little reason to buy “gold-plated” hardware that reduces the frequency of failures. The primary impact would be to increase cost. [Barroso and H](#_bookmark924)€o[lzle (2009)](#_bookmark924) found a factor of 20 difference in price-performance between a high-end Hewlett Packard sharedmemory multiprocessor and a commodity Hewlett Packard server when running the TPC-C database benchmark. Not surprisingly, Google and all other companies with WSCs use low-end commodity servers. In fact, the Open Compute Project ([http://opencompute.org](http://opencompute.org/)) is an organization where such companies collaborate on open designs of servers and racks for data centers.

> 鉴于规模，软件必须处理故障，这意味着几乎没有理由购买“镀金”硬件来降低故障频率。主要影响是增加成本。[Barroso and H]（#_ bookmark924）€o [lzle（2009）]（#_ bookmark924）在运行 TPC 时运行 TPC 时，高端 Hewlett Packard SharedMemory Multialrocersor 和 Moscortity Hewlett Packard 在高端 hewlett sharememory 多处理器之间的价格效果差异为 20 倍。-c 数据库基准。毫不奇怪，Google 和所有其他 WSC 的公司都使用低端商品服务器。实际上，开放式计算项目（[http://opencompute.org]（[http://opencomcompute.org/](http://opencomcompute.org/)））是一个组织，此类公司在该组织中合作开放数据中心的服务器和机架。

Such WSC services also tend to develop their own software rather than buy third-party commercial software, in part to cope with the huge scale and in part to save money. For example, even on the best price-performance platform for TPC-C in 2017, adding the cost of the SAP SQL Anywhere database and the Windows operating system increases the cost of the Dell PowerEdge T620 server by 40%. In contrast, Google runs BigTable and the Linux operating system on its servers, for which it pays no licensing fees.

> 这样的 WSC 服务还倾向于开发自己的软件，而不是购买第三方商业软件，部分是为了应对巨大的规模和部分节省资金。例如，即使在 2017 年 TPC-C 的最佳价格绩效平台上，添加 SAP SQL Anywhere 数据库的成本和 Windows 操作系统也会增加 Dell PowerEdge T620 服务器的成本 40％。相比之下，Google 在其服务器上运行 Bigtable 和 Linux 操作系统，其不支付许可费。

Given this review of the applications and systems software of a WSC, we are ready to look at the computer architecture of a WSC.

> 鉴于对 WSC 的应用程序和系统软件的评论，我们准备查看 WSC 的计算机体系结构。
