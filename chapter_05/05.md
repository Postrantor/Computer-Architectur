## Synchronization: The Basics

Synchronization mechanisms are typically built with user-level software routines that rely on hardware-supplied synchronization instructions. For smaller multiprocessors or low-contention situations, the key hardware capability is an uninterruptible instruction or instruction sequence capable of atomically retrieving and changing a value. Software synchronization mechanisms are then constructed using this capability. In this section, we focus on the implementation of lock and unlock synchronization operations. Lock and unlock can be used straightforwardly to create mutual exclusion, as well as to implement more complex synchronization mechanisms.

> 同步机制通常是由依赖硬件供应同步指令的用户级软件例程构建的。对于较小的多层或低调情况，关键的硬件功能是能够在原子能检索和更改值的不介入指令或指令序列。然后使用此功能构建软件同步机制。在本节中，我们重点介绍锁定和解锁同步操作的实现。锁定和解锁可以直接用于创建相互排除，并实施更复杂的同步机制。

In high-contention situations, synchronization can become a performance bottleneck because contention introduces additional delays and because latency is potentially greater in such a multiprocessor. We discuss how the basic synchronization mechanisms of this section can be extended for large processor counts in Appendix I.

> 在高端情况下，同步可以成为一个性能的动物，因为争夺引入了其他延迟，并且因为在这种多处理器中潜在的延迟可能更大。我们讨论如何在附录 I 中扩展本节的基本同步机制。

### Basic Hardware Primitives

The key ability we require to implement synchronization in a multiprocessor is a set of hardware primitives with the ability to atomically read and modify a memory location. Without such a capability, the cost of building basic synchronization primitives will be too high and will increase as the processor count increases. There are a number of alternative formulations of the basic hardware primitives, all of which provide the ability to atomically read and modify a location, together with some way to tell whether the read and write were performed atomically. These hardware primitives are the basic building blocks that are used to build a wide variety of user-level synchronization operations, including things such as locks and barriers. In general, architects do not expect users to employ the basic hardware primitives, but instead expect that the primitives will be used by system programmers to build a synchronization library, a process that is often complex and tricky. Let’s start with one such hardware primitive and show how it can be used to build some basic synchronization operations.

> 我们需要在多处理器中实现同步的关键能力是一组硬件原始图，具有原子读取和修改内存位置的能力。没有这样的能力，构建基本同步原语的成本将太高，并且随着处理器计数的增加而增加。基本硬件原始词有多种替代公式，所有这些配方都提供了原子读取和修改位置的能力，并以某种方式判断读取和写入是否是原子上执行的。这些硬件原始图是用于构建各种用户级同步操作(包括锁和障碍物)的基本构建块。通常，工程师不希望用户采用基本的硬件原始图，而是期望系统程序人员将使用原始库来构建同步库，这一过程通常很复杂且棘手。让我们从一个这样的硬件原始版本开始，并展示如何用于构建一些基本的同步操作。

One typical operation for building synchronization operations is the _atomic exchange_, which interchanges a value in a register for a value in memory. To see how to use this to build a basic synchronization operation, assume that we want to build a simple lock where the value 0 is used to indicate that the lock is free and 1 is used to indicate that the lock is unavailable. A processor tries to set the lock by doing an exchange of 1, which is in a register, with the memory address corresponding to the lock. The value returned from the exchange instruction is 1 if some other processor had otherwise already claimed access and 0. In the latter case, the value is also changed to 1, preventing any competing exchange from also retrieving a 0.

> 建筑同步操作的一个典型操作是 _ATomic Exchange_，它可以在存储器中的值中互换寄存器中的值。要查看如何使用它来构建基本的同步操作，假设我们要构建一个简单的锁定，其中使用值 0 来指示锁定是免费的，并且使用 1 表示锁定不可用。处理器试图通过进行 1 个在寄存器中的 1 交换来设置锁定，并将内存地址与锁相对应。如果其他一些处理器否则已经声称访问，则从交换指令返回的值为 1，为 0。在后一种情况下，该值也将其更改为 1，以防止任何竞争交换也无法检索 0。

For example, consider two processors that each try to do the exchange simultaneously: This race is broken because exactly one of the processors will perform the exchange first, returning 0, and the second processor will return 1 when it does the exchange. The key to using the exchange (or swap) primitive to implement synchronization is that the operation is atomic: the exchange is indivisible, and two simultaneous exchanges will be ordered by the write serialization mechanisms. It is impossible for two processors trying to set the synchronization variable in this manner to both determine they have simultaneously set the variable.

> 例如，考虑两个处理器，每个处理器都尝试进行交换模拟：这场比赛被打破了，因为一个处理器中的一个将首先执行交换，返回 0，第二个处理器将在交换时返回 1。使用 Exchange(或交换)原始的关键来实现合成，是该操作是原子：交换是不可分割的，并且将通过写入序列化机制来订购两个同时交换。两个试图以这种方式设置同步变量的处理器不可能确定它们同时设置了变量。

There are a number of other atomic primitives that can be used to implement synchronization. They all have the key property that they read and update a memory value in such a manner that we can tell whether the two operations executed atomically. One operation, present in many older multiprocessors, is _test-and-set_, which tests a value and sets it if the value passes the test. For example, we could define an operation that tested for 0 and set the value to 1, which can be used in a fashion similar to how we used atomic exchange. Another atomic synchronization primitive is _fetch-and-increment_: it returns the value of a memory location and atomically increments it. By using the value 0 to indicate that the synchronization variable is unclaimed, we can use fetch-and-increment, just as we used exchange. There are other uses of operations like fetch-and-increment, which we will see shortly.

> 还有许多其他可用于实现同步的原子原始原子。他们都具有他们阅读和更新内存值的关键属性，以使我们可以分辨出两个操作是否从原子上执行。在许多较旧的多处理器中存在的一个操作是 _test and-set_，它测试值并在值通过测试时将其设置。例如，我们可以定义一个测试为 0 并将值设置为 1 的操作，该值可以按照我们如何使用原子交换的方式使用。另一个原子同步原始性是 _fetch and-Increment_：它返回存储位置的值并在原子上返回。通过使用值 0 来指示无人认领的同步变量，我们可以像使用交换一样使用提取和提示。还有其他操作的用途，例如提取和灌溉，我们很快就会看到。

Implementing a single atomic memory operation introduces some challenges because it requires both a memory read and a write in a single, uninterruptible instruction. This requirement complicates the implementation of coherence because the hardware cannot allow any other operations between the read and the write, and yet must not deadlock.

> 实现单个原子存储器操作引入了一些挑战，因为它既需要内存读取，又需要单个不间断的指令写入。这一要求使连贯性的实现复杂化，因为硬件不能允许阅读和写入之间的任何其他操作，却不能僵局。

An alternative is to have a pair of instructions where the second instruction returns a value from which it can be deduced whether the pair of instructions was executed as though the instructions were atomic. The pair of instructions is effectively atomic if it appears as though all other operations executed by any processor occurred before or after the pair. Thus, when an instruction pair is effectively atomic, no other processor can change the value between the instruction pair. This is the approach used in the MIPS processors and in RISC V.

> 另一种替代方法是要有一对指令，其中第二个指令返回一个值，即是否执行了两对指令，就可以从该值中推导出一个指令。如果说明似乎在该对之前或之后发生的任何其他操作执行的所有其他操作，则两对指令有效地是原子。因此，当指令对具有效率的原子化时，没有其他处理器可以更改指令对之间的值。这是 MIPS 处理器和 RISC V 中使用的方法。

In RISC V, the pair of instructions includes a special load called a _load reserved_ (also called load linked or _load locked)_ and a special store called a _store conditional_. Load reserved loads the contents of memory given by rs1 into rd and creates a reservation on that memory address. Store conditional stores the value in rs2 into the memory address given by rs1. If the reservation of the load is broken by a write to the same memory location, the store conditional fails and writes a nonzero to rd; if it succeeds, the store conditional writes 0. If the processor does a context switch between the two instructions, then the store conditional always fails. These instructions are used in sequence, and because the load reserved returns the initial value and the store conditional returns 0 only if it succeeds, the following sequence implements an atomic exchange on the memory location specified by the

> 在 RISC V 中，这对指令包括一个特殊的负载，称为*负载保留*(也称为 Load Linked 或 *load 锁定)*和一个称为* store storeditional*的特殊商店。保留的负载将 RS1 给出的内存内容加载到 RD 中，并在该内存地址上创建预订。存储条件将 RS2 中的值存储在 RS1 给出的内存地址中。如果保留负载通过写入相同的内存位置打破，则商店有条件失败并将非零写入 RD；如果成功，则商店有条件地写入 0。如果处理器在两个说明之间进行调节切换，则商店的条件总是会失败。这些说明是按顺序使用的，并且由于保留的负载返回初始值，并且存储的条件返回 0 仅在成功时返回 0，以下序列在由原子位置上实现了原子交换。

At the end of this sequence, the contents of x4 and the memory location specified by x1 have been atomically exchanged. Anytime a processor intervenes and modifies the value in memory between the lr and sc instructions, the sc returns 0 in x3, causing the code sequence to try again.

> 在此序列的末尾，X4 的内容和 X1 指定的内存位置已被原子交换。每当处理器都会介入并修改 LR 和 SC 指令之间的内存中值时，SC 在 X3 中返回 0，从而导致代码序列再次尝试。

An advantage of the load reserved/store conditional mechanism is that it can be used to build other synchronization primitives. For example, here is an atomic fetch-and-increment:

> 保留载荷/存储条件机制的一个优点是它可用于构建其他同步基原始人。例如，这是一个原子的提取：

These instructions are typically implemented by keeping track of the address specified in the lr instruction in a register, often called the _reserved register_. If an interrupt occurs, or if the cache block matching the address in the link register is invalidated (e.g., by another sc), the link register is cleared. The sc instruction simply checks that its address matches that in the reserved register. If so, the sc succeeds; otherwise, it fails. Because the store conditional will fail after either another attempted store to the load reserved address or any exception, care must be taken in choosing what instructions are inserted between the two instructions. In particular, only register-register instructions can safely be permitted; otherwise, it is possible to create deadlock situations where the processor can never complete the sc. In addition, the number of instructions between the load reserved and the store conditional should be small to minimize the probability that either an unrelated event or a competing processor causes the store conditional to fail frequently.

> 这些说明通常是通过跟踪寄存器中 LR 指令中指定的地址(通常称为保留寄存器\_)来实现的。如果发生中断，或者如果链接寄存器中的地址匹配的缓存块无效(例如，另一个 SC)，则清除链接寄存器。SC 指令只需检查其地址是否与预留寄存器中的地址匹配。如果是这样，SC 成功；否则，它会失败。由于商店有条件的其他商店将在保留负载地址或任何例外之后会失败，因此在选择两个说明之间插入哪些说明时必须注意。特别是，只能安全允许登记注册说明；否则，可以创建处理器永远无法完成 SC 的僵局情况。此外，保留的负载和有条件的有条件的指令数量应很小，以最大程度地减少无关事件或处理器的概率导致商店有条件地经常失败的概率。

### Implementing Locks Using Coherence

Once we have an atomic operation, we can use the coherence mechanisms of a multiprocessor to implement _spin locks_—locks that a processor continuously tries to acquire, spinning around a loop until it succeeds. Spin locks are used when programmers expect the lock to be held for a very short amount of time and when they want the process of locking to be low latency when the lock is available. Because spin locks tie up the processor waiting in a loop for the lock to become free, they are inappropriate in some circumstances.

> 一旦我们进行了原子操作，我们就可以使用多处理器的相干机制来实现\_spin 锁 锁定处理器不断尝试获取，绕着循环旋转，直到成功为止。当程序期望锁定时间很短的时间以及他们希望锁定的过程在可用时锁定的过程时，使用旋转锁。由于旋转锁将处理器绑在循环中等待锁才能获得免费的处理器，因此在某些情况下它们是不合适的。

The simplest implementation, which we would use if there were no cache coherence, would be to keep the lock variables in memory. A processor could continually try to acquire the lock using an atomic operation, say, atomic exchange, and test whether the exchange returned the lock as free. To release the lock, the processor simply stores the value 0 to the lock. Here is the code sequence to lock a spin lock whose address is in x1. It uses EXCH as a macro for the atomic exchange sequence from page 414:

> 如果没有缓存相干性，我们将使用的最简单实现将是将锁定变量保持在内存中。处理器可以连续尝试使用原子操作(例如原子交换)来获取锁，并测试该交易所是否免费返回锁定。要释放锁，处理器只需将值 0 存储到锁上。这是锁定 X1 地址的旋转锁的代码序列。它将 EXCH 作为宏来作为原子交换序列的宏：第 414 页：

If our multiprocessor supports cache coherence, we can cache the locks using the coherence mechanism to maintain the lock value coherently. Caching locks has two advantages. First, it allows an implementation where the process of "spinning" (trying to test and acquire the lock in a tight loop) could be done on a local cached copy rather than requiring a global memory access on each attempt to acquire the lock. The second advantage comes from the observation that there is often locality in lock accesses; that is, the processor that used the lock last will use it again in the near future. In such cases, the lock value may reside in the cache of that processor, greatly reducing the time to acquire the lock.

> 如果我们的多处理器支持缓存相干性，我们可以使用相干机制缓存锁，以相干地维护锁值。缓存锁具有两个优势。首先，它允许实现 "旋转" 过程(试图以紧密的循环测试和获取锁定的过程)可以在本地缓存副本上完成，而不是在每次尝试获取锁定的尝试时都需要进行全局内存访问。第二个优势来自观察到锁访问中经常存在的地方。也就是说，最后使用锁的处理器将在不久的将来再次使用它。在这种情况下，锁值可能存在于该处理器的缓存中，从而大大减少了获取锁定的时间。

Obtaining the first advantage—being able to spin on a local cached copy rather than generating a memory request for each attempt to acquire the lock—requires a change in our simple spin procedure. Each attempt to exchange in the preceding loop requires a write operation. If multiple processors are attempting to get the lock, each will generate the write. Most of these writes will lead to write misses because each processor is trying to obtain the lock variable in an exclusive state.

> 获得第一个优势 能够在本地缓存副本上旋转，而不是为每次尝试获取锁定的记忆请求生成内存请求 对我们的简单旋转过程进行了更改。每次尝试在前面的循环中交换都需要进行写操作。如果多个处理器试图获取锁，则每个处理器都会生成写入。这些写作中的大多数都会导致写信，因为每个处理器都试图以独家状态获得锁定变量。

Thus we should modify our spin lock procedure so that it spins by doing reads on a local copy of the lock until it successfully sees that the lock is available. Then it attempts to acquire the lock by doing a swap operation. A processor first reads the lock variable to test its state. A processor keeps reading and testing until the value of the read indicates that the lock is unlocked. The processor then races against all other processes that were similarly "spin waiting" to see which can lock the variable first. All processes use a swap instruction that reads the old value and stores a 1 into the lock variable. The single winner will see the 0, and the losers will see a 1 that was placed there by the winner. (The losers will continue to set the variable to the locked value, but that doesn’t matter.) The winning processor executes the code after the lock and, when finished, stores a 0 into the lock variable to release the lock, which starts the race all over again. Here is the code to perform this spin lock (remember that 0 is unlocked and 1 is locked):

> 因此，我们应该修改我们的旋转锁定过程，以便通过在锁的本地副本上进行读数来旋转，直到成功地看到锁可用为止。然后，它试图通过进行交换操作来获取锁。处理器首先读取锁定变量以测试其状态。处理器继续读取和测试，直到读取值表示已解锁锁定为止。然后，处理器与所有其他类似地 "旋转等待" 的过程进行比赛，以查看哪些可以先锁定可变的过程。所有进程都使用交换指令，该指令读取旧值并将 1 存储在锁变量中。单身获胜者将看到 0，失败者将看到一个由获胜者放置的 1。(失败者将继续将变量设置为锁定值，但这没关系。)获胜的处理器在锁后执行代码，完成后，将 0 存储在锁定变量中以释放锁定，以启动锁定比赛再次。这是执行此旋转锁的代码(请记住，0 已解锁，1 已锁定)：

Figure 5.22 Cache coherence steps and bus traffic for three processors, P0, P1, and P2. This figure assumes write invalidate coherence. P0 starts with the lock (step 1), and the value of the lock is 1 (i.e., locked); it is initially exclusive and owned by P0 before step 1 begins. P0 exits and unlocks the lock (step 2). P1 and P2 race to see which reads the unlocked value during the swap (steps 3–5). P2 wins and enters the critical section (steps 6 and 7), while P1’s attempt fails, so it starts spin waiting (steps 7 and 8). In a real system, these events will take many more than 8 clock ticks because acquiring the bus and replying to misses take much longer. Once step 8 is reached, the process can repeat with P2, eventually getting exclusive access and setting the lock to 0.

> 图 5.22 三个处理器 P0，P1 和 P2 的缓存相干步骤和总线流量。该图假设写入无效的连贯性。P0 从锁开始(步骤 1)，锁的值为 1(即锁定)；它最初是排斥的，并由 P0 在步骤 1 开始之前拥有。P0 退出并解锁锁(步骤 2)。P1 和 P2 竞赛以查看在交换过程中读取未锁定值的读数(步骤 3-5)。P2 获胜并进入关键部分(步骤 6 和 7)，而 P1 的尝试失败，因此它开始旋转等待(步骤 7 和 8)。在一个真实的系统中，这些事件将需要 8 个以上的时钟滴答，因为获得公共汽车并回复遇到的时间需要更长的时间。达到第 8 步后，该过程可以使用 P2 重复，最终获得独家访问并将锁定为 0。

Let’s examine how this "spin lock" scheme uses the cache coherence mechanisms. [Figure 5.22](#_bookmark241) shows the processor and bus or directory operations for multiple processes trying to lock a variable using an atomic swap. Once the processor with the lock stores a 0 into the lock, all other caches are invalidated and must fetch the new value to update their copy of the lock. One such cache gets the copy of the unlocked value (0) first and performs the swap. When the cache miss of other processors is satisfied, they find that the variable is already locked, so they must return to testing and spinning.

> 让我们检查一下这种 "旋转锁" 方案如何使用缓存相干机械主义。[图 5.22](#_bookmark241) 显示了试图使用原子交换锁定变量的多个过程的处理器和总线或目录操作。一旦带有锁定的处理器将 0 存储到锁中，所有其他缓存将无效，并且必须获取新值才能更新其锁的副本。一个这样的缓存首先获取未锁定值(0)的副本，然后执行交换。当满足其他会员的缓存失误时，他们发现该变量已经锁定，因此他们必须返回测试和旋转。

This example shows another advantage of the load reserved/store conditional primitives: the read and write operations are explicitly separated. The load reserved need not cause any bus traffic. This fact allows the following simple code sequence, which has the same characteristics as the optimized version using exchange (x1 has the address of the lock, the lr has replaced the LD, and the sc has replaced the EXCH):

> 此示例显示了保留/存储条件原始原始原始载荷的另一个优点：明确分开读取操作和写作操作。保留的负载不必引起任何巴士流量。这个事实允许以下简单的代码序列，该序列具有与使用 Exchange 的优化版本相同的特征(X1 具有锁的地址，LR 已更换了 LD，SC 已更换了 Exch)：

The first branch forms the spinning loop; the second branch resolves races when two processors see the lock available simultaneously.

> 第一个分支形成旋转循环；当两个处理器同时看到可用的锁定时，第二个分支可以解决比赛。
