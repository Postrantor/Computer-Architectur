## Network Routing, Arbitration, and Switching

> ##网络路由，仲裁和切换

Routing, arbitration, and switching are performed at every switch along a packet’s path in a switched media network, no matter what the network topology. Numerous interesting techniques for accomplishing these network functions have been proposed in the literature. In this section, we focus on describing a representative set of approaches used in commercial systems for the more commonly used net- work topologies. Their impact on performance is also highlighted.

> 无论网络拓扑是什么，在切换媒体网络中的数据包路径上，每个开关都会在每个开关上执行路由，仲裁和切换。文献中已经提出了许多用于完成这些网络功能的有趣技术。在本节中，我们专注于描述商业系统中使用的代表性方法，用于更常用的净工作拓扑。它们对性能的影响也得到了强调。

Figure F.16 Topological characteristics of interconnection networks used in commercial high-performance machines.

> 图 F.16 商业高性能机器中使用的互连网络的拓扑特性。

### Routing

> ###路由

The _routing algorithm_ defines which network path, or paths, are allowed for each packet. Ideally, the routing algorithm supplies shortest paths to all packets such that traffic load is evenly distributed across network links to minimize contention. However, some paths provided by the network topology may not be allowed in order to guarantee that all packets can be delivered, no matter what the traffic behavior. Paths that have an unbounded number of allowed nonminimal hops from packet sources, for instance, may result in packets never reaching their destina- tions. This situation is referred to as _livelock_. Likewise, paths that cause a set of packets to block in the network forever waiting only for network resources (i.e., links or associated buffers) held by other packets in the set also prevent packets from reaching their destinations. This situation is referred to as _deadlock_. As dead- lock arises due to the finiteness of network resources, the probability of its occur- rence increases with increased network traffic and decreased availability of network resources. For the network to function properly, the routing algorithm must guard against this anomaly, which can occur in various forms—for example, routing deadlock, request-reply (protocol) deadlock, and fault-induced (reconfiguration) deadlock, etc. At the same time, for the network to provide the highest possible per- formance, the routing algorithm must be efficient—allowing as many routing options to packets as there are paths provided by the topology, in the best case.

> _ROUTING 算法_定义每个数据包允许使用哪个网络路径或路径。理想情况下，路由算法为所有数据包提供最短的路径，使流量负载均匀分布在网络链接上以最大程度地减少争议。但是，可能不允许网络拓扑提供的某些路径，以确保无论交通方式如何，都可以交付所有数据包。例如，具有无限数量的来自数据包源的非最小啤酒花的路径可能导致数据包永远不会达到其目的。这种情况称为_livelock_。同样，导致一组数据包在网络中封锁的路径永远只等待集合中其他数据包持有的网络资源（即链接或关联的缓冲区），还可以防止数据包到达其目的地。这种情况称为_deadlock_。由于网络资源的有限性，由于网络资源的有限，其发生的可能性随着网络流量的增加和网络资源的可用性降低而增加。为了使网络正常运行，路由算法必须防止这种异常，例如，可以以各种形式发生，例如，路由僵局，请求 - 回复（协议）死锁和故障诱导的（重新配置）僵局等。同时，要为网络提供最高的能力，路由算法必须是有效的 - 在最好的情况下，将路由选项与拓扑提供的路径相比，将路由选项与拓扑所提供的路径相同。

The simplest way of guarding against livelock is to restrict routing such that only minimal paths from sources to destinations are allowed or, less restrictively, only a limited number of nonminimal hops. The strictest form has the added benefit of consuming the minimal amount of network bandwidth, but it prevents packets from being able to use alternative nonminimal paths in case of contention or faults along the shortest (minimal) paths.

> 防止生计的最简单方法是限制路由，以便仅允许从源到目的地的最小路径，或者仅限制性地限制了有限数量的非微小啤酒花。最严格的形式具有消耗最小的网络带宽量的额外好处，但是在竞争或最短（最小）路径的情况下，它可以防止数据包使用替代性非微小路径。

Deadlock is more difficult to guard against. Two common strategies are used in practice: avoidance and recovery. In _deadlock avoidance_, the routing algorithm restricts the paths allowed by packets to only those that keep the global network state deadlock-free. A common way of doing this consists of establishing an order- ing between a set of resources—the minimal set necessary to support network full access—and granting those resources to packets in some total or partial order such that cyclic dependency cannot form on those resources. This allows an escape path always to be supplied to packets no matter where they are in the network to avoid entering a deadlock state. In _deadlock recovery_, resources are granted to packets without regard for avoiding deadlock. Instead, as deadlock is possible, some mech- anism is used to detect the likely existence of deadlock. If detected, one or more packets are removed from resources in the deadlock set—possibly by regressively dropping the packets or by progressively redirecting the packets onto special dead- lock recovery resources. The freed network resources are then granted to other packets needing them to resolve the deadlock.

> 僵局更难防止。实践中使用了两种常见的策略：避免和恢复。在_deadlock deverence_中，路由算法将数据包允许的路径限制为仅保留全局网络状态无僵局的路径。这样做的一种常见方法是在一组资源之间建立订单（支持网络完全访问所需的最低设置），并以某些总或部分顺序授予这些资源，以使周期性的依赖性无法在这些资源上形成。这允许总是将逃生路径提供给数据包，无论网络中的位置如何避免进入死锁状态。在_deadlock 恢复_中，将资源授予数据包，而不考虑避免僵局。取而代之的是，由于可能的僵局，一些机械主义被用来检测可能的僵局。如果检测到，则将一个或多个数据包从僵局设置中的资源中删除，这可能是通过回归删除数据包或逐步将数据包逐步将其重定向到特殊的 Dead-Lock 恢复资源。然后将释放的网络资源授予需要它们解决僵局的其他数据包。

Let us consider routing algorithms designed for distributed switched networks. [Figure F.17(a)](#_bookmark614) illustrates one of many possible deadlocked configurations for packets within a region of a 2D mesh network. The routing algorithm can avoid all such deadlocks (and livelocks) by allowing only the use of minimal paths that cross the network dimensions in some total order. That is, links of a given dimen- sion are not supplied to a packet by the routing algorithm until no other links are needed by the packet in all of the preceding dimensions for it to reach its destination. This is illustrated in [Figure F.17(b)](#_bookmark614), where dimensions are crossed in _XY_ dimension order. All the packets must follow the same order when traversing dimensions, exiting a dimension only when links are no longer required in that dimension. This well-known algorithm is referred to as _dimension-order routing_ (DOR) or _e-cube routing_ in hypercubes. It is used in many commercial systems built from distributed switched networks and on-chip networks. As this routing algorithm always supplies the same path for a given source-destination pair, it is a _deterministic routing_ algorithm.

> 让我们考虑为分布式开关网络设计的路由算法。[图 F.17（a）]（#_ bookmark614）说明了 2D 网络网络区域内的数据包的许多可能的僵局配置之一。路由算法可以通过仅允许使用最小路径来避免所有此类僵局（和生计）。也就是说，直到在所有前面的所有维度中，该数据包都不需要其他链接才能到达其目的地。这在[图 F.17（b）]（#_ bookmark614）中进行了说明，其中尺寸按_xy_尺寸顺序越过。所有数据包在穿越尺寸时必须遵循相同的顺序，仅在该维度不再需要链接时退出维度。该众所周知的算法称为_dimension-rorder routing_（dor）或_e-cube routing_在超启发中。它用于许多由分布式交换网络和片上网络构建的商业系统。由于该路由算法始终为给定的源用途对提供相同的路径，因此它是_-二键式路由_算法。

![](./media/image654.png)
![](./media/image655.png)

Figure F.17 A mesh network with packets routing from sources, _s<sub>i</sub>_, to destinations, _d<sub>i</sub>_. (a) Deadlock forms from packets destined to _d_<sub>1</sub> through _d_<sub>4</sub> blocking on others in the same set that fully occupy their requested buffer resources one hop away from their destinations. This deadlock cycle causes other packets needing those resources also to block, like packets from _s_<sub>5</sub> destined to _d_<sub>5</sub> that have reached node _s_<sub>3</sub>. (b) Deadlock is avoided using dimension- order routing. In this case, packets exhaust their routes in the _X_ dimension before turning into the _Y_ dimension in order to complete their routing.

> 图 F.17 网格网络，带有来自源的数据包路由，_s <sub> i </sub> _，到达目的地，_d <sub> i </sub> _。（a）僵局从注定到_d_d_ <sub> 1 </sub>到_d_d_ <sub> 4 </sub>在同一组中完全占据其请求的缓冲资源的同一组中的僵局。此死锁周期导致其他需要这些资源的数据包也可以阻止，例如来自_s_ <sub> 5 </sub>的数据包，到达_D_ <sub> 5 </sub>已达到 node _s_s_ <sub> 3 </sub>的数据包。（b）使用维订单路由避免僵局。在这种情况下，数据包在变成_y_尺寸之前，将其路由在_x_维度中耗尽，以完成路由。

Crossing dimensions in order on some minimal set of resources required to support network full access avoids deadlock in meshes and hypercubes. However, for distributed switched topologies that have wrap-around links (e.g., rings and tori), a total ordering on a minimal set of resources within each dimension is also needed if resources are to be used to full capacity. Alternatively, some empty resources or _bubbles_ along the dimensions would be required to remain below full capacity and avoid deadlock. To allow full access, either the physical links must be duplicated or the logical buffers associated with each link must be duplicated, resulting in _physical channels_ or _virtual channels_, respectively, on which the ordering is done. Ordering is not necessary on all network resources to avoid dead- lock—it is needed only on some minimal set required to support network full access (i.e., some _escape resource set_). Routing algorithms based on this technique (called Duato’s protocol) can be defined that allow alternative paths provided by the topology to be used for a given source-destination pair in addition to the escape resource set. One of those allowed paths must be selected, preferably the most efficient one. Adapting the path in response to prevailing network traffic condi- tions enables the aggregate network bandwidth to be better utilized and contention to be reduced. Such routing capability is referred to as _adaptive routing_ and is used in many commercial systems.

> 越过尺寸为支持网络访问所需的一些最小资源集，避免了网格和超振管中的死锁。但是，对于具有环绕链接的分布式开关拓扑（例如，戒指和托里），如果要使用资源来满足，也需要在每个维度内的最小资源集上进行最小的资源集订购。另外，将需要一些空的资源或_bubbles _沿尺寸_的_BUBBLES _必须保持低于满足并避免僵局。为了允许完整访问，必须重复物理链接，或者必须重复与每个链接关联的逻辑缓冲区，从而分别导致_physical Channels_或_virtual Channels_，在其中完成了订购。在所有网络资源上没有必要订购以避免使用死锁 - 仅在支持网络完整访问所需的一些最小设置（即某些_escape 资源 set_）中才需要订购。可以定义基于此技术的路由算法（称为 Duato 的协议），该算法允许拓扑提供的替代路径可用于给定的源用途对，除了逃生资源集。必须选择其中之一，最好是最有效的路径。适应响应盛行的网络流量条件的路径，可以更好地利用总体网络带宽并减少争议。这种路由功能称为_adaptive 路由_，用于许多商业系统。

Example How many of the possible dimensional turns are eliminated by dimension-order routing on an _n_-dimensional mesh network? What is the fewest number of turns that actually need to be eliminated while still maintaining connectedness and dead- lock freedom? Explain using a 2D mesh network.

> 示例通过_n_维网络上的维订单路由消除了多少个尺寸转弯？在保持连接性和死锁自由的同时，实际需要消除的最少的转弯数是多少？使用 2D 网络进行解释。

_Answer_ The dimension-order routing algorithm eliminates exactly half of the possible dimensional turns as it is easily proven that all turns from any lower-ordered dimension into any higher-ordered dimension are allowed, but the converse is not true. For example, of the eight possible turns in the 2D mesh shown in [Figure F.17](#_bookmark614), the four turns from _X_+ to _Y_+, _X_+ to _Y_ , _X_ to _Y_+, and _X_ to _Y_ are allowed, where the signs (+ or ) refer to the direction of travel within a dimen- sion. The four turns from _Y_+ to _X_+, _Y_+ to _X_ , _Y_ to _X_+, and _Y_ to _X_ are dis- allowed turns. The elimination of these turns prevents cycles of any kind from forming—and, thus, avoids deadlock—while keeping the network connected. However, it does so at the expense of not allowing any routing adaptivity.

> _answer_尺寸 - 订单路由算法完全消除了可能的尺寸转弯的一半，因为很容易证明，从任何较低级别的尺寸转弯都允许进入任何较高阶的尺寸，但相反不正确。例如，在[图 f.17]（#_ bookmark614）中显示的八个可能的转弯中允许的位置（+ 或）指尺寸内的行程方向。从_y_+ 到_x_+，_y_+ 到_x_，_y_到_x_+，以及_y_到_x_的四个转弯是允许的转弯。消除这些转弯会阻止任何形式的周期形成，从而避免僵局，同时保持网络连接。但是，这样做是为了不允许任何路由适应性。

The _Turn Model_ routing algorithm proves that the minimum number of elim- inated turns to prevent cycles and maintain connectedness is a quarter of the pos- sible turns, but the right set of turns must be chosen. Only some particular set of eliminated turns allow both requirements to be satisfied. With the elimination of the wrong set of a quarter of the turns, it is possible for combinations of allowed turns to emulate the eliminated ones (and, thus, form cycles and deadlock) or for the network not to be connected. For the 2D mesh, for example, it is possible to eliminate only the two turns ending in the westward direction (i.e., _Y_+ to _X_ and _Y_ to _X_ ) by requiring packets to start their routes in the westward direction (if needed) to maintain connectedness. Alternatives to this west-first routing for 2D meshes are negative-first routing and north-last routing. For these, the extra quarter of turns beyond that supplied by DOR allows for partial adaptivity in routing, mak- ing these adaptive routing algorithms.

> _TURN 模型_路由算法证明，防止周期和保持连接性的最小淘汰弯道数量是可观转弯的四分之一，但必须选择正确的转弯集。只有一组特定的淘汰转弯允许满足这两个要求。通过消除四分之一转弯的错误集，可以组合允许的转弯组合，模仿被淘汰的转弯（以及形成循环和僵局），或者不得连接网络。例如，对于 2D 网格，可以仅消除两个转弯，以向西方向结束（即_y_+ to _x_和_y_至_x_），通过要求数据包在西方方向（如果需要）启动其路线到保持联系。这是第 2 个网格的这一西部路线的替代方案是负面的路由和北半路路线。为此，DOR 提供的额外四分之一的回合允许在路由和制造这些自适应路由算法时进行部分适应性。

Routing algorithms for centralized switched networks can similarly be defined to avoid deadlocks by restricting the use of resources in some total or partial order. For fat trees, resources can be totally ordered along paths start- ing from the input leaf stage upward to the root and then back down to the out- put leaf stage. The routing algorithm can allow packets to use resources in increasing partial order, first traversing up the tree until they reach some _least common ancestor_ (LCA) of the source and destination, and then back down the tree until they reach their destinations. As there are many least common ances- tors for a given destination, multiple alternative paths are allowed while going up the tree, making the routing algorithm adaptive. However, only a single deterministic path to the destination is provided by the fat tree topology from a least common ancestor. This _self-routing_ property is common to many MINs and can be readily exploited: The switch output port at each stage is given sim- ply by shifts of the destination node address.

> 可以类似地定义用于集中式交换网络的路由算法，以避免僵局通过以某些总或部分顺序限制资源的使用。对于胖树，可以完全沿着从输入叶阶段到根开始的路径完全订购资源，然后再回到外叶阶段。该路由算法可以允许数据包以增加部分顺序的资源，首先穿越树，直到它们到达源和目的地的某些共同祖先_（lca），然后向下往下往下，直到到达目的地为止。由于对于给定目的地来说，最不常见的呼吸器，因此在爬上树时允许多个替代路径，从而使路由算法自适应。但是，只有一个至少共同祖先的脂肪树拓扑提供了到达目的地的单一确定性路径。此_ self-routing_属性在许多分钟内都很常见，并且可以很容易利用：每个阶段的开关输出端口都通过目标节点地址的偏移来模拟。

More generally, a tree graph can be mapped onto any topology—whether direct or indirect—and links between nodes at the same tree level can be allowed by assigning directions to them, where “up” designates paths moving toward the tree root and “down” designates paths moving away from the root node. This allows for generic _up\*/down\* routing_ to be defined on any topology such that packets follow paths (possibly adaptively) consisting of zero or more up links followed by zero or more down links to their destination. Up/down ordering pre- vents cycles from forming, avoiding deadlock. This routing technique was used in Autonet—a self-configuring switched LAN—and in early Myrinet SANs.

> 更一般地，可以将树图映射到任何拓扑（无论是直接的还是间接），并且可以通过向它们分配方向来允许在同一树级别的节点之间的链接，其中“ UP”指定了向树根移动的路径，并“向下移动””指定路径远离根节点。这允许在任何拓扑上定义通用_UP \*/down \*路由_，以便数据包遵循（可能是适应性的）路径，该路径由零或更多的链接组成，然后是零或更多链接到其目的地。向上/下订购前循环的形成，避免僵局。这种路由技术用于 Autonet（一种自我配置的开关 LAN），并在 Myrinet 早期 SANS 中使用。

Routing algorithms are implemented in practice by a combination of the rout- ing information placed in the packet header by the source node and the routing control mechanism incorporated in the switches. For _source routing_, the entire routing path is precomputed by the source—possibly by table lookup—and placed in the packet header. This usually consists of the output port or ports supplied for each switch along the predetermined path from the source to the destination, which can be stripped off by the routing control mechanism at each switch. An additional bit field can be included in the header to signify whether adaptive routing is allowed (i.e., that any one of the supplied output ports can be used). For _distributed routing_, the routing information usually consists of the destination address. This is used by the routing control mechanism in each switch along the path to determine the next output port, either by computing it using a finite-state machine or by look- ing it up in a local routing table (i.e., forwarding table). Compared to distributed routing, source routing simplifies the routing control mechanism within the net- work switches, but it requires more routing bits in the header of each packet, thus increasing the header overhead.

> 通过源节点和交换机中包含的路由控制机制在数据包标头中放置在数据包标头中的路由信息的组合来实施路由算法。对于_source 路由_，整个路由路径由源预先计算（可能是由表查找），并放置在数据包标题中。这通常由从源到目的地的预定路径沿每个开关提供的输出端口或端口组成，每个开关处的路由控制机构可以剥离。标题中可以包含一个额外的位字段，以表示是否允许自适应路由（即，可以使用任何一个提供的输出端口）。对于_分布式路由_，路由信息通常由目标地址组成。每个开关中的路由控制机制都沿路径使用，以确定下一个输出端口，通过使用有限状态机进行计算或通过在本地路由表中进行计算（即转发表）。与分布式路由相比，源路由简化了净工作开关中的路由控制机制，但是它需要在每个数据包的标头中更多的路由位，从而增加了标题开销。

### Arbitration

> ###仲裁

The _arbitration algorithm_ determines when requested network paths are available for packets. Ideally, arbiters maximize the matching of free network resources and packets requesting those resources. At the switch level, arbiters maximize the matching of free output ports and packets located in switch input ports requesting those output ports. When all requests cannot be granted simultaneously, switch arbiters resolve conflicts by granting output ports to packets in a fair way such that _starvation_ of requested resources by packets is prevented. This could happen to packets in shorter queues if a serve-longest-queue (SLQ) scheme is used. For packets having the same priority level, simple round-robin (RR) or age-based schemes are sufficiently fair and straightforward to implement.

> _arbitration Algorithm_确定可用于数据包的请求网络路径。理想情况下，仲裁员最大程度地匹配了请求这些资源的免费网络资源和数据包。在开关级别上，仲裁员最大化位于开关输入端口中的自由输出端口和数据包的匹配，要求这些输出端口。如果无法同时批准所有请求，则通过以公平的方式将输出端口授予数据包来解决冲突，从而阻止了数据包的请求资源。如果使用了最长时间（SLQ）方案，则可能会在较短的队列中的数据包。对于具有相同优先级的数据包，简单的圆形旋转（RR）或基于年龄的方案就足够公平且直接实施。

Arbitration can be distributed to avoid centralized bottlenecks. A straightfor- ward technique consists of two phases: a request phase and a grant phase. Let us assume that each switch input port has an associated queue to hold incoming packets and that each switch output port has an associated local arbiter implement- ing a round-robin strategy. [Figure F.18(a)](#_bookmark615) shows a possible set of requests for a four-port switch. In the _request phase_, packets at the head of each input port queue send a single request to the arbiters corresponding to the output ports requested by them. Then, each output port arbiter independently arbitrates among the requests it receives, selecting only one. In the _grant phase_, one of the requests to each arbiter is granted the requested output port. When two packets from different input ports request the same output port, only one receives a grant, as shown in the figure. As a consequence, some output port bandwidth remains unused even though all input queues have packets to transmit.

> 仲裁可以分配以避免集中式瓶颈。直接技术由两个阶段组成：请求阶段和赠款阶段。让我们假设每个开关输入端口都有一个关联的队列以容纳传入数据包，并且每个开关输出端口都有一个关联的本地仲裁器实现了圆形旋转策略。[图 F.18（a）]（#_ bookmark615）显示了四个端口开关的一组请求。在_request 阶段_中，每个输入端口队列的头部的数据包向对应于他们请求的输出端口的仲裁者发送一个请求。然后，每个输出端口仲裁器在其收到的请求中独立仲裁，仅选择一个。在_grant 阶段_中，授予每个仲裁者的一个请求之一。当来自不同输入端口的两个数据包请求同一输出端口时，只有一个收到赠款，如图所示。结果，即使所有输入队列都有要传输的数据包，但某些输出端口带宽仍未使用。

Figure F.18 Two arbitration techniques. (a) Two-phased arbitration in which two of the four input ports are granted requested output ports. (b) Three-phased arbitration in which three of the four input ports are successful in gaining the requested output ports, resulting in higher switch utilization.

> 图 F.18 两种仲裁技术。（a）两步仲裁，其中四个输入端口中有两个被请求的输出端口。（b）基于三台仲裁，其中四个输入端口中的三个成功地获得了所需的输出端口，从而导致更高的开关利用率。

The simple two-phase technique can be improved by allowing several simul- taneous requests to be made by each input port, possibly coming from different virtual channels or from multiple adaptive routing options. These requests are sent to different output port arbiters. By submitting more than one request per input port, the probability of matching increases. Now, arbitration requires three phases: request, grant, and acknowledgment. [Figure F.18(b)](#_bookmark615) shows the case in which up to two requests can be made by packets at each input port. In the request phase, requests are submitted to output port arbiters, and these arbiters select one of the received requests, as is done for the two-phase arbiter. Likewise, in the grant phase, the selected requests are granted to the corresponding requesters. Taking into account that an input port can submit more than one request, it may receive more than one grant. Thus, it selects among possibly multiple grants using some arbitration strategy such as round-robin. The selected grants are confirmed to the corresponding output port arbiters in the acknowledgment phase.

> 可以通过允许每个输入端口提出几个模拟请求来改进简单的两阶段技术，可能来自不同的虚拟通道或来自多个自适应路由选项。这些请求将发送到不同的输出端口仲裁者。通过每个输入端口提交多个请求，匹配的可能性增加。现在，仲裁需要三个阶段：请求，授予和确认。[图 F.18（b）]（#_ bookmark615）显示了每个输入端口的数据包最多可以提出两个请求的情况。在请求阶段，请求将提交给输出端口仲裁者，这些仲裁员和两相仲裁者的收到的请求之一。同样，在赠款阶段，选定的请求被授予相应的请求者。考虑到输入端口可以提交多个请求，它可能会获得多个赠款。因此，它使用某种仲裁策略（例如圆形旋转措施）选择了可能的多个赠款。在确认阶段，选定的赠款已确认给相应的输出端口仲裁者。

As can be seen in [Figure F.18(b)](#_bookmark615), it could happen that an input port that submits several requests does not receive any grants, while some of the requested ports remain free. Because of this, a second arbitration iteration can improve the prob- ability of matching. In this iteration, only the requests corresponding to non- matched input and output ports are submitted. Iterative arbiters with multiple requests per input port are able to increase the utilization of switch output ports and, thus, the network link bandwidth. However, this comes at the expense of additional arbiter complexity and increased arbitration delay, which could increase the router clock cycle time if it is on the critical path.

> 从[图 F.18（b）]（#_ bookmark615）中可以看出，可能会碰到一个提交多个请求的输入端口不会收到任何赠款，而某些请求的端口仍然免费。因此，第二次仲裁迭代可以提高匹配的概率。在此迭代中，仅提交了与非匹配输入和输出端口相对应的请求。每个输入端口有多个请求的迭代仲裁者能够增加开关输出端口的利用，从而增加网络链接带宽。但是，这是以额外的仲裁者复杂性和增加仲裁延迟为代价的，如果路由器时钟周期时间在临界路径上，这可能会增加路由器时钟周期。

### Switching

> ###切换

The _switching technique_ defines how connections are established in the network. Ide- ally, connections between network resources are established or “switched in” only for as long as they are actually needed and exactly at the point that they are ready and needed to be used, considering both time and space. This allows efficient use of avail- ablenetwork bandwidth bycompeting traffic flowsandminimallatency. Connections at eachhop along the topological pathallowed bythe routing algorithm and granted by the arbitration algorithm can be established in three basic ways: prior to packet arrival using _circuit switching_, upon receipt of the entire packet using _store-and-forward packet switching_, or upon receipt of only portions of the packet with unit size no smal- ler than that of the packet header using _cut-through packet switching_.

> _switching Technique_定义了网络中如何建立连接。综上所生，仅在实际需要的时间内就建立或“切换”网络资源之间的连接，并且正是在考虑到时间和空间的情况下，它们已经准备就绪和需要使用。这允许有效利用可用的流量流量通过流量流量和米尼映射。路由算法沿拓扑路径的每个霍普的连接可以通过_circuit switching_到达数据包，在使用_store-and-forward packept switch_或 Receipt 收到整个数据包后，可以通过三个基本方式建立仲裁算法授予并由仲裁算法授予的连接。仅使用_cut-trough-through 数据包切换_的单位大小的部分的部分包含单位大小的部分。

Circuit switching establishes a circuit _a priori_ such that network bandwidth is allocated for packet transmissions along an entire source-destination path. It is possible to pipeline packet transmission across the circuit using staging at each hop along the path, a technique known as _pipelined circuit switching_. As routing, arbitration, and switching are performed only once for one or more packets, routing bits are not needed in the header of packets, thus reducing latency and overhead. This can be very efficient when information is continuously transmitted between devices for the same circuit setup. However, as network bandwidth is removed from the shared pool and preallocated regardless of whether sources are in need of consuming it or not, circuit switching can be very inefficient and highly wasteful of bandwidth. Packet switching enables network bandwidth to be shared and used more efficiently when packets are transmitted intermittently, which is the more common case. Packet switching comes in two main varieties—store-and-forward and cutthrough switching, both of which allow network link bandwidth to be multi- plexed on packet-sized or smaller units of information. This better enables band- width sharing by packets originating from different sources. The finer granularity of sharing, however, increases the overhead needed to perform switching: Routing, arbitration, and switching must be performed for every packet, and routing and flow control bits are required for every packet if flow control is used.

> 电路开关建立了一个电路_a 先验_，以便将网络带宽分配给沿整个源用途路径的数据包传输。可以使用沿着路径的每个跳台上的分阶段进行管道数据包传输，这是一种称为_PIPELINED 电路开关的技术。由于仅对一个或多个数据包执行一次路由，仲裁和切换，因此数据包标题中不需要路由位，从而减少了延迟和开销。当信息在设备之间连续传输以进行同一电路设置时，这可能非常有效。但是，由于网络带宽将从共享池中删除，并且无论是否需要消耗源，因此均可予以预先定位，因此电路切换可能非常效率低下且高度浪费带宽。数据包切换使网络带宽可以在间歇性传输时共享和更有效地使用，这是更常见的情况。数据包切换有两个主要品种：商店和前向和切换开关，这两种都允许网络链接带宽在数据包大小或较小的信息单位上进行多种封装。这更好地使源自来自不同来源的数据包进行了宽度共享。但是，分享的粒度更细的粒度增加了执行切换所需的开销：每个数据包必须执行路由，仲裁和切换，如果使用流量控制，则需要每个数据包进行路由和流控制位。

Store-and-forward packet switching establishes connections such that a packet is forwarded to the next hop in sequence along its source-destination path only after the entire packet is first stored (staged) at the receiving switch. As packets are completely stored at every switch before being transmitted, links are completely decoupled, allowing full link bandwidth utilization even if links have very different bandwidths. This property is very important in WANs, but the price to pay is packet latency; the total routing, arbitration, and switching delay is multiplicative with the number of hops, as we have seen in [Section F.4](#network-topology) when analyzing perfor- mance under this assumption.

> 存储和前向数据包开关建立了连接，使数据包仅在整个数据包首先在接收开关上存储（分阶段）后，将数据包转发到下一个跃点沿其源用途路径序列。由于数据包在传输之前完全存储在每个开关上，因此链接将完全解耦，即使链接具有非常不同的带宽，也可以完全链接带宽利用率。该物业在 WAN 中非常重要，但是付款的价格是包潜伏期；正如我们在[F.4]节（＃网络 - 访问）中看到的那样，总路由，仲裁和切换延迟与啤酒花的数量是乘法性的。

Cut-through packet switching establishes connections such that a packet can “cut through” switches in a pipelined manner once the header portion of the packet (or equivalent amount of payload trailing the header) is staged at receiving switches. That is, the rest of the packet need not arrive before switching in the granted resources. This allows routing, arbitration, and switching delay to be additive with the number of hops rather than multiplicative to reduce total packet latency. Cut-through comes in two varieties, the main differences being the size of the unit of information on which flow control is applied and, consequently, the buffer requirements at switches. _Virtual cut-through switching_ implements flow control at the packet level, whereas _wormhole switching_ implements it on flow units, or _flits_, which are smaller than the maximum packet size but usually at least as large as the packet header. Since wormhole switches need to be capable of storing only a small portion of a packet, packets that block in the network may span several switches. This can cause other packets to block on the links they occupy, leading to premature network saturation and reduced effective bandwidth unless some centralized buffer is used within the switch to store them—a technique called _buffered wormhole switching_. As chips can implement relatively large buffers in current technology, virtual cut-through is the more commonly used switching technique. However, wormhole switching may still be preferred in OCNs designed to minimize silicon resources.

> 切割数据包开关建立了连接，以便一旦数据包的标头部分（或等效量的有效负载尾声尾随标题）在接收开关时上演。也就是说，其余的数据包在切换授予资源之前不必到达。这允许路由，仲裁和切换延迟与啤酒花的数量相加，而不是乘法，以减少数据包延迟。切割有两个品种，主要区别是应用流量控制的信息单位的大小，因此，开关处的缓冲区要求。_virtual 切割开关_在数据包级别上实现流量控制，而_ normhole switching_在流量单位或_FLITS_上实现它，它们小于最大数据包大小，但通常与数据包标头一样大。由于虫洞开关只需要能够存储一小部分数据包，因此网络中阻止的数据包可能跨越多个开关。这可能会导致其他数据包在它们所占据的链接上阻塞，从而导致过早的网络饱和度并降低有效带宽，除非在开关中使用了一些集中式缓冲区来存储它们 - 这是一种称为_Buffered 蠕虫孔切换的技术。由于芯片可以在当前技术中实施相对较大的缓冲区，因此虚拟切割是更常用的开关技术。但是，在旨在最大程度减少硅资源的 OCN 中，仍然可以选择虫洞切换。

Premature network saturation caused by wormhole switching can be mitigated by allowing several packets to share the physical bandwidth of a link simulta- neously via time-multiplexed switching at the flit level. This requires physical links to have a set of virtual channels (i.e., the logical buffers mentioned previously) at each end, into which packets are switched. Before, we saw how virtual channels can be used to decouple physical link bandwidth from buffered packets in such a way as to avoid deadlock. Now, virtual channels are multiplexed in such a way that bandwidth is switched in and used by flits of a packet to advance even though the packet may share some links in common with a blocked packet ahead. This, again, allows network bandwidth to be used more efficiently, which, in turn, reduces the average packet latency.

> 通过允许多个数据包通过 Flit 级别的时光切换，可以通过允许几个数据包共享链接的物理带宽来缓解由虫洞切换引起的过早网络饱和度。这需要物理链接在两端都具有一组虚拟通道（即，前面提到的逻辑缓冲区），然后切换到哪个数据包。以前，我们看到了如何使用虚拟通道将物理链路带宽从缓冲数据包中解脱，以避免僵局。现在，虚拟通道是多重的，以至于即使数据包可能与前方的阻止数据包共享一些共同的链接，也可以将带宽切换并用数据包进行推进。再次，这允许更有效地使用网络带宽，从而减少了平均数据包延迟。

### Impact on Network Performance

> ###对网络性能的影响

Routing, arbitration, and switching can impact the packet latency of a loaded network by reducing the contention delay experienced by packets. For an unloaded network that has no contention, the algorithms used to perform routing and arbitration have no impact on latency other than to determine the amount of delay incurred in implementing those functions at switches—typically, the pin-to-pin latency of a switch chip is several tens of nanoseconds. The only change to the best-case packet latency expression given in the previous section comes from the switching technique. Store-and-forward packet switching was assumed before in which transmission delay for the entire packet is incurred on all _d_ hops plus at the source node. For cut-through packet switching, transmission delay is pipelined across the network links comprising the packet’s path at the granularity of the packet header instead of the entire packet. Thus, this delay component is reduced, as shown in the following lower-bound expression for packet latency:

> 路由，仲裁和切换可以通过减少数据包经历的争论延迟来影响加载网络的数据包延迟。对于没有争议的卸载网络，用于执行路由和仲裁的算法对延迟没有影响，而不是确定在交换机处实现这些功能的延迟量（通常是开关的 PIN 到 PIN 潜伏期）芯片是几十纳秒。上一节中给出的最佳案例数据包延迟表达式的唯一更改来自开关技术。在源节点上所有_d_ hops Plus 上都会产生整个数据包的传输延迟之前，假定存储和前向数据包切换。对于切割数据包切换，将传输延迟在网络链接上管道延迟，其中包括数据包标头的粒度而不是整个数据包的粒度。因此，该延迟分量减少了，如以下小数据包潜伏期的下降表达式所示：

The effective bandwidth is impacted by how efficiently routing, arbitration, and switching allow network bandwidth to be used. The routing algorithm can distrib- ute traffic more evenly across a loaded network to increase the utilization of the aggregate bandwidth provided by the topology—particularly, by the bisection links. The arbitration algorithm can maximize the number of switch output ports that accept packets, which also increases the utilization of network bandwidth. The switching technique can increase the degree of resource sharing by packets, which further increases bandwidth utilization. These combine to affect network bandwidth, BW<sub>Network</sub>, by an _efficiency factor_, ρ, where 0 &lt;ρ≤ 1:

> 有效带宽受到如何有效路由，仲裁和切换的影响，可以使用网络带宽。路由算法可以在加载的网络上更均匀地分配流量，以增加拓扑所提供的骨料带宽的利用率（尤其是通过一分数链接）。仲裁算法可以最大化接受数据包的开关输出端口的数量，这也增加了网络带宽的利用率。开关技术可以增加数据包的资源共享程度，从而进一步增加带宽利用率。这些结合以影响网络带宽，bw <sub>网络</sub>，通过_效率因子_，ρ，其中 0＆lt;ρ≤1：

The efficiency factor, ρ, is difficult to calculate or to quantify by means other than simulation. Nevertheless, with this parameter we can estimate the best-case upper- bound effective bandwidth by using the following expression that takes into account the effects of routing, arbitration, and switching:

> 效率因子 ρ 难以计算或通过模拟以外的其他方式进行量化。然而，使用此参数，我们可以通过使用以下表达式来估计最佳案例上限有效带宽，以考虑路由，仲裁和切换的影响：

We note that ρ also depends on how well the network handles the traffic generated by applications. For instance, ρ could be higher for circuit switching than for cut-through switching if large streams of packets are continually transmitted between a source-destination pair, whereas the converse could be true if packets are transmitted intermittently.

> 我们注意到，ρ 还取决于网络处理应用程序生成的流量的程度。例如，如果电路开关的电路开关可能比切开的切换更高，如果在源用途对之间不断传输大量数据包，则相反的话，如果数据包间歇性地传输，则相反。

Example Compare the performance of deterministic routing versus adaptive routing for a 3D torus network interconnecting 4096 nodes. Do so by plotting latency versus applied load and throughput versus applied load. Also compare the efficiency of the best and worst of these networks. Assume that virtual cut-through switching, three-phase arbitration, and virtual channels are implemented. Consider separately the cases for two and four virtual channels, respectively. Assume that one of the virtual channels uses bubble flow control in dimension order so as to avoid dead- lock; the other virtual channels are used either in dimension order (for deterministic routing) or minimally along shortest paths (for adaptive routing), as is done in the IBM Blue Gene/L torus network.

> 示例比较了 3D 圆环网络互连 4096 节点的确定性路由与自适应路由的性能。通过绘制延迟与所施加的负载与吞吐量与所施加的负载来做到这一点。还要比较这些网络中最佳和最差的效率。假设实现了虚拟切割开关，三相仲裁和虚拟通道。分别考虑两个和四个虚拟通道的案例。假设其中一个虚拟通道使用尺寸顺序的气泡流控制以避免死锁；其他虚拟通道以尺寸顺序（用于确定性路由）或最小路径（用于自适应路由）的方式使用，就像在 IBM 蓝色基因/L 圆环网络中所做的那样。

_Answer_ It is very difficult to compute analytically the performance of routing algorithms given that their behavior depends on several network design parameters with com- plex interdependences among them. As a consequence, designers typically resort to cycle-accurate simulators to evaluate performance. One way to evaluate the effect of a certain design decision is to run sets of simulations over a range of net- work loads, each time modifying one of the design parameters of interest while keeping the remaining ones fixed. The use of synthetic traffic loads is quite fre- quent in these evaluations as it allows the network to stabilize at a certain working point and for behavior to be analyzed in detail. This is the method we use here (alternatively, trace-driven or execution-driven simulation can be used).

> _ANSWER_非常困难地通过分析计算路由算法的性能，因为它们的行为取决于它们之间具有相互依存关系的几个网络设计参数。结果，设计师通常会诉诸循环精确的模拟器以评估性能。评估某个设计决策效果的一种方法是在一系列净工作载荷上运行一组模拟，每次修改感兴趣的设计参数之一，同时将其余的固定为固定。在这些评估中，合成交通负荷的使用非常频繁，因为它允许网络在某个工作点稳定并详细分析行为。这是我们在此处使用的方法（或者可以使用跟踪驱动或执行驱动的模拟）。

[Figure F.19](#_bookmark616) shows the typical interconnection network performance plots. On the left, average packet latency (expressed in network cycles) is plotted as a func- tion of applied load (traffic generation rate) for the two routing algorithms with two and four virtual channels each; on the right, throughput (traffic delivery rate) is similarly plotted. Applied load is normalized by dividing it by the number of nodes in the network (i.e., bytes per cycle per node). Simulations are run under the assumption of uniformly distributed traffic consisting of 256-byte packets, where flits are byte sized. Routing, arbitration, and switching delays are assumed to sum to 1 network cycle per hop while the time-of-flight delay over each link is assumed to be 10 cycles. Link bandwidth is 1 byte per cycle, thus providing results that are independent of network clock frequency.

> [图 F.19]（#_ bookmark616）显示了典型的互连网络性能图。在左侧，将平均数据包延迟（在网络周期中表达）被绘制为两个带有两个和四个虚拟通道的路由算法的施加负载（交通生成速率）的功能；在右侧，同样绘制了吞吐量（流量输送率）。通过将其除以网络中的节点的数量（即每个节点每个周期的字节）来归一化。模拟是在均匀分布的流量的假设下进行的，该流量由 256 个字节数据包组成，其中 Flits 是字节大小的。假定路由，仲裁和切换延迟延迟每跳到 1 个网络周期，而在每个链接上的飞行时间延迟则假定为 10 个周期。链路带宽为每个周期 1 个字节，因此提供了独立于网络时钟频率的结果。

As can be seen, the plots within each graph have similar characteristic shapes, but they have different values. For the latency graph, all start at the no-load latency

> 可以看出，每个图内的图具有相似的特征形状，但是它们具有不同的值。对于延迟图，全部从无负载延迟开始

![](./media/image656.png)

Figure F.19 Deterministic routing is compared against adaptive routing, both with either two or four virtual channels, assuming uniformly distributed traffic on a 4 K node 3D torus network with virtual cut-through switch- ing and bubble flow control to avoid deadlock. (a) Average latency is plotted versus applied load, and (b) through- put is plotted versus applied load (the upper grayish plots show peak throughput, and the lower black plots show sustained throughput). Simulation data were collected by P. Gilabert and J. Flich at the Universidad Politècnica de València, Spain (2006).

> 图 F.19 与自适应路由相比，确定性路由与两个或四个虚拟通道进行了比较，假设在 4 K 节点 3D 圆环网络上均匀分布的流量具有虚拟切割开关和气泡流量控制，以避免僵局。（a）平均延迟与施加的负载相比绘制，并且（b）构图与施加的载荷相比（上灰色地块显示峰值吞吐量，下黑色地块显示持续的吞吐量）。P. Gilabert 和 J. Flich 收集了模拟数据，该大学是西班牙政治上的 València 大学（2006 年）。

as predicted by the latency expression given above, then slightly increase with traf- fic load as contention for network resources increases. At higher applied loads, latency increases exponentially, and the network approaches its saturation point as it is unable to absorb the applied load, causing packets to queue up at their source nodes awaiting injection. In these simulations, the queues keep growing over time, making latency tend toward infinity. However, in practice, queues reach their capacity and trigger the application to stall further packet generation, or the application throttles itself waiting for acknowledgments/responses to outstanding packets. Nevertheless, latency grows at a slower rate for adaptive routing as alter- native paths are provided to packets along congested resources.

> 正如上面给出的延迟表达式所预测的那样，随着网络资源争议的增加，随着传统负载的增加而略有增加。在较高的施加载荷下，延迟呈指数增加，网络接近其饱和点，因为它无法吸收施加的负载，从而导致数据包在其源节点等待注入的源节点排队。在这些模拟中，队列随着时间的推移不断增长，使潜伏期趋于无穷大。但是，实际上，队列达到其能力，并触发应用程序以使数据包生成更多，或者应用程序本身等待确认/对未偿还数据包的响应。然而，随着自适应路由的速度较慢，随着沿拥挤资源的数据包提供了较慢的速度。

For this same reason, adaptive routing allows the network to reach a higher peak throughput for the same number of virtual channels as compared to deterministic routing. At nonsaturation loads, throughput increases fairly linearly with applied load. When the network reaches its saturation point, however, it is unable to deliver traffic at the same rate at which traffic is generated. The saturation point, therefore, indicates the maximum achievable or “peak” throughput, which would be no more than that predicted by the effective bandwidth expression given above. Beyond saturation, throughput tends to drop as a consequence of massive head-of-line blocking across the network (as will be explained further in [Section F.6](#switch-microarchitecture)), very much like cars tend to advance more slowly at rush hour. This is an important region of the throughput graph as it shows how significant of a performance drop the routing algorithm can cause if congestion management techniques (discussed briefly in [Section F.7](#practical-issues-for-commercial-interconnection-networks)) are not used effectively. In this case, adaptive routing has more of a performance drop after saturation than deterministic routing, as mea- sured by the postsaturation sustained throughput.

> 由于这个原因，与确定性路由相比，自适应路由使网络可以达到相同数量的虚拟通道的峰值吞吐量。在非饱和载荷下，吞吐量通过施加的载荷相当线性地增加。但是，当网络达到其饱和点时，它无法以与流量产生的流量相同的速率交付流量。因此，饱和点表示最大可实现或“峰值”吞吐量，这将不超过上面给出的有效带宽表达式所预测的。除了饱和之外，由于在[F.6]（＃switch-Microharchitecture）中将进一步解释，因此吞吐量倾向于下降，这将进一步解释），就像汽车往往会进展更多一样高峰时段慢慢。这是吞吐量图的一个重要区域，因为它显示了如果交通拥堵的管理技术会导致性能下降的重要性（在[F.7]节中简要讨论））未有效使用。在这种情况下，自适应路由在饱和后的性能下降而不是确定性路由，因为后饱和持续的吞吐量可以证明。

For both routing algorithms, more virtual channels (i.e., four) give packets a greater ability to pass over blocked packets ahead, allowing for a higher peak throughput as compared to fewer virtual channels (i.e., two). For adaptive routing with four virtual channels, the peak throughput of 0.43 bytes/cycle/node is near the maximum of 0.5 bytes/cycle/node that can be obtained with 100% efficiency (i.e., ρ 100%), assuming there is enough injection and reception bandwidth to make the network bisection the bottlenecking point. In that case, the network bandwidth is simply 100% times the network bisection bandwidth (BW<sub>Bisection</sub>) divided by the fraction of traffic crossing the bisection (γ), as given by the expression above. Tak- ing into account that the bisection splits the torus into two equally sized halves, γ is equal to 0.5 for uniform traffic as only half the injected traffic is destined to a node at the other side of the bisection. The BW<sub>Bisection</sub> for a 4096-node 3D torus network is 16 16 4 unidirectional links times the link bandwidth (i.e., 1 byte/cycle). If we normalize the bisection bandwidth by dividing it by the number of nodes (as we did with network bandwidth), the BW<sub>Bisection</sub> is 0.25 bytes/cycle/node. Dividing this by γ gives the ideal maximally obtainable network bandwidth of 0.5 bytes/ cycle/node.

> 对于这两种路由算法，更多的虚拟通道（即四个）使数据包具有更大的能力，可以通过封锁的数据包，与更少的虚拟通道（即两个）相比，可以更高的峰值吞吐量。对于具有四个虚拟通道的自适应路由，0.43 字节/循环/节点的峰值吞吐量接近可以 100％效率获得的 0.5 个字节/循环/节点（即 ρ100％），假设有足够的注射，则可以获得。和接收带宽，使网络二进使瓶颈点。在这种情况下，网络带宽仅是网络二分线带宽（BW <sub> bisection </sub>）的 100％倍除以上面的表达式所给出的交叉交通分数（γ）的分数。考虑到二分位数将圆环分为两个同等大小的半半，γ 的流量等于 0.5，因为只有一半的注射流量注定为分配的另一侧。4096 节点 3D 圆环网络的 BW <sub>二次</sub>是 16 16 4 单向链接次链路带宽（即 1 个字节/循环）。如果我们通过将节点数除以节点的数量（与网络带宽一样）来归一化，则 BW <sub> bisection </sub>为 0.25 字节/循环/节点。除以 γ 提供了理想的最大获得网络带宽为 0.5 字节/循环/节点。

We can find the efficiency factor, ρ, of the simulated network simply by divid- ing the measured peak throughput by the ideal throughput. The efficiency factor for the network with fully adaptive routing and four virtual channels is 0.43/(0.25/ 0.5) 86%, whereas for the network with deterministic routing and two virtual channels it is 0.37/(0.25/0.5) 74%. Besides the 12% difference in efficiency between the two, another 14% gain in efficiency might be obtained with even bet- ter routing, arbitration, switching, and virtual channel designs.

> 我们可以简单地将测得的峰值吞吐量划分为理想吞吐量，从而找到模拟网络的效率因子 ρ。具有完全自适应路由和四个虚拟通道的网络的效率因子为 0.43/（0.25/0.5）86％，而对于具有确定性路由的网络和两个虚拟通道的网络为 0.37/（0.25/0.5）74％。除了两者之间的效率差异为 12％外，还可以通过布线路由，仲裁，切换和虚拟通道设计获得另外 14％的效率增益。

To put this discussion on routing, arbitration, and switching in perspective, Figure F.20 lists the techniques used in SANs designed for commercial high- performance computers. In addition to being applied to the SANs as shown in the figure, the issues discussed in this section also apply to other interconnect domains: from OCNs to WANs.

> 为了将讨论在路由，仲裁和切换方面进行视角，图 F.20 列出了用于商用高性能计算机的 SAN 中使用的技术。除了被应用于图中所示的 SAN 外，本节中讨论的问题还适用于其他互连域：从 OCN 到 WANS。
