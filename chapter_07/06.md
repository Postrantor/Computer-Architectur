## Intel Crest, a Data Center Accelerator for Training

> ##英特尔·克雷斯特（Intel Crest），培训数据中心加速器

The quotation by the Intel CEO that opens [Section 7.3](#example-domain-deep-neural-networks) came from the press release announcing that Intel was going to start shipping DSAs (“accelerants”) for DNN. The first example was Crest, which was announced while we were writing this edition. Despite the limited details, we include it here because of the significance of a traditional microprocessor manufacturer like Intel taking this bold step of embracing DSAs.

> 英特尔首席执行官的报价开放了[7.3 节]（＃示例域 - 深处神经网络）来自新闻稿，宣布英特尔将开始为 DNN 运送 DSA（“ Accelerants”）。第一个示例是 Crest，我们在撰写此版本时宣布了这一点。尽管细节有限，但我们在这里包括它，因为像英特尔这样的传统微处理器制造商的意义采取了这种大胆的采用 DSA 的步骤。

Crest is aimed at DNN training. The Intel CEO said the goal is to accelerate DNN training a hundredfold over the next three years. [Figure 7.6](#_bookmark332) shows that train- ing can take a month. There is likely to be a demand to decrease the DNN training to just eight hours, which would be 100 times quicker than the CEO predicted. DNNs will surely become even more complex over the next 3 years, which will require a much greater training effort. Thus there seems little danger that a 100 improvement in training is overkill.

> Crest 针对 DNN 培训。英特尔首席执行官表示，目标是在未来三年内加速 DNN 训练一百倍。[图 7.6]（#\_ bookmark332）表明训练可能需要一个月。可能需要将 DNN 培训降低到仅八个小时，这可能比首席执行官预期的快 100 倍。在未来 3 年中，DNNS 肯定会变得更加复杂，这将需要更大的培训工作。因此，似乎很少有危险训练 100 改进。

Crest instructions operate on blocks of 32 32 matrices. Crest uses a number format called _flex point_, which is a scaled fixed-point representation: 32 32 matri- ces of 16-bit data share a single 5-bit exponent that is provided as part of the instruction set.

> 波峰说明在 32 32 矩阵的块上运行。CREST 使用称为 *FLEX POINT* 的数字格式，该格式是缩放的固定点表示：16 位数据的 32 32 矩阵共享一个单个 5 位指数，该指数作为指令集的一部分提供。

[Figure 7.28](#_bookmark359) shows the block diagram of the Lake Crest chip. To compute on these matrices, Crest uses the12 processing clusters of [Figure 7.28](#_bookmark359). Each cluster includes a large SRAM, a big linear algebra processing unit, and a small amount of logic for on- and off-chip routing. The four 8 GiB HBM2 DRAM modules offer 1 TB/s of memory bandwidth, which should lead to an attractive Roofline model for the Crest chip. In addition to high-bandwidth paths to main memory, Lake Crest supports high band- width interconnects directly between compute cores inside the processing clusters, which facilitates quick core-to-core communication without passing through shared memory. Lake Crest’s goal is a factor of 10 improvement in training over GPUs.

> [图 7.28]（#_ bookmark359）显示了湖冠芯片的框图。为了计算这些矩阵，Crest 使用[图 7.28]（#_ bookmark359）的 12 处理簇。每个群集都包括一个大 SRAM，一个大的线性代数处理单元以及少量的逻辑，用于芯片和外部路由。四个 8 GIB HBM2 DRAM 模块提供 1 TB/s 的内存带宽，这应该导致带有冠状芯片的有吸引力的车顶线模型。除了通往主要记忆的高带宽路径外，湖峰还支持高带宽度在处理簇内部的计算芯之间直接互连，这有助于快速核心到核心通信而无需通过共享记忆。克雷斯特湖的目标是对 GPU 的训练有 10 倍的进步。

[Figure 7.28](#_bookmark359) shows 12 Inter-Chip Links (ICLs) and 2 Inter-Chip Controllers (ICCs), so Crest is clearly designed to allow many Crest chips to collaborate, sim- ilar in spirit to the dedicated network connecting the 48 FPGAs in Catapult. It’s likely that the 100 improvement in training will require ganging together several Crest chips.

> [图 7.28]（#\_ bookmark359）显示了 12 个芯片间链接（ICL）和 2 个芯片间控制器（ICC），因此，Crest 清楚地设计为允许许多 Crest 芯片进行协作，并与专用网络连接有关弹射器中的 48 个 FPGA。100 个训练的改进很可能需要将几个波峰芯片筹集在一起。
