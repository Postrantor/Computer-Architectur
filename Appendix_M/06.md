## The Development of Pipelining and Instruction-Level Parallelism ([Chapter 3](#_bookmark46) and [Appendices C](#_bookmark481) and [H](#_bookmark481))

> ##管道和指令级并行的开发([[第 3 章](#_ bookmark46)和[appendices c](#_ bookmark481)和[h](#_ bookmark481))

### Early Pipelined CPUs

> ###早期管道的 CPU

The first general-purpose pipelined processor is considered to be Stretch, the IBM 7030. Stretch followed the IBM 704 and had a goal of being 100 times faster than the 704. The goal was a stretch from the state of the art at that time, hence the

> 第一个通用管道的处理器被认为是伸展的，IBM7030。延伸沿 IBM 704 延伸，目标是比 704 快 100 倍。这个目标是从当时的最新状态延伸，因此

nickname. The plan was to obtain a factor of 1.6 from overlapping fetch, decode, and execute, using a four-stage pipeline. Bloch [1959] and Bucholtz [1962] described the design and engineering trade-offs, including the use of ALU bypasses.

> 昵称。该计划是使用四阶段管道从重叠的获取，解码和执行中获得 1.6 的系数。Bloch [1959]和 Bucholtz [1962]描述了设计和工程权衡，包括使用 Alu 旁路。

A series of general pipelining descriptions that appeared in the late 1970s and early 1980s provided most of the terminology and described most of the basic tech- niques used in simple pipelines. These surveys include Keller [1975], Ramamoorthy and Li [1977], and Chen [1980], as well as Kogge [1981], whose book is devoted entirely to pipelining. Davidson and his colleagues [1971, 1975] developed the concept of pipeline reservation tables as a design methodology for multicycle pipe- lines with feedback (also described in Kogge [1981]). Many designers use a varia- tion of these concepts, in either designing pipelines or in creating software to schedule them.

> 一系列在 1970 年代末和 1980 年代初出现的一系列一般管道描述提供了大部分术语，并描述了简单管道中使用的大多数基本技术。这些调查包括 Keller [1975]，Ramamoorthy 和 Li [1977]和 Chen [1980]以及 Kogge [1981]，他们的书完全致力于管道。戴维森(Davidson)和他的同事[1971，1975]开发了管道保留表的概念，作为带有反馈的多环形管道的设计方法(也在 Kogge [1981]中进行了描述)。许多设计师在设计管道或创建软件来安排这些概念时使用这些概念的变化。

The RISC processors were originally designed with ease of implementation and pipelining in mind. Several of the early RISC papers, published in the early 1980s, attempt to quantify the performance advantages of the simplification in instruction set. The best analysis, however, is a comparison of a VAX and a MIPS implementation published by Bhandarkar and Clark in 1991, 10 years after the first published RISC papers (see [Figure M.1](#_bookmark908)). After 10 years of arguments about the implementation benefits of RISC, this paper convinced even the most skeptical designers of the advantages of a RISC instruction set architecture.

> RISC 处理器最初是在易于实施和管道上设计的。1980 年代初发表的一些早期 RISC 论文试图量化教学集合中简化的性能优势。然而，最好的分析是对 Bhandarkar 和 Clark 在 1991 年发表的 VAX 和 MIPS 实施的比较，这是在首次发表的 RISC 论文 10 年后(见[图 M.1](#_ bookmark908))。经过 10 年关于 RISC 实施益处的争论，本文甚至说服了最怀疑的设计师 RISC 教学套装体系结构的优势。

J. E. Smith and his colleagues have written a number of papers examining instruction issue, exception handling, and pipeline depth for high-speed scalar CPUs. Kunkel and Smith [1986] evaluated the impact of pipeline overhead and dependences on the choice of optimal pipeline depth; they also provided an excel- lent discussion of latch design and its impact on pipelining. Smith and Pleszkun [1988] evaluated a variety of techniques for preserving precise exceptions. Weiss and Smith [1984] evaluated a variety of hardware pipeline scheduling and instruc- tion issue techniques.

> J. E. Smith 和他的同事们写了许多论文，研究了指导问题，例外处理和高速标量 CPU 的管道深度。Kunkel 和 Smith [1986]评估了管道开销的影响以及对最佳管道深度选择的依赖。他们还提供了关于闩锁设计及其对管道的影响的出色讨论。Smith and Pleszkun [1988]评估了保留精确例外的各种技术。Weiss 和 Smith [1984]评估了各种硬件管道调度和指导问题技术。

The MIPS R4000 was one of the first deeply pipelined microprocessors and is described by Killian [1991] and by Heinrich [1993]. The initial Alpha implemen- tation (the 21064) has a similar instruction set and similar integer pipeline struc- ture, with more pipelining in the floating-point unit.

> MIPS R4000 是第一个深层管道的微处理器之一，由 Killian [1991]和 Heinrich [1993]描述。初始 α 实施(21064)具有相似的指令集和类似的整数管道结构，在浮点单元中具有更多的管道。

### The Introduction of Dynamic Scheduling

> ###引入动态调度

In 1964, CDC delivered the first CDC 6600. The CDC 6600 was unique in many ways. In addition to introducing scoreboarding, the CDC 6600 was the first pro- cessor to make extensive use of multiple functional units. It also had peripheral processors that used multithreading. The interaction between pipelining and instruction set design was understood, and a simple, load-store instruction set was used to promote pipelining. The CDC 6600 also used an advanced packaging technology. Thornton [1964] described the pipeline and I/O processor architecture, including the concept of out-of-order instruction execution. Thornton’s book [1970] provides an excellent description of the entire processor, from technology to architecture, and includes a foreword by Cray. (Unfortunately, this book is currently out of print.) The CDC 6600 also has an instruction scheduler for the FORTRAN compilers, described by Thorlin [1967].

> 1964 年，CDC 交付了第一个 CDC6600。CDC6600 在许多方面都是独一无二的。除了引入计分板外，CDC 6600 是第一个广泛使用多个功能单元的专业人士。它还具有使用多线程的外围处理器。理解管道和指令集设计之间的相互作用，并使用简单的负载储物指令集来促进管道。CDC 6600 还使用了高级包装技术。Thornton [1964]描述了管道和 I/O 处理器体系结构，包括执行额外指令的概念。Thornton 的书[1970]很好地描述了整个处理器，从技术到建筑，并包括 Cray 的前言。(不幸的是，这本书目前是绝版的。)CDC 6600 还为 Fortran 编译器提供了指令调度程序，由 Thorlin [1967]描述。

### The IBM 360 Model 91: A Landmark Computer

> ### IBM 360 模型 91：地标电脑

The IBM 360/91 introduced many new concepts, including tagging of data, reg- ister renaming, dynamic detection of memory hazards, and generalized forward- ing. Tomasulo’s algorithm is described in his 1967 paper. Anderson, Sparacio, and Tomasulo [1967] described other aspects of the processor, including the use of branch prediction. Many of the ideas in the 360/91 faded from use for nearly 25 years before being broadly resurrected in the 1990s. Unfortunately, the 360/91 was not successful, and only a handful were sold. The complexity of the design made it late to the market and allowed the Model 85, which was the first IBM processor with a cache, to outperform the 91.

> IBM 360/91 引入了许多新概念，包括标记数据，重命名，动态记忆危害和广义前进。Tomasulo 的算法在他的 1967 年论文中进行了描述。Anderson，Sparacio 和 Tomasulo [1967]描述了处理器的其他方面，包括使用分支预测。360/91 中的许多想法在 1990 年代广泛复活之前逐渐消失了近 25 年。不幸的是，360/91 没有成功，只有少量出售。设计的复杂性使市场迟到了，并允许 85 Model 85，这是第一个具有缓存的 IBM 处理器，可以超越 91。

### Branch-Prediction Schemes

> ###分支预测计划

The 2-bit dynamic hardware branch-prediction scheme was described by J. E. Smith [1981]. Ditzel and McLellan [1987] described a novel branch-target buffer for CRISP, which implements branch folding. The correlating predictor we exam- ine was described by Pan, So, and Rameh [1992]. Yeh and Patt [1992, 1993] gen- eralized the correlation idea and described multilevel predictors that use branch histories for each branch, similar to the local history predictor used in the 21264. McFarling’s tournament prediction scheme, which he refers to as a com- bined predictor, is described in his 1993 technical report. There are a variety of more recent papers on branch prediction based on variations in the multilevel and correlating predictor ideas. Kaeli and Emma [1991] described return address prediction, and Evers et al. [1998] provided an in-depth analysis of multilevel pre- dictors. The data shown in [Chapter 3](#_bookmark93) are from Skadron et al. [1999]. There are several schemes for prediction that may offer some additional benefit beyond tour- nament predictors. Eden and Mudge [1998] and Jimenez and Lin [2002] have described such approaches.

> J. E. Smith [1981]描述了 2 位动态硬件分支预测方案。Ditzel 和 McLellan [1987]描述了一种新颖的分支靶向缓冲液，用于 Crisp，该缓冲液实现了分支折叠。我们检查的相关预测因子由 Pan，So 和 Rameh [1992]描述。Yeh 和 Patt [1992，1993]赋予了相关性思想，并描述了每个分支使用分支历史的多级预测指标，类似于 21264 中使用的局部历史预测指标。在他的 1993 年技术报告中描述了固定的预测因子。基于多级和相关的预测器思想的变化，有各种各样的有关分支预测的论文。Kaeli 和 Emma [1991]描述了返回地址预测，Evers 等人。[1998]提供了对多层次预测师的深入分析。[第 3 章](#_ bookmark93)中显示的数据来自 Skadron 等。[1999]。有几种预测方案可能会为旅游预测指标提供一些额外的好处。Eden 和 Mudge [1998]以及 Jimenez 和 Lin [2002]描述了这种方法。

### The Development of Multiple-Issue Processors

> ###多发处理器的开发

IBM did pioneering work on multiple issue. In the 1960s, a project called ACS was under way in California. It included multiple-issue concepts, a proposal for dynamic scheduling (although with a simpler mechanism than Tomasulo’s scheme, which used backup registers), and fetching down both branch paths. The project originally started as a new architecture to follow Stretch and surpass the CDC 6600/6800. ACS started in New York but was moved to California, later changed to be S/360 com- patible, and eventually canceled. John Cocke was one of the intellectual forces behind the team that included a number of IBM veterans and younger contributors,

> IBM 在多个问题上进行了开创性的工作。在 1960 年代，加利福尼亚州正在进行一个名为 ACS 的项目。它包括多发概念，这是动态调度的建议(尽管使用备份寄存器的托马苏洛方案更简单的机制)，并取下了两个分支路径。该项目最初是作为一个新的建筑开始，以遵循拉伸并超过 CDC 6600/6800。ACS 在纽约开始，但被转移到加利福尼亚，后来更改为 S/360 合并，并最终被取消。约翰·科克(John Cocke)是团队背后的知识力量之一，其中包括许多 IBM 退伍军人和年轻贡献者，

many of whom went on to other important roles in IBM and elsewhere: Jack Ber- tram, Ed Sussenguth, Gene Amdahl, Herb Schorr, Fran Allen, Lynn Conway, and Phil Dauber, among others. While the compiler team published many of their ideas and had great influence outside IBM, the architecture ideas were not widely disseminated at that time. The most complete accessible documentation of this important project is at _[www.cs.clemson.edu/](http://www.cs.clemson.edu/~mark/acs.html) [mark/acs.html](http://www.cs.clemson.edu/~mark/acs.html)_, which includes inter- views with the ACS veterans and pointers to other sources. Sussenguth [1999] is a good overview of ACS.

> 其中许多人继续在 IBM 和其他地方扮演其他重要角色：Jack Bertram，Ed Sussenguth，Gene Amdahl，Herb Schorr，Fran Allen，Lynn Conway 和 Phil Dauber 等。虽然编译器团队发表了许多想法，并且在 IBM 之外产生了很大的影响，但当时的建筑思想并未被广泛传播。这个重要项目的最完整的文档是在_ [[www.cs.clemson.edu/](http://www.cs.clemson.edu/)]([www.cs.clemson.edu/~mark/acs.html](http://www.cs.clemson.edu/~mark/acs.html))[mark/acs.html]([www.cs.clemson.edu/~mark/acs.html)](http://www.cs.clemson.edu/~mark/acs.html))_，其中包括与 ACS 退伍军人的视图和其他来源的指示。Sussenguth [1999]是 ACS 的良好概述。

Most of the early multiple-issue processors that actually reached the market followed an LIW or VLIW design approach. Charlesworth [1981] reported on the Floating Point Systems AP-120B, one of the first wide-instruction processors containing multiple operations per instruction. Floating Point Systems applied the concept of software pipelining both in a compiler and by handwriting assembly language libraries to use the processor efficiently. Because the processor was an attached processor, many of the difficulties of implementing multiple issue in general-purpose processors (for example, virtual memory and exception handling) could be ignored.

> 实际上到达市场的大多数早期多发处理器遵循 LIW 或 VLIW 设计方法。Charlesworth [1981]报道了浮点系统 AP-1220B，这是每个指令中包含多个操作的第一个宽指令处理器之一。浮点系统应用了软件在编译器和手写汇编语言库中提供管道的概念，以有效地使用处理器。由于处理器是一个附件的处理器，因此可以忽略在通用处理器中实现多个问题的许多困难(例如，虚拟内存和异常处理)。

One of the interesting approaches used in early VLIW processors, such as the AP-120B and i860, was the idea of a pipeline organization that requires operations to be “pushed through” a functional unit and the results to be caught at the end of the pipeline. In such processors, operations advance only when another operation pushes them from behind (in sequence). Furthermore, an instruction specifies the destination for an instruction issued earlier that will be pushed out of the pipeline when this new operation is pushed in. Such an approach has the advantage that it does not specify a result destination when an operation first issues but only when the result register is actually written. This separation eliminates the need to detect write after write (WAW) and write after read (WAR) hazards in the hardware. The disadvantage is that it increases code size since no-ops may be needed to push results out when there is a dependence on an operation that is still in the pipeline and no other operations of that type are immediately needed. Instead of the “push-and- catch” approach used in these two processors, almost all designers have chosen to use _self-draining pipelines_ that specify the destination in the issuing instruction and in which an issued instruction will complete without further action. The advantages in code density and simplifications in code generation seem to outweigh the advan- tages of the more unusual structure.

> 早期 VLIW 处理器中使用的一种有趣的方法，例如 AP-1220B 和 I860，是一个管道组织的想法，该组织需要“推动”操作一个功能单元，并且结果将在结束时捕获。管道。在这样的处理器中，只有当另一个操作从后面推动(顺序)时，操作才会推进。此外，一项指令指定了前面发出的指令的目的地结果寄存器实际上是编写的。这种分离消除了在硬件中读取(战争)危害后写入(WAW)和写入的需要。缺点是它增加了代码大小，因为当对仍在管道中的操作依赖且不需要其他操作时，可能需要 NO-OPS 才能将结果推出。与其在这两个处理器中使用的“推和捕获”方法，几乎所有设计人员都选择使用_自我排水管道_指定发行指令中目的地的目的地以及发行指令将完成的情况下完成的无行动。代码密度和代码生成的简化优势似乎超过了更异常结构的优势。

Several research projects introduced some form of multiple issue in the mid- 1980s. For example, the Stanford MIPS processor had the ability to place two operations in a single instruction, although this capability was dropped in com- mercial variants of the architecture, primarily for performance reasons. Along with his colleagues at Yale, Fisher [1983] proposed creating a processor with a very wide instruction (512 bits) and named this type of processor a VLIW. Code was generated for the processor using trace scheduling, which Fisher [1981] had developed originally for generating horizontal microcode. The imple- mentation of trace scheduling for the Yale processor is described by Fisher et al. [1984] and by Ellis [1986].

> 1980 年代中期，一些研究项目引入了某种形式的多个问题。例如，斯坦福 MIPS 处理器能够在单个指令中放置两个操作，尽管该功能在架构的商业变体中删除，主要是出于绩效原因。Fisher [1983]与他在耶鲁大学的同事一起创建一个具有非常广泛指导(512 位)的处理器，并将这种类型的处理器命名为 VLIW。Fisher [1981]最初开发了用于生成水平微模的制定的 Trace Scheduling 为处理器生成代码。Fisher 等人描述了耶鲁处理器的痕量调度。[1984]和 Ellis [1986]。

Although IBM canceled ACS, active research in the area continued in the 1980s. More than 10 years after ACS was canceled, John Cocke made a new proposal for a superscalar processor that dynamically made issue decisions; he and Tilak Agerwala described the key ideas in several talks in the mid-1980s and coined the term _superscalar_. He called the design America; it is described by Agerwala and Cocke [1987]. The IBM Power1 architecture (the RS/6000 line) is based on these ideas (see Bakoglu et al. [1989]).

> 尽管 IBM 取消了 ACS，但该地区的积极研究仍在 1980 年代继续进行。ACS 取消十多年后，约翰·科克(John Cocke)为超级标准处理器提出了新的建议，该加工机动态做出了发行决策。他和蒂拉克·阿格瓦拉(Tilak Agerwala)在 1980 年代中期的几个演讲中描述了关键思想，并创造了_superscalar_一词。他称呼美国设计；它由 Agerwala 和 Cocke [1987]描述。IBM Power1 体系结构(RS/6000 线)基于这些想法(参见 Bakoglu 等人[1989])。

J. E. Smith [1984] and his colleagues at Wisconsin proposed the decoupled approach that included multiple issue with limited dynamic pipeline scheduling. A key feature of this processor is the use of queues to maintain order among a class of instructions (such as memory references) while allowing it to slip behind or ahead of another class of instructions. The Astronautics ZS-1 described by Smith et al. [1987] embodies this approach with queues to connect the load-store unit and the operation units. The Power2 design uses queues in a similar fashion. J. E. Smith [1989] also described the advantages of dynamic scheduling and compared that approach to static scheduling.

> J. E. Smith [1984]及其在威斯康星州的同事提出了脱钩的方法，其中包括有限的动态管道计划的多个问题。该处理器的一个关键功能是使用队列在一类指令(例如内存引用)之间保持顺序，同时允许其在其他类别的指令后面或前方滑动。Smith 等人描述的宇航学 ZS-1。[1987]用队列体现了这种方法，以连接负载店单元和操作单元。Power2 Design 以类似的方式使用队列。J. E. Smith [1989]还描述了动态调度的优势，并将这种方法与静态调度进行了比较。

The concept of speculation has its roots in the original 360/91, which per- formed a very limited form of speculation. The approach used in recent processors combines the dynamic scheduling techniques of the 360/91 with a buffer to allow in-order commit. Smith and Pleszkun [1988] explored the use of buffering to maintain precise interrupts and described the concept of a reorder buffer. Sohi [1990] described adding renaming and dynamic scheduling, making it possible to use the mechanism for speculation. Patt and his colleagues were early propo- nents of aggressive reordering and speculation. They focused on checkpoint and restart mechanisms and pioneered an approach called HPSm, which is also an extension of Tomasulo’s algorithm [Hwu and Patt 1986].

> 投机的概念根源在原始的 360/91 中，从而形成了非常有限的投机形式。最近的处理器中使用的方法将 360/91 的动态调度技术与缓冲区结合在一起，以允许订购提交。Smith and Pleszkun [1988]探索了使用缓冲以保持精确中断的使用，并描述了重新订购缓冲液的概念。Sohi [1990]描述了添加重命名和动态调度，从而可以使用该机制进行投机。帕特(Patt)和他的同事是激进的重新排序和猜测的早期提议。他们专注于检查点和重新启动机制，并开创了一种称为 HPSM 的方法，这也是 Tomasulo 算法的扩展[HWU 和 Patt 1986]。

The use of speculation as a technique in multiple-issue processors was evalu- ated by Smith, Johnson, and Horowitz [1989] using the reorder buffer technique; their goal was to study available ILP in nonscientific code using speculation and multiple issue. In a subsequent book, Johnson [1990] described the design of a speculative superscalar processor. Johnson later led the AMD K-5 design, one of the first speculative superscalars.

> Smith，Johnson 和 Horowitz [1989]评估了在多发处理器中使用投机作为一种技术的使用；他们的目标是使用猜测和多个问题研究可用的 ILP。Johnson [1990]在随后的一本书中描述了投机性超大在处理器的设计。Johnson 后来领导了 AMD K-5 设计，这是最早投机性超级标准之一。

In parallel with the superscalar developments, commercial interest in VLIW approaches also increased. The Multiflow processor (see Colwell et al. [1987]) was based on the concepts developed at Yale, although many important refine- ments were made to increase the practicality of the approach. Among these was a control-lable store buffer that provided support for a form of speculation. Although more than 100 Multiflow processors were sold, a variety of problems, including the difficulties of introducing a new instruction set from a small company and competition from commercial RISC microprocessors that changed the economics in the mini-computer market, led to the failure of Multiflow as a company.

> 与超级发展的同时，对 VLIW 方法的商业兴趣也增加了。Multiflow 处理器(参见 Colwell 等人[1987])是基于在耶鲁大学开发的概念，尽管做出了许多重要的精炼以提高方法的实用性。其中包括一个可控制的商店缓冲区，为一种投机形式提供了支持。尽管售出了 100 多个多股处理器，但各种问题，包括引入小型公司的新指令的困难以及商业 RISC 微处理器的竞争，改变了迷你计算机市场的经济性，导致了多股的失败。作为一家公司。

Around the same time as Multiflow, Cydrome was founded to build a VLIW- style processor (see Rau et al. [1989]), which was also unsuccessful commercially. Dehnert, Hsu, and Bratt [1989] explained the architecture and performance of the Cydrome Cydra 5, a processor with a wide-instruction word that provides dynamic register renaming and additional support for software pipelining. The Cydra 5 is a unique blend of hardware and software, including conditional instructions and register rotation, aimed at extracting ILP. Cydrome relied on more hardware than the Multiflow processor and achieved competitive performance primarily on vector-style codes. In the end, Cydrome suffered from problems similar to those of Multiflow and was not a commercial success. Both Multiflow and Cydrome, although unsuccessful as commercial entities, produced a number of people with extensive experience in exploiting ILP as well as advanced compiler technology; many of those people have gone on to incorporate their experience and the pieces of the technology in newer processors. Fisher and Rau [1993] edited a comprehen- sive collection of papers covering the hardware and software of these two impor- tant processors.

> 大约在 Multiflow 的同一时间，Cydrome 的成立是为了构建 VLIW 风格的处理器(参见 Rau 等人[1989])，该处理器在商业上也没有成功。Dehnert，Hsu 和 Bratt [1989]解释了 Cydrome Cydra 5 的体系结构和性能，Cydrome Cydra 5 是一个带有广泛指导词的处理器，可提供动态寄存器重命名和对软件管道管道的额外支持。Cydra 5 是硬件和软件的独特混合物，包括有条件的说明和寄存器旋转，旨在提取 ILP。与多股处理器相比，Cydrome 更依赖于硬件，并且主要在矢量式代码上实现了竞争性能。最后，Cydrome 遭受了类似于 Multiflow 的问题，并不是商业上的成功。Multiflow 和 Cydrome 虽然作为商业实体不成功，但却产生了许多在利用 ILP 和高级编译器技术方面经验丰富的人。这些人中的许多人都继续将他们的经验和技术的碎片纳入新的处理器中。Fisher and Rau [1993]编辑了一本全面的论文集合，涵盖了这两个重要处理器的硬件和软件。

Rau had also developed a scheduling technique called _polycyclic scheduling_, which is a basis for most software-pipelining schemes (see Rau, Glaeser, and Picard [1982]). Rau’s work built on earlier work by Davidson and his colleagues on the design of optimal hardware schedulers for pipelined processors. Other his- torical LIW processors have included the Apollo DN 10000 and the Intel i860, both of which could dual-issue FP and integer operations.

> Rau 还开发了一种名为_polycyclic Schedul__的调度技术，该技术是大多数软件访问方案的基础(请参阅 Rau，Glaeser 和 Picard [1982])。Rau 的作品建立在戴维森(Davidson)及其同事对管道处理器最佳硬件调度程序设计的早期作品上。其他历史性 LIW 处理器还包括 Apollo DN 10000 和 Intel I860，两者都可以双发出 FP 和整数操作。

### Compiler Technology and Hardware Support for Scheduling

> ###编译器技术和硬件支持用于调度

Loop-level parallelism and dependence analysis were developed primarily by D. Kuck and his colleagues at the University of Illinois in the 1970s. They also coined the commonly used terminology of _antidependence_ and _output dependence_ and developed several standard dependence tests, including the GCD and Banerjee tests. The latter test was named after Uptal Banerjee and comes in a variety of fla- vors. Recent work on dependence analysis has focused on using a variety of exact tests ending with a linear programming algorithm called Fourier–Motzkin. D. Maydan and W. Pugh both showed that the sequences of exact tests were a prac- tical solution.

> 循环级别的并行性和依赖分析主要由 D. Kuck 及其同事在 1970 年代在伊利诺伊大学进行。他们还创造了_antidePendence_和_Output 依赖_的常用术语，并开发了多个标准依赖测试，包括 GCD 和 BanerJee 测试。后一个测试以 Auttal Banerjee 的名字命名，并具有多种速度。关于依赖分析的最新工作集中在使用以线性编程算法为结尾的各种精确测试，称为傅立叶 - 莫兹金。D. Maydan 和 W. Pugh 都表明精确测试的序列是实践溶液。

In the area of uncovering and scheduling ILP, much of the early work was con- nected to the development of VLIW processors, described earlier. Lam [1988] developed algorithms for software pipelining and evaluated their use on Warp, a wide-instruction-word processor designed for special-purpose applications. Weiss and Smith [1987] compared software pipelining versus loop unrolling as techniques for scheduling code on a pipelined processor. Rau [1994] developed modulo scheduling to deal with the issues of software-pipelining loops and simul- taneously handling register allocation.

> 在发现和调度 ILP 领域，早期的大部分工作都与 VLIW 处理器的开发相结合。Lam [1988]开发了用于软件管道的算法，并评估了它们在 Warp 上的用途，这是一种宽建筑字处理器，专为特殊用途应用而设计。Weiss and Smith [1987]将软件管道上的与循环展开与管道处理器上的调度代码进行了比较。Rau [1994]开发了 Modulo 计划，以处理软件流行循环和模拟处理寄存器分配的问题。

Support for speculative code scheduling was explored in a variety of contexts, including several processors that provided a mode in which exceptions were ignored, allowing more aggressive scheduling of loads (e.g., the MIPS TFP pro- cessor [Hsu 1994]). Several groups explored ideas for more aggressive hardware support for speculative code scheduling. For example, Smith, Horowitz, and Lam

> 在各种上下文中探讨了对投机代码调度的支持，包括几个提供了忽略例外模式的处理器，从而使负载更加积极地调度(例如，MIPS TFP Prosessor [HSU 1994])。几个小组探索了想法，以提供投机代码调度的更多积极性硬件支持。例如，史密斯，霍洛维茨和林

[1992] created a concept called boosting that contains a hardware facility for sup- porting speculation but provides a checking and recovery mechanism, similar to those in IA-64 and Crusoe. The sentinel scheduling idea, which is also similar to the speculate-and-check approach used in both Crusoe and the IA-64 architec- tures, was developed jointly by researchers at the University of Illinois and HP Laboratories (see Mahlke et al. [1992]).

> [1992]创建了一个名为 Boosting 的概念，该概念包含用于投机的硬件设施，但提供了一种检查和恢复机制，类似于 IA-64 和 Crusoe 中的恢复机制。Sentinel 调度构想也类似于 Crusoe 和 IA-64 架构中使用的推测和检查方法，是由伊利诺伊大学和 HP 实验室的研究人员共同开发的(参见 Mahlke 等。1992])。

In the early 1990s, Wen-Mei Hwu and his colleagues at the University of Illi- nois developed a compiler framework, called IMPACT (see Chang et al. [1991]), for exploring the interaction between multiple-issue architectures and compiler technology. This project led to several important ideas, including superblock scheduling (see Hwu et al. [1993]), extensive use of profiling for guiding a variety of optimizations (e.g., procedure inlining), and the use of a special buffer (similar to the ALAT or program-controlled store buffer) for compile-aided memory con- flict detection (see Gallagher et al. [1994]). They also explored the performance trade-offs between partial and full support for predication in Mahlke et al. [1995]. The early RISC processors all had delayed branches, a scheme inspired from microprogramming, and several studies on compile time branch prediction were inspired by delayed branch mechanisms. McFarling and Hennessy [1986] did a quantitative comparison of a variety of compile time and runtime branch- prediction schemes. Fisher and Freudenberger [1992] evaluated a range of compile time branch-prediction schemes using the metric of distance between mispredic- tions. Ball and Larus [1993] and Calder et al. [1997] described static prediction schemes using collected program behavior.

> 在 1990 年代初，Wen-Mei HWU 及其伊利诺伊大学的同事开发了一个称为 Impact 的编译器框架(参见 Chang 等人[1991])，以探索多发架构与编译器技术之间的相互作用。该项目导致了几个重要的想法，包括超级封锁计划(参见 HWU 等人[1993])，广泛使用分析来指导各种优化(例如，程序内部)，以及使用特殊缓冲区(类似于类似的缓冲区)用于编译的存储器检测检测的 ALAT 或程序控制的商店缓冲区)(参见 Gallagher 等人[1994])。他们还探索了 Mahlke 等人对偏见的部分和全面支持之间的性能权衡。[1995]。早期的 RISC 处理器都延迟了分支，这是从微型编程中启发的方案，以及关于编译时间分支预测的几项研究受到延迟分支机制的启发。McFarling 和 Hennessy [1986]对各种编译时间和运行时分支预测方案进行了定量比较。Fisher and Freudenberger [1992]使用错误预示的距离度量评估了一系列编译时间分支预测方案。Ball and Larus [1993]和 Calder 等。[1997]使用收集的程序行为描述了静态预测方案。

### EPIC and the IA-64 Development

> ### Epic 和 IA-64 开发

The roots of the EPIC approach lie in earlier attempts to build LIW and VLIW machines—especially those at Cydrome and Multiflow—and in a long history of compiler work that continued after these companies failed at HP, the University of Illinois, and elsewhere. Insights gained from that work led designers at HP to propose a VLIW-style, 64-bit architecture to follow the HP PA RISC architecture. Intel was looking for a new architecture to replace the x86 (now called IA-32) architecture and to provide 64-bit capability. In 1995, they formed a partnership to design a new architecture, IA-64 (see Huck et al. [2000]), and build processors based on it. Itanium (see Sharangpani and Arora [2000]) is the first such processor. In 2002, Intel introduced the second-generation IA-64 design, the Itanium 2 (see McNairy and Soltis [2003] and McCormick and Knies [2002]).

> 史诗般的方法的根源在于早期试图建造 Liw 和 Vliw 机器，尤其是在 Cydrome 和 Multiflow 的机器，以及在这些公司在 HP，伊利诺伊大学和其他地方失败后继续进行的编译器工作的悠久历史。从这项工作中获得的洞察力导致惠普的设计师提出了 VLIW 风格的 64 位体系结构，以遵循 HP PA RISC 建筑。英特尔正在寻找一种新的体系结构来替换 X86(现称 IA-32)体系结构并提供 64 位功能。1995 年，他们建立了一个合作伙伴关系，以设计新的体系结构 IA-64(参见 Huck 等人[2000])，并基于它来构建处理器。Itanium(见 Sharangpani 和 Arora [2000])是第一个这样的处理器。2002 年，英特尔推出了第二代 IA-64 设计，即 Itanium 2(参见 McNairy 和 Soltis [2003]以及 McCormick and Knies [2002])。

### Studies of ILP and Ideas to Increase ILP

> ### ILP 的研究和增加 ILP 的想法

A series of early papers, including Tjaden and Flynn [1970] and Riseman and Foster [1972], concluded that only small amounts of parallelism could be available at the instruction level without investing an enormous amount of hardware. These papers dampened the appeal of multiple instruction issue for more than 10 years.

> 包括 Tjaden 和 Flynn [1970]以及 Riseman and Foster [1972]在内的一系列早期论文得出的结论是，只能在教学级别可用少量的并行性，而无需投资大量的硬件。这些论文抑制了十多年的多个指导问题的吸引力。

Nicolau and Fisher [1984] published a paper based on their work with trace sched- uling and asserted the presence of large amounts of potential ILP in scientific programs.

> Nicolau and Fisher [1984]根据他们与 Trace Scheduling 的工作发表了一篇论文，并主张了科学计划中存在大量潜在 ILP。

Since then there have been many studies of the available ILP. Such studies have been criticized because they presume some level of both hardware support and compiler technology. Nonetheless, the studies are useful to set expectations as well as to understand the sources of the limitations. Wall has participated in sev- eral such studies, including Jouppi and Wall [1989] and Wall [1991, 1993]. Although the early studies were criticized as being conservative (e.g., they didn’t include speculation), the last study is by far the most ambitious study of ILP to date and the basis for the data in [Section 3.10](#_bookmark93). Sohi and Vajapeyam [1989] provided measurements of available parallelism for wide-instruction-word processors. Smith, Johnson, and Horowitz [1989] also used a speculative superscalar processor to study ILP limits. At the time of their study, they anticipated that the processor they specified was an upper bound on reasonable designs. Recent and upcoming processors, however, are likely to be at least as ambitious as their processor. Skadron et al. [1999] examined the performance trade-offs and limitations in a processor comparable to the most aggressive processors in 2005, concluding that the larger window sizes will not make sense without significant improvements on branch prediction for integer programs.

> 从那时起，就有许多有关可用 ILP 的研究。此类研究之所以受到批评，是因为它们假定硬件支持和编译器技术水平。但是，这些研究对于设定期望以及了解局限性的来源很有用。沃尔(Wall)参加了该研究，包括 Jouppi 和 Wall [1989]和 Wall [1991，1993]。尽管早期的研究被批评为保守的(例如，它们没有猜测)，但最后一项研究是迄今为止对 ILP 的最雄心勃勃的研究，也是[3.10](#_ bookmark93)中数据的基础。Sohi 和 Vajapeyam [1989]为广泛的处理器提供了可用的并行性测量。Smith，Johnson 和 Horowitz [1989]还使用投机性超量表处理器来研究 ILP 限制。在学习时，他们预计他们指定的处理器是合理设计的上限。然而，最近和即将到来的处理器可能至少与处理器一样雄心勃勃。Skadron 等。[1999]研究了与 2005 年最激进的处理器相当的处理器的性能权衡和局限性，得出的结论是，如果没有对整数程序的分支机构预测的重大改进，较大的窗口尺寸将是没有意义的。

Lam and Wilson [1992] looked at the limitations imposed by speculation and showed that additional gains are possible by allowing processors to speculate in multiple directions, which requires more than one PC. (Such schemes cannot exceed what perfect speculation accomplishes, but they help close the gap between realistic prediction schemes and perfect prediction.) Wall’s 1993 study includes a limited evaluation of this approach (up to eight branches are explored).

> Lam and Wilson [1992]研究了通过投机所施加的局限性，并表明通过允许处理器猜测多个方向，这可能是可能的，这需要多个 PC。(此类方案不能超过完美的投机成就，但是它们有助于缩小现实预测方案和完美预测之间的差距。)Wall 的 1993 年研究包括对这种方法的有限评估(最多探索了八个分支)。

### Going Beyond the Data Flow Limit

> ###超越数据流量限制

One other approach that has been explored in the literature is the use of value pre- diction. Value prediction can allow speculation based on data values. There have been a number of studies of the use of value prediction. Lipasti and Shen published two papers in 1996 evaluating the concept of value prediction and its potential impact on ILP exploitation. Calder, Reinman, and Tullsen [1999] explored the idea of selective value prediction. Sodani and Sohi [1997] approached the same prob- lem from the viewpoint of reusing the values produced by instructions. Moshovos et al. [1997] showed that deciding when to speculate on values, by tracking whether such speculation has been accurate in the past, is important to achieving performance gains with value speculation. Moshovos and Sohi [1997] and Chrysos and Emer [1998] focused on predicting memory dependences and using this infor- mation to eliminate the dependence through memory. González and González [1998], Babbay and Mendelson [1998], and Calder, Reinman, and Tullsen [1999] are more recent studies of the use of value prediction. This area is currently highly active, with new results being published in every conference.

> 文献中探索的另一种方法是使用价值词语。价值预测可以允许基于数据值投机。有许多关于价值预测使用的研究。Lipasti 和 Shen 在 1996 年发表了两篇论文，评估了价值预测的概念及其对 ILP 开发的潜在影响。Calder，Reinman 和 Tullsen [1999]探索了选择性价值预测的想法。Sodani 和 Sohi [1997]从重复使用指令产生的值的角度接近了相同的问题。Moshovos 等。[1997]表明，决定何时通过跟踪过去的推测是否准确地推测值，对于以价值推测来实现绩效提高至关重要。Moshovos 和 Sohi [1997]以及 Chrysos 和 Emer [1998]着重于预测记忆依赖并使用此信息来消除通过记忆消除依赖性。González 和 González[1998]，Babbay 和 Mendelson [1998]以及 Calder，Reinman 和 Tullsen [1999]是关于价值预测使用的最新研究。该领域目前很活跃，每次会议都将发布新的结果。

### Recent Advanced Microprocessors

> ###最近的高级微处理器

The years 1994 and 1995 saw the announcement of wide superscalar processors (three or more issues per clock) by every major processor vendor: Intel Pentium Pro and Pen- tium II (these processors share the same core pipeline architecture, described by Col- welland Steck[1995]); AMDK-5, K-6, and Athlon; Sun UltraSPARC(see Lauterbach and Horel [1999]); Alpha 21164 (see Edmondson et al. [1995]) and 21264 (see Kessler [1999]); MIPS R10000 and R12000 (see Yeager [1996]); PowerPC 603, 604, and 620 (see Diep, Nelson, and Shen [1995]); and HP 8000 (Kumar [1997]). The latter part of the decade (1996–2000) saw second generations of many of these processors (Pentium III, AMD Athlon, and Alpha 21264, among others). The second generation, although similar in issue rate, could sustain a lower CPI and provided much higher clock rates. All included dynamic scheduling, and they almost universally supported speculation. In practice, many factors, including the implementation technology, the memory hier- archy, the skill of the designers, and the type of applications benchmarked, all play a role in determining which approach is best.

> 1994 年和 1995 年，每个主要的处理器供应商宣布了广泛的超级处理器(每个时钟三个或更多问题)：英特尔奔腾 Pro 和 Pentium II(这些处理器共享相同的核心管道架构，由 Col-Welland Steck 描述[1995]);AMDK-5，K-6 和 Athlon；Sun Ultrasparc(见 Lauterbach 和 Horel [1999])；Alpha 21164(见 Edmondson 等人[1995])和 21264(见 Kessler [1999])；MIPS R10000 和 R12000(见 Yeager [1996])；PowerPC 603、604 和 620(见 Diep，Nelson 和 Shen [1995])；和 HP 8000(Kumar [1997])。十年后的后期(1996-2000)看到了许多这样的处理器的第二代(Pentium III，AMD Athlon 和 Alpha 21264 等)。第二代虽然发行率相似，但可以维持较低的 CPI 并提供更高的时钟率。所有这些都包括动态调度，并且几乎普遍支持猜测。实际上，许多因素，包括实施技术，内存范围，设计师的技能以及基准的应用程序类型，都在确定哪种方法是最好的。

The period from 2000 to 2005 was dominated by three trends among superscalar processors: the introduction of higher clock rates achieved through deeper pipelin- ing (e.g., in the Pentium 4; see Hinton et al. [2001]), the introduction of multithread- ing by IBM in the Power 4 and by Intel in the Pentium 4 Extreme, and the beginning of the movement to multicore by IBM in the Power 4, AMD in Opteron (see Keltcher et al. [2003]), and most recently by Intel (see Douglas [2005]).

> 从 2000 年到 2005 年的时期由超级处理器中的三个趋势主导：通过更深入的管道登录实现的较高时钟率(例如，在奔腾 4 中；参见 Hinton 等人[2001])，《 MultIthRead-Rread-引入》由 IBM 在 Power 4 中和 Intel 在 Pentium 4 Extreme 中，以及 IBM 在 Power 4 中的多项运动的开始，Opteron 在 Opteron 中的 AMD(参见 Keltcher 等人[2003])，以及最近的 Intel。(见道格拉斯[2005])。

### Multithreading and Simultaneous Multithreading

> ###多线程和同时多线程

The concept of multithreading dates back to one of the earliest transistorized com- puters, the TX-2. TX-2 is also famous for being the computer on which Ivan Suth- erland created Sketchpad, the first computer graphics system. TX-2 was built at MIT’s Lincoln Laboratory and became operational in 1959. It used multiple threads to support fast context switching to handle I/O functions. Clark [1957] described the basic architecture, and Forgie [1957] described the I/O architecture. Multithreading was also used in the CDC 6600, where a fine-grained multithread- ing scheme with interleaved scheduling among threads was used as the architecture of the I/O processors. The HEP processor, a pipelined multiprocessor designed by Denelcor and shipped in 1982, used fine-grained multithreading to hide the pipe- line latency as well as to hide the latency to a large memory shared among all the processors. Because the HEP had no cache, this hiding of memory latency was critical. Burton Smith, one of the primary architects, described the HEP architec- ture in a 1978 paper, and Jordan [1983] published a performance evaluation. The TERA processor extends the multithreading ideas and is described by Alverson et al. in a 1992 paper. The Niagara multithreading approach is similar to those of the HEP and TERA systems, although Niagara employs caches reducing the need for thread-based latency hiding.

> 多线程的概念可以追溯到最早的晶体管合并器之一 TX-2。TX-2 还以 Ivan Sutherland 创建了第一个计算机图形系统 Sketchpad 的计算机而闻名。TX-2 建于 MIT 的 Lincoln 实验室，并于 1959 年开始运行。它使用多个线程来支持快速上下文切换以处理 I/O 功能。Clark [1957]描述了基本体系结构，而 Loomie [1957]描述了 I/O 架构。CDC 6600 也使用了多线程，在该方案中，线程中的细粒度多线程方案在线程之间进行了交错调度，用作 I/O 处理器的体系结构。HEP 处理器是由 Denelcor 设计并于 1982 年发货的管道多处理器，使用细粒度的多线程隐藏管线潜伏期，并将延迟隐藏到所有处理器中共享的大型内存中。由于 HEP 没有缓存，因此内存延迟的隐藏至关重要。主要工程师之一伯顿·史密斯(Burton Smith)在 1978 年的论文中描述了 HEP 建筑，Jordan [1983]发表了一项绩效评估。TERA 处理器扩展了多线程思想，并由 Alverson 等人描述。在 1992 年的论文中。尼亚加拉多线程方法类似于 HEP 和 TERA 系统的方法，尽管尼亚加拉采用了缓存，从而减少了基于线的潜伏期隐藏的需求。

In the late 1980s and early 1990s, researchers explored the concept of coarse- grained multithreading (also called _block multithreading_) as a way to tolerate latency, especially in multiprocessor environments. The SPARCLE processor in the Alewife system used such a scheme, switching threads whenever a highlatency exceptional event, such as a long cache miss, occurred. Agarwal et al. described SPARCLE in a 1993 paper. The IBM Pulsar processor uses similar ideas.

> 在 1980 年代末和 1990 年代初，研究人员探索了粗粒的多线程(也称为_Block MultineReading_)的概念，是一种耐受延迟的方式，尤其是在多处理器环境中。Alewife 系统中的 Sparcle 处理器使用了这样的方案，每当发生较高的杰出事件(例如长缓存失误)时，切换线程。Agarwal 等。在 1993 年的论文中描述了 Sparcle。IBM Pulsar 处理器使用类似的想法。

By the early 1990s, several research groups had arrived at two key insights. First, they realized that fine-grained multithreading was needed to get the max- imum performance benefit, since in a coarse-grained approach, the overhead of thread switching and thread start-up (e.g., filling the pipeline from the new thread) negated much of the performance advantage (see Laudon, Gupta, and Horowitz [1994]). Second, several groups realized that to effectively use large numbers of functional units would require both ILP and thread-level parallelism (TLP). These insights led to several architectures that used combinations of multi- threading and multiple issue. Wolfe and Shen [1991] described an architecture called XIMD that statically interleaves threads scheduled for a VLIW processor. Hirata et al. [1992] described a proposed processor for media use that combines a static superscalar pipeline with support for multithreading; they reported speed- ups from combining both forms of parallelism. Keckler and Dally [1992] com- bined static scheduling of ILP and dynamic scheduling of threads for a processor with multiple functional units. The question of how to balance the allocation of functional units between ILP and TLP and how to schedule the two forms of par- allelism remained open.

> 到 1990 年代初，几个研究小组已经获得了两个关键见解。首先，他们意识到需要细粒度的多线程以获得最大的性能优势，因为在粗粒的方法中，线程开关和线程启动的开销(例如，从新线程中填充管道)被否定了性能优势的大部分(请参阅 Laudon，Gupta 和 Horowitz [1994])。其次，几个小组意识到，有效使用大量功能单元将需要 ILP 和线程级并行性(TLP)。这些见解导致了几种使用多线程和多个问题组合的体系结构。Wolfe and Shen [1991]描述了一个名为 XIMD 的架构，该体系结构是静态交织的线程，该线程计划为 VLIW 处理器。Hirata 等。[1992]描述了一种提议的用于介质使用的处理器，该处理器将静态超量表管道与多线程的支持相结合。他们报告了结合两种并行性的速度。Keckler and Dally [1992]汇总了具有多个功能单元的处理器的 ILP 的静态调度和线程的动态调度。如何平衡 ILP 和 TLP 之间功能单元的分配以及如何安排两种形式的阶段等级主义的问题仍然是开放的。

When it became clear in the mid-1990s that dynamically scheduled supersca- lars would be delivered shortly, several research groups proposed using the dynamic scheduling capability to mix instructions from several threads on the fly. Yamamoto et al. [1994] appear to have published the first such proposal, though the simulation results for their multithreaded superscalar architecture use simplistic assumptions. This work was quickly followed by Tullsen, Eggers, and Levy [1995], who provided the first realistic simulation assessment and coined the term _simultaneous multithreading._ Subsequent work by the same group together with industrial coauthors addressed many of the open questions about SMT. For example, Tullsen et al. [1996] addressed questions about the challenges of scheduling ILP versus TLP. Lo et al. [1997] provided an extensive discussion of the SMT concept and an evaluation of its performance potential, and Lo et. al. [1998] evaluated database performance on an SMT processor. Tuck and Tullsen [2003] reviewed the performance of SMT on the Pentium 4.

> 当在 1990 年代中期很明显，即将动态安排的 supersca-lars 将很快交付时，几个研究小组提出了使用动态调度能力来混合几个线程的动态调度能力。Yamamoto 等。[1994]似乎已经发布了第一个这样的建议，尽管其多线程超量表体系结构的仿真结果使用了简单的假设。这项工作很快是 Tullsen，Eggers 和 Levy [1995]，他们提供了第一个现实的模拟评估，并创造了_Simultanes MultineReading 一词。例如，Tullsen 等人。[1996]解决了有关调度 ILP 与 TLP 的挑战的问题。Lo 等。[1997]对 SMT 概念及其性能潜力的评估进行了广泛的讨论，并提供了 lo 等。al。[1998]评估了 SMT 处理器上的数据库性能。Tuck and Tullsen [2003]回顾了 SMT 在 Pentium 4 上的性能。

The IBM Power4 introduced multithreading (see Tendler et al. [2002]), while the Power5 used simultaneous multithreading. Mathis et al. [2005] explored the performance of SMT in the Power5, while Sinharoy et al. [2005] described the system architecture.

> IBM Power4 引入了多线程(参见 Tendler 等[2002])，而 Power5 使用同时多线程。Mathis 等。[2005]探索了 Power5 中 SMT 的性能，而 Sinharoy 等。[2005]描述了系统体系结构。
