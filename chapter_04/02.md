## Vector Architecture

> ##向量体系结构

The most efficient way to execute a vectorizable application is a vector processor.

> 执行矢量化应用程序的最有效方法是矢量处理器。

Jim Smith,

> 吉姆·史密斯，

_International Symposium on Computer Architecture_ (1994)

> _ International On Computer Archittection _(1994)

Vector architectures grab sets of data elements scattered about memory, place them into large sequential register files, operate on data in those register files, and then disperse the results back into memory. A single instruction works on vectors of data, which results in dozens of register-register operations on independent data elements.

> 向量体系结构获取散布在内存的数据元素的集合，将它们放入大型顺序寄存器文件中，在这些寄存器文件中操作数据，然后将结果分配回存储器。单个指令对数据向量作出了起作用，这导致数十个寄存器注册操作对独立的数据元素进行操作。

These large register files act as compiler-controlled buffers, both to hide memory latency and to leverage memory bandwidth. Because vector loads and stores are deeply pipelined, the program pays the long memory latency only once per vector load or store versus once per element, thus amortizing the latency over, say, 32 elements. Indeed, vector programs strive to keep the memory busy.

> 这些大寄存器文件充当编译器控制的缓冲区，无论是隐藏内存延迟还是利用内存带宽。由于向量负载和存储是深层管道的，因此该程序仅支付每个矢量负载或存储量与每个元素一次的长期内存延迟一次，从而将延迟摊销为 32 个元素。确实，向量程序努力使内存忙碌。

The power wall leads architects to value architectures that can deliver good performance without the energy and design complexity costs of highly out-oforder superscalar processors. Vector instructions are a natural match to this trend because architects can use them to increase performance of simple in-order scalar processors without greatly raising energy demands and design complexity. In practice, developers can express many of the programs that ran well on complex out-oforder designs more efficiently as data-level parallelism in the form of vector instructions, as [Kozyrakis and Patterson (2002)](#_bookmark971) showed.

> 电源墙将工程师带到价值架构，这些体系结构可以在没有高度置式超量表处理器的能源和设计复杂性成本的情况下提供良好的性能。矢量说明是与这种趋势的自然匹配，因为工程师可以使用它们来提高简单的内在标量处理器的性能，而不会大大提高能源需求和设计复杂性。实际上，如[Kozyrakis and Patterson(2002)](#\_ bookmark971)所示，开发人员可以表达许多在复杂的户外设计上运行良好的程序。

### RV64V Extension

> ### RV64V 扩展

We begin with a vector processor consisting of the primary components that [Figure 4.1](#_bookmark170) shows. It is loosely based on the 40-year-old Cray-1, which was one of the first supercomputers. At the time of the writing of this edition, the RISCV vector instruction set extension RVV was still under development. (The vector extension by itself is called RVV, so RV64V refers to the RISC-V base instructions plus the vector extension.) We show a subset of RV64V, trying to capture its essence in a few pages.

> 我们从一个矢量处理器开始，该矢量处理器由[图 4.1](#\_ bookmark170)显示的主要组件组成。它是基于 40 年历史的 Cray-1，这是最早的超级计算机之一。在此版本撰写本文时，RISCV 矢量指令集扩展 RVV 仍在开发中。(向量扩展本身称为 RVV，因此 RV64V 指的是 RISC-V 基本指令以及向量扩展。)我们显示了 RV64V 的子集，试图在几页中捕获其本质。

![](./media/image221.png)

> ！[](./ Media/image221.png)

> Figure 4.1 The basic structure of a vector architecture, RV64V, which includes a RISC-V scalar architecture. There are also 32 vector registers, and all the functional units are vector functional units. The vector and scalar registers have a significant number of read and write ports to allow multiple simultaneous vector operations. A set of crossbar switches _(thick gray lines)_ connects these ports to the inputs and outputs of the vector functional units.

>> 图 4.1 矢量体系结构 RV64V 的基本结构，其中包括 RISC-V 标量体系结构。还有 32 个向量寄存器，所有功能单元均为矢量功能单元。向量和标量寄存器具有大量的读取端口，以允许多个同时进行矢量操作。一组横梁开关*(厚灰线)*将这些端口连接到矢量功能单元的输入和输出。
>>

The primary components of the instruction set architecture of RV64V are the following:

> RV64V 的指令集体系结构的主要组件如下：

_Vector registers_—Each vector register holds a single vector, and RV64V has 32 of them, each 64 bits wide. The vector register file needs to provide enough ports to feed all the vector functional units. These ports will allow a high degree of overlap among vector operations to different vector registers. The read and write ports, which total at least 16 read ports and 8 write ports, are connected to the functional unit inputs or outputs by a pair of crossbar switches. One way to increase the register file bandwidth is to compose it from multiple banks, which work well with relatively long vectors.

> _vector 寄存器_- east 矢量寄存器保存一个向量，RV64V 具有 32 个矢量，每个矢量均为 64 位宽。矢量寄存器文件需要提供足够的端口来馈送所有矢量功能单元。这些端口将允许向量操作之间的高度重叠与不同的向量寄存器。读写端口，总共至少 16 个读取端口和 8 个写入端口，通过一对横梁开关连接到功能单元输入或输出。增加寄存器文件带宽的一种方法是从多个银行组成，这些银行与相对较长的向量配合使用。

_Vector functional units_—Each unit is fully pipelined in our implementation, and it can start a new operation on every clock cycle. A control unit is needed to detect hazards, both structural hazards for functional units and data hazards on register accesses. [Figure 4.1](#_bookmark170) shows that we assume an implementation of RV64V has five functional units. For simplicity, we focus on the floating-point functional units in this section.

> _vector 函数单位_- EAST 在我们的实施中完全管道，并且可以在每个时钟周期开始一个新操作。需要一个控制单元来检测危害，即功能单元的结构性危害和登记处访问中的数据危害。[图 4.1](#\_ bookmark170)表明，我们假设 RV64V 的实现具有五个功能单元。为简单起见，我们专注于本节中的浮点功能单元。

_Vector load/store unit_—The vector memory unit loads or stores a vector to or from memory. The vector loads and stores are fully pipelined in our hypothetical RV64V implementation so that words can be moved between the vector registers and memory with a bandwidth of one word per clock cycle, after an initial latency. This unit would also normally handle scalar loads and stores.

> _vector LOAD/存储单位_-矢量内存单元加载或存储向量到或从内存中存储。向量负载和存储在我们的假设 RV64V 实现中完全管道，因此在初始延迟后，可以在每个时钟周期中以一个单词的带宽在向量寄存器和内存之间移动单词。该单元通常还将处理标量负载和存储。

_A set of scalar registers_—Scalar registers can likewise provide data as input to the vector functional units, as well as compute addresses to pass to the vector load/store unit. These are the normal 31 general-purpose registers and 32 floating-point registers of RV64G. One input of the vector functional units latches scalar values as they are read out of the scalar register file.

> _a 标量寄存器集_- Scalar 寄存器同样可以提供数据作为向量功能单元的输入，以及计算地址以传递到向量负载/存储单元。这些是 RV64G 的正常 31 通用登记册和 32 个浮点登记册。矢量功能单元的一个输入将标量值从标量寄存器文件中读取时锁定标量值。

[Figure 4.2](#_bookmark171) lists the RV64V vector instructions we use in this section. The description in [Figure 4.2](#_bookmark171) assumes that the input operands are all vector registers, but there are also versions of these instructions where an operand can be a scalar register (xi or fi). RV64V uses the suffix .vv when both are vectors, .vs when the second operand is a scalar, and .sv when the first is a scalar register. Thus these three are all valid RV64V instructions: vsub.vv, vsub.vs, and vsub.sv. (Add and other commutative operations have only the first two versions, as vadd.sv and vadd.sv would be redundant.) Because the operands determine the version of the instruction, we usually let the assembler supply the appropriate suffix. The vector functional unit gets a copy of the scalar value at instruction issue time.

> [图 4.2](#_ bookmark171)列出了我们在本节中使用的 RV64V 向量指令。[图 4.2](#_ bookmark171)中的描述假设输入操作数都是向量寄存器，但是这些说明也有一些版本，其中操作数可以是标量寄存器(XI 或 FI)。当两个操作数为标量时，当两个都是向量时，RV64V 使用后缀.vv，当第一个是标量寄存器时的.sv。因此，这三个都是有效的 RV64V 指令：vsub.vv，vsub.vs 和 vsub.sv.(添加和其他交换操作只有前两个版本，因为 vadd.sv 和 vadd.sv 将是多余的。)由于操作数确定了指令的版本，因此我们通常让汇编器提供适当的后缀。向量功能单元在指令问题时获得标量值的副本。

Although the traditional vector architectures didn’t support narrow data types efficiently, vectors naturally accommodate varying data sizes ([Kozyrakis and](#_bookmark971) [Patterson, 2002](#_bookmark971)). Thus, if a vector register has 32 64-bit elements, then 128 16bit elements, and even 256 8-bit elements are equally valid views. Such hardware multiplicity is why a vector architecture can be useful for multimedia applications as well as for scientific applications.

> 尽管传统矢量体系结构并不能有效地支持狭窄的数据类型，但向量自然可容纳各种数据尺寸([[Kozyrakis and](#_ bookmark971)[Patterson，2002](#_ bookmark971))。因此，如果向量寄存器具有 32 个 64 位元素，则 128 个 16 位元素，甚至 256 个 8 位元素同样有效。这种硬件多重性是为什么向量体系结构可用于多媒体应用程序以及科学应用程序。

Note that the RV64V instructions in [Figure 4.2](#_bookmark171) omit the data type and size! An innovation of RV64V is to associate a data type and data size _with each vector register_, rather than the normal approach of the instruction supplying that information. Thus, before executing the vector instructions, a program configures the vector registers being used to specify their data type and widths. [Figure 4.3](#_bookmark172) lists the options for RV64V.

> 请注意，[图 4.2](#_ bookmark171)中的 RV64V 指令省略了数据类型和大小！RV64V 的创新是将数据类型和数据大小关联，而每个向量寄存器_，而不是提供该信息的指令的正常方法。因此，在执行向量指令之前，程序将配置用于指定其数据类型和宽度的向量寄存器。[图 4.3](#\_ bookmark172)列出了 RV64V 的选项。

Figure 4.2 The RV64V vector instructions. All use the R instruction format. Each vector operation with two operands is shown with both operands being vector (.vv), but there are also versions where the second operand is a scalar register (.vs) and, when it makes a difference, where the first operand is a scalar register and the second is a vector register (.sv). The type and width of the operands are determined by configuring each vector register rather than being supplied by the instruction. In addition to the vector registers and predicate registers, there are two vector control and status registers (CSRs), vl and vctype, discussed below. The strided and indexed data transfers are also explained later. Once completed, RV64 will surely have more instructions, but the ones in this figure will be included.

> 图 4.2 RV64V 向量指令。所有人都使用 R 指令格式。显示每个具有两个操作数的向量操作，两个操作数为矢量(.vv)，但是在某些版本中，第二操作数为标量寄存器(.vs)，当它有所不同时，第一个操作数为标量注册，第二个是向量寄存器(.sv)。操作数的类型和宽度是通过配置每个向量寄存器而不是指令提供的。除了向量寄存器和谓词寄存器外，下面还有两个向量控制和状态寄存器(CSR)，VL 和 VCTYPE。稍后还解释了艰难的索引数据传输。完成后，RV64 肯定会有更多的说明，但是该图中的指示将包括在内。

Figure 4.3 Data sizes supported for RV64V assuming it also has the singleand double-precision floating-point extensions RVS and RVD. Adding RVV to such a RISC-V design means the scalar unit must also add RVH, which is a scalar instruction extension to support half-precision (16-bit) IEEE 754 floating point. Because RV32V would not have doubleword scalar operations, it could drop 64-bit integers from the vector unit. If a RISC-V implementation didn’t include RVS or RVD, it could omit the vector floating-point instructions.

> 图 4.3 为 RV64V 支持的数据大小，假设它还具有单重点浮点扩展名 RVS 和 RVD。将 RVV 添加到此类 RISC-V 设计中意味着标量单元还必须添加 RVH，这是标量指令扩展程序，以支持半精确(16 位)IEEEE 754 浮点。由于 RV32V 不会具有双向标量操作，因此它可能会从矢量单元中删除 64 位整数。如果 RISC-V 实施不包括 RVS 或 RVD，则可能会省略矢量浮点指令。

One reason for _dynamic register typing_ is that many instructions are required for a conventional vector architecture that supports such variety. Given the combinations of data types and sizes in [Figure 4.3](#_bookmark172), if not for dynamic register typing, [Figure 4.2](#_bookmark171) would be several pages long!

> _Dynamic 寄存器键入的原因之一是，支持这种多样性的传统矢量体系结构需要许多说明。给定数据类型和大小的组合[图 4.3](#_ bookmark172)，如果不是用于动态寄存器键入的话，[图 4.2](#\_ bookmark171)将是几页长！

Dynamic typing also lets programs disable unused vector registers. As a consequence, enabled vector registers are allocated all the vector memory as long vectors. For example, assume we have 1024 bytes of vector memory, if 4 vector registers are enabled and they are type 64–bit floats, the processor would give each vector register 256 bytes or 256/8 32 elements. This valiue is called the maximum vector length (mvl), which is set by the processor and cannot be changed by sofware.

> 动态键入还可以使程序禁用未使用的向量寄存器。结果，将启用的向量寄存器分配为所有向量内存作为长向量。例如，假设我们有 1024 个字节向量内存，如果启用了 4 个向量寄存器并且它们是 64 位式浮点，则处理器将给出每个向量寄存器 256 字节或 256/8 32 个元素。该阀称为最大矢量长度(MVL)，该阀由处理器设置，无法通过 SOFWare 更改。

One complaint about vector architectures is that their larger state means slower context switch time. Our implementation of RV64V increases state a factor of 3: from 2 32 8 512 bytes to 2 32 1024 1536 bytes. A pleasant side effect of dynamic register typing is that the program can configure vector registers as _disabled_ when they are not being used, so there is no need to save and restore them on a context switch.

> 关于向量体系结构的一个抱怨是，它们的较大状态意味着上下文切换时间较慢。我们对 RV64V 的实施增加了状态 3：从 2 32 8 512 字节到 2 32 1024 1536 字节。动态寄存器键入的令人愉悦的副作用是，该程序在不使用时可以将 vector 寄存器配置为 *disabled*，因此无需在上下文开关上保存和还原它们。

A third benefit of dynamic register typing is that conversions between different size operands can be implicit depending on the configuration of the registers rather than as additional explicit conversion instructions. We’ll see an example of this benefit in the next section.

> 动态寄存器键入的第三个好处是，不同大小操作数之间的转换可能是隐含的，具体取决于寄存器的配置，而不是作为附加的显式转换说明。我们将在下一节中看到此好处的示例。

The names vld and vst denote vector load and vector store, and they load or store an entire vectors of data. One operand is the vector register to be loaded or stored; the other operand, which is a RV64G general-purpose register, is the starting address of the vector in memory. Vector needs more registers beyond the vector registers themselves. The vector-length register vl is used when the natural vector length is not equal to mvl, the vector-type register vctype records register types, and the predicate registers p*<sub>i</sub>* are used when loops involve IF statements. We’ll see them in action in the following example.

> 名称 VLD 和 VST 表示向量负载和向量存储，它们加载或存储了整个数据矢量。一个操作数是要加载或存储的向量寄存器；另一个操作数是 RV64G 通用寄存器，是存储器中向量的起始地址。向量需要更多的寄存器，超出了向量寄存器。当天然向量长度不等于 MVL 时，使用向量长度寄存器 VL，矢量型寄存器 vCtype 记录寄存器类型，而谓词寄存器 p* <sub> i </sub>*当循环涉及时，则使用 p* <sub> i </sub>*语句。在下面的示例中，我们将看到它们的行动。

With a vector instruction, the system can perform the operations on the vector data elements in many ways, including operating on many elements simultaneously. This flexibility lets vector designs use slow but wide execution units to achieve high performance at low power. Furthermore, the independence of elements within a vector instruction set allows scaling of functional units without performing additional costly dependency checks, as superscalar processors require.

> 通过向量指令，系统可以以多种方式对矢量数据元素进行操作，包括同时在许多元素上操作。这种灵活性使矢量设计使用缓慢但宽的执行单元以低功率以高性能。此外，矢量指令集中元素的独立性允许缩放功能单元，而无需执行额外的昂贵依赖检查，正如超级处理器所要求的那样。

### How Vector Processors Work: An Example

> ###向量处理器的工作方式：一个示例

We can best understand a vector processor by looking at a vector loop for RV64V. Let’s take a typical vector problem, which we use throughout this section:

> 我们可以通过查看 RV64V 的向量循环来最好地理解矢量处理器。让我们处理一个典型的向量问题，我们在本节中使用该问题：

the _SAXPY_ or _DAXPY_ loop that forms the inner loop of the Linpack benchmark ([Dongarra et al., 2003](#_bookmark944)). (SAXPY stands for single-precision <u>a</u> <u>X</u> plus <u>Y</u>, and DAXPY for <u>d</u>ouble precision <u>a</u> <u>X p</u>lus <u>Y</u>.) Linpack is a collection of linear algebra routines, and the Linpack benchmark consists of routines for performing Gaussian elimination.

> *saxpy* 或 *daxpy* 循环构成 Linpack 基准的内部环([Dongarra 等，2003](#\_ bookmark944))。(saxpy 代表单精制<u> a </u> <u> x </u> plus <u> y </u>，而 daxpy for <u> d </u> d </u> ouble precision <u> a</u> <u> x p </u> lus <u> y </u>。)linpack 是线性代数例程的集合，linpack 基准包括用于执行高斯消除的例程。

For now, let us assume that the number of elements, or _length_, of a vector register (32) matches the length of the vector operation we are interested in. (This restriction will be lifted shortly.)

> 现在，让我们假设向量寄存器(32)的元素数量或 *length* 的数量与我们感兴趣的向量操作的长度匹配。(此限制将很快提高。)

Example Show the code for RV64G and RV64V for the DAXPY loop. For this example, assume that X and Y have 32 elements and the starting addresses of X and Y are in x5 and x6, respectively. (A subsequent example covers when they do not have 32 elements.)

> 示例显示 Daxpy 循环的 RV64G 和 RV64V 的代码。在此示例中，假设 X 和 Y 具有 32 个元素，X 和 Y 的起始地址分别在 X5 和 X6 中。(随后的示例没有 32 个元素。)

Note that the assembler determines which version of the vector operations to generate. Because the multiply has a scalar operand, it generates vmul.vs, whereas the add doesn’t, so it generates vadd.vv.

> 请注意，汇编器确定要生成的向量操作的哪个版本。由于倍数具有标量操作数，因此它生成 vmul.vs，而添加则没有，因此生成 vadd.vv.

The initial instruction configures the first four vector registers to hold 64-bit floating-point data. The last instruction disables all vector registers. If a context switch happened after the last instruction, there is no additional state to save. The most dramatic difference between the preceding scalar and vector code is that the vector processor greatly reduces the dynamic instruction bandwidth, executing only 8 instructions versus 258 for RV64G. This reduction occurs because the vector operations work on 32 elements and the overhead instructions that constitute nearly half the loop on RV64G are not present in the RV64V code. When the compiler produces vector instructions for such a sequence, and the resulting code spends much of its time running in vector mode, the code is said to be _vectorized_ or _vectorizable_. Loops can be vectorized when they do not have dependences between iterations of a loop, which are called _loop-carried dependences_ (see [Section 4.5](#detecting-and-enhancing-loop-level-parallelism)). Another important difference between RV64G and RV64V is the frequency of pipeline interlocks for a simple implementation of RV64G. In the straightforward RV64G code, every fadd.d must wait for a fmul.d, and every fsd must wait for the fadd.d. On the vector processor, each vector instruction will stall only for the first element in each vector, and then subsequent elements will flow smoothly down the pipeline. Thus pipeline stalls are required only once per vector _instruction_, rather than once per vector _element_. Vector architects call forwarding of elementdependent operations _chaining_, in that the dependent operations are “chained” together. In this example, the pipeline stall frequency on RV64G will be about 32 higher than it is on RV64V. Software pipelining, loop unrolling (Appendix H), or out-of-order execution can reduce the pipeline stalls on RV64G; however, the large difference in instruction bandwidth cannot be reduced substantially.

> 初始指令配置了前四个向量寄存器，以持有 64 位浮点数据。最后的指令禁用所有向量寄存器。如果上次指令之后发生了上下文开关，则没有其他保存状态。前面的标量和向量代码之间的最大差异是，矢量处理器大大降低了动态指令带宽，仅执行 8 个指令，而 RV64G 的 258。这种减少之所以发生，是因为向量操作在 32 个元素上起作用，而 RV64V 代码中不存在构成 RV64G 上循环几乎一半的架空指令。当编译器为该序列产生矢量指令，而所得代码将其大部分时间用于向量模式时，则据说该代码为* vectorized *或* vectorizable*。当循环之间不依赖循环时，循环可以被矢量化，该循环被称为* loop inderied 依赖*(请参见[4.5](＃检测和启用 loop-level-level-paralallelism))。RV64G 和 RV64V 之间的另一个重要区别是简单实现 RV64G 的管道互锁的频率。在直接的 RV64G 代码中，每个 FADD.D 都必须等待 FMUL.D，并且每个 FSD 都必须等待 FADD.D。在矢量处理器上，每个向量指令仅对每个向量的第一个元素停滞不前，然后后续元素将顺利流下管道。因此，每个向量 *instruction* 只需要一次管道摊位，而不是每个向量 *Element*。向量架构师呼叫元素依赖性操作的转发 *chaining*，因为相关操作被“链接”在一起。在此示例中，RV64G 上的管道失速频率将比 RV64V 上的管道频率高约 32。软件管道管道，循环展开(附录 H)或端外执行可以减少 RV64G 上的管道摊位；但是，教学带宽的巨大差异不能大大减少。

Let’s show off the dynamic register typing before discussing performance of the code.

> 让我们在讨论代码性能之前炫耀动态寄存器键入。

Example A common use of multiply-accumulate operations is to multiply using narrow data and to accumulate at a wider size to increase the accuracy of a sum of products. Show how the preceding code would change if X and a were single-precision instead of a double-precision floating point. Next, show the changes to this code if we switch X, Y, and a from floating-point type to integers.

> 示例乘以造成的操作的常见用途是使用狭窄的数据繁殖，并以更大的尺寸积累以提高产品总和的准确性。说明如果 X 和 A 为单精度而不是双精度浮点，则前面的代码将如何更改。接下来，如果我们将 X，Y 和 A 从浮点类型切换到整数，则显示此代码的更改。

_Answer_ The changes are underlined in the following code. Amazingly, the same code works with two small changes: the configuration instruction includes one single-precision vector, and the scalar load is now single-precision:

> *answer* 更改在以下代码中下划线。令人惊讶的是，相同的代码可与两个小更改一起使用：配置指令包括一个单精度向量，并且标量负载现在为单精度：

Note that RV64V hardware will implicitly perform a conversion from the narrower single-precision to the wider double-precision in this setup.

> 请注意，RV64V 硬件将隐式地从较窄的单精度执行此设置中的更广泛的双重精确。

The switch to integers is almost as easy, but we must now use an integer load instruction and integer register to hold the scalar value:

> 切换到整数几乎很容易，但是我们现在必须使用整数负载指令和整数寄存器来保持标量值：

### Vector Execution Time

> ###矢量执行时间

The execution time of a sequence of vector operations primarily depends on three factors: (1) the length of the operand vectors, (2) structural hazards among the operations, and (3) the data dependences. Given the vector length and the _initiation rate_, which is the rate at which a vector unit consumes new operands and produces new results, we can compute the time for a single vector instruction.

> 一系列向量操作的执行时间主要取决于三个因素：(1)操作数矢量的长度，(2)操作之间的结构危害，以及(3)数据依赖性。考虑到矢量长度和 *initiation 速率*，这是向量单元消耗新操作数并产生新结果的速率，我们可以计算单个向量指令的时间。

All modern vector computers have vector functional units with multiple parallel pipelines (or _lanes_) that can produce two or more results per clock cycle, but they may also have some functional units that are not fully pipelined. For simplicity, our RV64V implementation has one lane with an initiation rate of one element per clock cycle for individual operations. Thus the execution time in clock cycles for a single vector instruction is approximately the vector length.

> 所有现代矢量计算机都有具有多个平行管道(或 *lanes*)的矢量功能单元，它们每个时钟周期都可以产生两个或更多的结果，但是它们也可能具有某些功能单元，这些单元尚未完全管道。为简单起见，我们的 RV64V 实现具有一个车道，每个操作的启动率为一个元素。因此，单个向量指令的时钟循环中的执行时间大约是向量长度。

To simplify the discussion of vector execution and vector performance, we use the notion of a _convoy_, which is the set of vector instructions that could potentially execute together. The instructions in a convoy _must not_ contain any structural hazards; if such hazards were present, the instructions would need to be serialized and initiated in different convoys. Thus the vld and the following vmul in the preceding example can be in the same convoy. As we will soon see, you can estimate performance of a section of code by counting the number of convoys. To keep this analysis simple, we assume that a convoy of instructions must complete execution before any other instructions (scalar or vector) can begin execution.

> 为了简化对向量执行和向量性能的讨论，我们使用 *convoy* 的概念，这是可能共同执行的矢量指令集。车队中的说明不得不包含任何结构性危害；如果存在这种危害，则需要在不同的车队中序列化并启动这些指示。因此，前一个示例中的 VLD 和以下 VMUL 可以在同一车队中。正如我们将很快看到的那样，您可以通过计算车队数量来估计一部分代码的性能。为了简化此分析，我们假设指令车队必须在任何其他指令(标量或向量)开始执行之前完成执行。

It might seem that in addition to vector instruction sequences with structural hazards, sequences with read-after-write dependency hazards should also be in separate convoys. However, chaining allows them to be in the same convoy since it allows a vector operation to start as soon as the individual elements of its vector source operand become available: the results from the first functional unit in the chain are “forwarded” to the second functional unit. In practice, we often implement chaining by allowing the processor to read and write a particular vector register at the same time, albeit to different elements. Early implementations of chaining worked just like forwarding in scalar pipelining, but this restricted the timing of the source and destination instructions in the chain. Recent implementations use _flexible chaining_, which allows a vector instruction to chain to essentially any other active vector instruction, assuming that we don’t generate a structural hazard. All modern vector architectures support flexible chaining, which we assume throughout this chapter.

> 似乎除了具有结构性危害的矢量指导序列外，具有读取后依赖性危害的序列也应在单独的车队中。但是，链接可以使它们处于同一护卫舰中，因为它允许向量操作在其向量源操作数的各个元素中开始启动：链中第一个功能单元的结果“转发”到第二个功能单元。功能单元。实际上，我们经常通过允许处理器同时读取和编写特定矢量寄存器来实现链接，尽管它是不同的元素。链接的早期实现就像在标量管道中的转发一样起作用，但这限制了链中源和目的地指示的时机。最近的实现使用 *FLEXIBLE CHANED*，允许向量指令链条以实质上任何其他活动向量指令，假设我们没有产生结构性危害。所有现代矢量体系结构都支持灵活的链接，我们在本章中假设。

To turn convoys into execution time, we need a metric to estimate the length of a convoy. It is called a _chime_, which is simply the unit of time taken to execute one convoy. Thus a vector sequence that consists of _m_ convoys executes in _m_ chimes; for a vector length of _n_, for our simple RV64V implementation, this is approximately _m n_ clock cycles.

> 要将车队变成执行时间，我们需要一个指标来估计车队的长度。它称为 *chime*，这只是执行一支车队所花费的时间单位。因此，由 *m* 车队组成的向量序列在 *m* chimes 中执行；对于 *n* 的矢量长度，对于我们的简单 RV64V 实现，这大约是 *M N* 时钟循环。

The chime approximation ignores some processor-specific overheads, many of which are dependent on vector length. Therefore measuring time in chimes is a better approximation for long vectors than for short ones. We will use the chime measurement, rather than clock cycles per result, to indicate explicitly that we are ignoring certain overheads.

> 循环近似忽略了一些特定于处理器的开销，其中许多取决于向量长度。因此，与短向量相比，在钟形中测量时间是更好的近似值。我们将使用铃声测量，而不是每个结果时钟周期，以明确指出我们忽略了某些开销。

If we know the number of convoys in a vector sequence, we know the execution time in chimes. One source of overhead ignored in measuring chimes is any limitation on initiating multiple vector instructions in a single clock cycle. If only one vector instruction can be initiated in a clock cycle (the reality in most vector processors), the chime count will underestimate the actual execution time of a convoy. Because the length of vectors is typically much greater than the number of instructions in the convoy, we will simply assume that the convoy executes in one chime.

> 如果我们知道矢量序列中的车队数量，我们就会知道钟声中的执行时间。在测量铃声中忽略的高架源是在单个时钟周期中启动多个向量指令的任何限制。如果只能在时钟周期(大多数向量处理器中的现实)中启动一个向量指令，则循环计数将低估车队的实际执行时间。由于向量的长度通常比车队中的说明数量要大得多，因此我们简单地假设车队在一个钟声中执行。

Example Show how the following code sequence lays out in convoys, assuming a single copy of each vector functional unit:

> 示例显示以下代码序列如何在车队中列出，假设每个向量功能单元的单个副本：

How many chimes will this vector sequence take? How many cycles per FLOP (floating-point operation) are needed, ignoring vector instruction issue overhead?

> 这个矢量序列需要多少个铃？每个翻牌的周期(浮点操作)需要多少个循环，忽略了矢量指令问题开销？

_Answer_ The first convoy starts with the first vld instruction. The vmul is dependent on the first vld, but chaining allows it to be in the same convoy.

> *answer* 第一个车队以第一个 VLD 指令开始。VMUL 取决于第一个 VLD，但链接使其在同一车队中。

The second vld instruction must be in a separate convoy because there is a structural hazard on the load/store unit for the prior vld instruction. The vadd is dependent on the second vld, but it can again be in the same convoy via chaining. Finally, the vst has a structural hazard on the vld in the second convoy, so it must go in the third convoy. This analysis leads to the following layout of vector instructions into convoys:

> 第二个 VLD 指令必须在单独的车队中，因为负载/存储单元的先前 VLD 指令有一个结构性危害。VADD 取决于第二个 VLD，但它可以通过链接再次在同一车队中。最后，VST 在第二个车队中对 VLD 有结构性危害，因此必须进入第三艘车队。该分析导致了以下矢量说明到车队的布局：

1. vld vmul

> 1. VLD VMUL

2. vld vadd

> 2. VLD

3. vst

> 3. vst

The sequence requires three convoys. Because the sequence takes three chimes and there are two floating-point operations per result, the number of cycles per FLOP is 1.5 (ignoring any vector instruction issue overhead). Note that, although we allow the vld and vmul both to execute in the first convoy, most vector machines will take 2 clock cycles to initiate the instructions.

> 该序列需要三个车队。由于该序列需要三个钟声，并且每个结果有两个浮点操作，因此每次翻牌的循环数为 1.5(忽略任何向量指令问题开销)。请注意，尽管我们允许 VLD 和 VMUL 都在第一个车队中执行，但大多数向量机将需要 2 个时钟周期来启动说明。

This example shows that the chime approximation is reasonably accurate for long vectors. For example, for 32-element vectors, the time in chimes is 3, so the sequence would take about 32 3 or 96 clock cycles. The overhead of issuing convoys in two separate clock cycles would be small.

> 该示例表明，对于长向量，循环近似是合理准确的。例如，对于 32 个元素向量，钟中的时间为 3，因此序列将大约需要 32 3 或 96 个时钟周期。在两个单独的时钟周期中发行车队的开销很小。

Another source of overhead is far more significant than the issue limitation. The most important source of overhead ignored by the chime model is vector _start-up time_, which is the latency in clock cycles until the pipeline is full. The start-up time is principally determined by the pipelining latency of the vector functional unit. For RV64V, we will use the same pipeline depths as the Cray-1, although latencies in more modern processors have tended to increase, especially for vector loads. All functional units are fully pipelined. The pipeline depths are 6 clock cycles for floating-point add, 7 for floating-point multiply, 20 for floating-point divide, and 12 for vector load.

> 开销的另一个来源远比发行限制更为重要。铃声模型忽略的最重要的间接费用来源是向量 *st-up-up Time*，它是时钟周期的延迟，直到管道已满。启动时间主要取决于向量功能单元的管道延迟。对于 RV64V，我们将使用与 Cray-1 相同的管道深度，尽管更现代的处理器的潜伏期倾向于增加，尤其是对于向量负载。所有功能单元均已完全管道。管道深度为 6 个时钟循环，用于浮点添加，浮点倍数为 7，浮点数为 20，矢量负载为 12。

Given these vector basics, the next several sections will give optimizations that either improve the performance or increase the types of programs that can run well on vector architectures. In particular, they will answer these questions:

> 鉴于这些向量基础知识，接下来的几个部分将提供优化，以提高性能或增加可以在矢量体系结构上运行良好的程序的类型。特别是，他们将回答以下问题：

How can a vector processor execute a single vector faster than one element per clock cycle? Multiple elements per clock cycle improve performance.

> 向量处理器如何比每个时钟周期一个元素更快地执行单个向量？每个时钟周期的多个元素可改善性能。

How does a vector processor handle programs where the vector lengths are not the same as the maximum vector length (mvl)? Because most application vectors don’t match the architecture vector length, we need an efficient solution to this common case.

> 向量处理器如何处理向量长度与最大向量长度(MVL)不同的程序？由于大多数应用程序向量与体系结构向量长度不符，因此我们需要有效的解决方案。

What happens when there is an IF statement inside the code to be vectorized? More code can vectorize if we can efficiently handle conditional statements.

> 当代码中有矢量化的代码中有 IF 语句时会发生什么？如果我们可以有效处理有条件的语句，则更多代码可以向量化。

What does a vector processor need from the memory system? Without sufficient memory bandwidth, vector execution can be futile.

> 向量处理器需要从内存系统中进行什么？没有足够的内存带宽，矢量执行可能是徒劳的。

How does a vector processor handle multiple dimensional matrices? This popular data structure must vectorize for vector architectures to do well.

> 向量处理器如何处理多个维矩阵？这种流行的数据结构必须矢量化才能使矢量体系结构做得很好。

How does a vector processor handle sparse matrices? This popular data structure must vectorize also.

> 向量处理器如何处理稀疏矩阵？这种流行的数据结构也必须矢量化。

How do you program a vector computer? Architectural innovations that are a mismatch to programming languages and their compilers may not get widespread use. The rest of this section introduces each of these optimizations of the vector architecture, and Appendix G goes into greater depth.

> 您如何编程矢量计算机？与编程语言及其编译器不匹配的建筑创新可能不会广泛使用。本节的其余部分介绍了矢量体系结构的每个优化，附录 G 越来越深。

### Multiple Lanes: Beyond One Element per Clock Cycle

> ###多个车道：每个时钟周期超出一个元素

A critical advantage of a vector instruction set is that it allows software to pass a large amount of parallel work to hardware using only a single short instruction. One vector instruction can include scores of independent operations yet be encoded in the same number of bits as a conventional scalar instruction. The parallel semantics of a vector instruction allow an implementation to execute these elemental operations using a deeply pipelined functional unit, as in the RV64V implementation we’ve studied so far; an array of parallel functional units; or a combination of parallel and pipelined functional units. [Figure 4.4](#_bookmark173) illustrates how to improve vector performance by using parallel pipelines to execute a vector add instruction.

> 矢量指令集的一个关键优势是，它允许软件仅使用单个简短指令将大量并行工作传递给硬件。一项向量指令可以包括几个独立操作，但与常规标量指令相同数量的位数进行编码。向量指令的平行语义使实现可以使用深层管道的功能单元执行这些元素操作，就像我们迄今为止研究的 RV64V 实现一样；一系列平行功能单元；或平行和管道功能单元的组合。[图 4.4](#\_ bookmark173)说明了如何通过使用并行管道执行向量添加指令来改善向量性能。

The RV64V instruction set has the property that all vector arithmetic instructions only allow element _N_ of one vector register to take part in operations with element _N_ from other vector registers. This dramatically simplifies the design of a highly parallel vector unit, which can be structured as multiple parallel _lanes_. As with a traffic highway, we can increase the peak throughput of a vector unit by adding more lanes. [Figure 4.5](#_bookmark174) shows the structure of a four-lane vector unit. Thus going to four lanes from one lane reduces the number of clocks for a chime from 32 to 8. For multiple lanes to be advantageous, both the applications and the architecture must support long vectors; otherwise, they will execute so quickly that you’ll run out of instruction bandwidth, requiring ILP techniques (see [Chapter 3](#_bookmark93)) to supply enough vector instructions.

> RV64V 指令集具有所有向量算法指令仅允许一个向量寄存器的元素 *n* 的属性，可以从其他向量寄存器中与元素 *n* 一起参加操作。这极大地简化了高度并行矢量单元的设计，可以将其构造为多个并行 *lanes*。与交通高速公路一样，我们可以通过添加更多车道来增加向量单元的峰值吞吐量。[图 4.5](#_ bookmark174)显示了四车道矢量单元的结构。因此，从一条车道进入四个车道会将铃声的时钟数从 32 减少到 8。要使多个车道有利，应用程序和体系结构都必须支持长向量；否则，他们将执行得如此之快，以至于您将用完指令带宽，需要 ILP 技术(请参阅[第 3 章](#_ bookmark93))以提供足够的矢量说明。

Each lane contains one portion of the vector register file and one execution pipeline from each vector functional unit. Each vector functional unit executes vector instructions at the rate of one element group per cycle using multiple pipelines, one per lane. The first lane holds the first element (element 0) for all vector registers, and so the first element in any vector instruction will have its source and destination operands located in the first lane. This allocation allows the arithmetic pipeline local to the lane to complete the operation without communicating with other lanes. Avoiding interlane communication reduces the wiring cost and register file ports required to build a highly parallel execution unit and helps explain why vector computers can complete up to 64 operations per clock cycle (2 arithmetic units and 2 load/store units across 16 lanes).

> 每个车道都包含矢量寄存器文件的一部分和每个向量功能单元的一个执行管道。每个矢量功能单元使用多个管道以每个泳道为单周的一个元素组以一个元素组的速率执行矢量指令。第一条泳道保存所有向量寄存器的第一个元素(元素 0)，因此任何向量指令中的第一个元素都将其源和目标操作数位于第一个车道中。这种分配使算术管道本地到车道可以完成操作，而无需与其他车道通信。避免货车通信减少建立高度平行执行单元所需的接线成本和注册文件端口，并有助于解释为什么矢量计算机每个时钟周期最多可以完成 64 个操作(2 个算术单元和 2 个跨 16 条车道的负载/存储单元)。

Adding multiple lanes is a popular technique to improve vector performance as it requires little increase in control complexity and does not require changes to existing machine code. It also allows designers to trade off die area, clock rate, voltage, and energy without sacrificing peak performance. If the clock rate of a vector processor is halved, doubling the number of lanes will retain the same peak performance.

> 添加多个车道是一种流行的技术，可以提高向量性能，因为它几乎不需要增加控制复杂性，并且不需要更改现有的机器代码。它还允许设计师在不牺牲峰值性能的情况下进行倒数面积，时钟速率，电压和能量的交易。如果向量处理器的时钟速率减半，则将车道的数量增加一倍，将保持相同的峰值性能。

![](./media/image227.png) ![](./media/image228.png)

> ！[](./ Media/image227.png)！[](./ Media/Image228.png)

Figure 4.4 Using multiple functional units to improve the performance of a single vector add instruction, C 5 A+ B. The vector processor (A) on the left has a single add pipeline and can complete one addition per clock cycle. The vector processor (B) on the right has four add pipelines and can complete four additions per clock cycle. The elements within a single vector add instruction are interleaved across the four pipelines. The set of elements that move through the pipelines together is termed an _element group_. Reproduced with permission from Asanovic, K., 1998. Vector Microprocessors (Ph.D. thesis). Computer Science Division, University of California, Berkeley.

> 图 4.4 使用多个功能单元改善单个向量添加指令的性能，C 5 a+B。左侧的向量处理器(a)具有单个添加管道，并且每个时钟周期都可以完成一个添加。右侧的矢量处理器(B)具有四个添加管道，每个时钟周期可以完成四个添加。单个矢量添加指令中的元素在四个管道中交织在一起。通过管道一起移动的一组元素称为*元组*。经 Asanovic，K.，1998 年的许可重复。矢量微处理器(博士学位论文)。加利福尼亚大学伯克利分校计算机科学系。

### Vector-Length Registers: Handling Loops Not Equal to 32

> ###向量长度寄存器：处理循环不等于 32

A vector register processor has a natural vector length determined by the maximum vector length (mvl). This length, which was 32 in our example above, is unlikely to match the real vector length in a program. Moreover, in a real program, the length of a particular vector operation is often _unknown_ at compile time. In fact, a single piece of code may require different vector lengths. For example, consider this code:

> 矢量寄存器处理器的自然向量长度由最大矢量长度(MVL)确定。这个长度在上面的示例中为 32，不太可能与程序中的真实矢量长度匹配。此外，在一个真实程序中，特定矢量操作的长度通常是在编译时 *UNKNOWN*。实际上，单个代码可能需要不同的向量长度。例如，考虑此代码：

Figure 4.5 Structure of a vector unit containing four lanes. The vector register memory is divided across the lanes, with each lane holding every fourth element of each vector register. The figure shows three vector functional units: an FP add, an FP multiply, and a load-store unit. Each of the vector arithmetic units contains four execution pipelines, one per lane, which act in concert to complete a single vector instruction. Note how each section of the vector register file needs to provide only enough ports for pipelines local to its lane. This figure does not show the path to provide the scalar operand for vector-scalar instructions, but the scalar processor (or Control Processor) broadcasts a scalar value to all lanes.

> 图 4.5 包含四个车道的向量单元的结构。向量寄存器内存分为各个车道，每个巷道都有每个向量寄存器的每个第四个元素。该图显示了三个矢量功能单元：fp 添加，fp 乘数和一个负载店单元。每个矢量算术单元都包含四个执行管道，一个每条车道，共同起作用以完成单个向量指令。请注意，矢量寄存器文件的每个部分只需要为其车道本地的管道提供足够的端口。该图并未显示为向量 - 标准指令提供标量操作数的路径，但是标量处理器(或控制处理器)向所有车道广播标量值。

The size of all the vector operations depends on n, which may not even be known until run time. The value of n might also be a parameter to a procedure containing the preceding loop and therefore subject to change during execution.

> 所有向量操作的大小取决于 n，直到运行时间才可能知道。n 的值也可能是包含前面循环的过程的参数，因此在执行过程中可能会更改。

The solution to these problems is to add a _vector-length register_ (vl). The vl controls the length of any vector operation, including a vector load or store. The value in the vl, however, cannot be greater than the maximum vector length (mvl). This solves our problem as long as the real length is less than or equal to the maximum vector length (mvl). This parameter means the length of vector registers can grow in later computer generations without changing the instruction set. As we will see in the next section, multimedia SIMD extensions have no equivalent of mvl, so they expand the instruction set every time they increase their vector length.

> 这些问题的解决方案是添加 *vector-Length Register*(VL)。VL 控制任何向量操作的长度，包括向量负载或存储。但是，VL 中的值不能大于最大矢量长度(MVL)。只要实际长度小于或等于最大矢量长度(MVL)，这可以解决我们的问题。该参数意味着向量寄存器的长度可以在以后的计算机世代内增长，而无需更改指令集。正如我们将在下一部分中看到的那样，多媒体 SIMD 扩展名与 MVL 相当，因此每次增加矢量长度时，它们都会扩展指令集。

What if the value of n is not known at compile time and thus may be greater than the mvl? To tackle the second problem where the vector is longer than the maximum length, a technique called _strip mining_ is traditionally used. Strip mining is the generation of code such that each vector operation is done for a size less than or equal to the mvl. One loop handles any number of iterations that is a multiple of the mvl and another loop that handles any remaining iterations and must be less than the mvl. RISC-V has a better solution than a separate loop for strip mining. The instruction setvl writes the smaller of the mvl and the loop variable n into vl (and to another register). If the number of iterations of the loop is larger than n, then the fastest the loop can compute is mvl values at time, so setvl sets vl to mvl. If n is smaller than mvl, it should compute only on the last n elements in this final iteration of the loop, so setvl sets vl to n. setvl also writes another scalar register to help with later loop bookkeeping. Below is the RV64V code for vector DAXPY for any value of n.

> 如果在编译时不知道 n 的值，因此可能大于 MVL 怎么办？为了解决矢量长于最大长度的第二个问题，传统上使用了一种称为 *Strip Mining* 的技术。带挖掘是代码的生成，因此每个向量操作的大小小于或等于 MVL。一个循环处理任何数量的迭代，这些迭代是 MVL 的倍数，另一个循环处理任何剩余迭代，并且必须小于 MVL。RISC-V 比单独的循环挖掘具有更好的解决方案。指令 SETVL 将 MVL 的较小的较小和循环变量 n 写入 VL(以及另一个寄存器)。如果循环的迭代次数大于 n，则循环可以计算的最快为 MVL 值，因此 SETVL 将 VL 设置为 MVL。如果 N 小于 MVL，则应仅在循环的最后迭代中的最后 N 元素上计算，因此 SETVL 将 VL 设置为 n。SETVL 还编写另一个标量寄存器，以帮助以后的循环簿记。以下是任何值 n 值的 vector daxpy 的 RV64V 代码。

### Predicate Registers: Handling IF Statements in Vector Loops

> ###谓词寄存器：处理 if vector 循环中的语句

From Amdahl’s law, we know that the speedup on programs with low to moderate levels of vectorization will be very limited. The presence of conditionals (IF statements) inside loops and the use of sparse matrices are two main reasons for lower levels of vectorization. Programs that contain IF statements in loops cannot be run in vector mode using the techniques we have discussed up to now because the IF statements introduce control dependences into a loop. Likewise, we cannot implement sparse matrices efficiently using any of the capabilities we have seen so far. We examine strategies for dealing with conditional execution here, leaving the discussion of sparse matrices for later.

> 根据 Amdahl 定律，我们知道，矢量化水平低至中等水平的程序的加速将非常有限。条件性(IF 语句)内部循环的存在和稀疏矩阵的使用是较低矢量化水平的两个主要原因。if 循环中包含语句的程序无法使用我们现在讨论的技术在向量模式下运行，因为 IF 语句将控制依赖引入循环。同样，我们无法使用到目前为止看到的任何功能有效地实施稀疏矩阵。我们研究了在此处处理有条件执行的策略，以便稍后的矩阵讨论。

![](./media/image229.png)

> ！[](./ Media/image229.png)

> Figure 4.6 A vector of arbitrary length processed with strip mining. All blocks but the first are of length MVL, utilizing the full power of the vector processor. In this figure, we use the variable _m_ for the expression (n % MVL). (The C operator % is modulo.)

>> 图 4.6 与条开采处理的任意长度的向量。除第一个块外，所有块都是长度 MVL 的，利用了向量处理器的全部功能。在此图中，我们将变量 *m* 用于表达式(n％MVL)。(C 运算符％为模型。)
>>

This loop cannot normally be vectorized because of the conditional execution of the body; however, if the inner loop could be run for the iterations for which X\[i\] 0, then the subtraction could be vectorized.

> 由于身体的有条件执行，该循环通常无法矢量化；但是，如果可以为 x \ [i \] 0 的迭代运行内部循环，则可以将减法进行矢量化。

The common extension for this capability is _vector-mask control_. In RV64V, predicate registers hold the mask and essentially provide conditional execution of each element operation in a vector instruction. These registers use a Boolean vector to control the execution of a vector instruction, just as conditionally executed instructions use a Boolean condition to determine whether to execute a scalar instruction (see [Chapter 3](#_bookmark93)). When the predicate register p0 is set, all following vector instructions operate only on the vector elements whose corresponding entries in the predicate register are 1. The entries in the destination vector register that correspond to a 0 in the mask register are unaffected by the vector operation. Like vector registers, predicate registers are configured and can be disabled. Enabling a predicate register initializes it to all 1 s, meaning that subsequent vector instructions operate on all vector elements. We can now use the following code for the previous loop, assuming that the starting addresses of X and Y are in x5 and x6, respectively:

> 此功能的共同扩展是 *vector 掩码控制*。在 RV64V 中，谓词寄存器持有掩码，并基本上在向量指令中提供了每个元素操作的有条件执行。这些寄存器使用布尔矢量来控制向量指令的执行，就像有条件执行的指令使用布尔条件来确定是否执行标量指令(请参阅[第 3 章](#\_ bookmark93))。设置谓词寄存器 P0 时，所有以下矢量指令仅在谓词寄存器中的相应条目为 1 上进行。目标矢量寄存器中的入口与掩码寄存器中的 0 相对应的入口不受向量操作的影响。。像向量寄存器一样，谓词寄存器也已配置并可以禁用。使谓词注册将其初始化为所有 1 s，这意味着随后的向量指令对所有向量元素进行操作。现在，假设 X 和 Y 的起始地址分别在 X5 和 X6 中，我们可以将以下代码用于上一个循环：

Compiler writers use the term _IF-conversion_ to transform an IF statement into a straight-line code sequence using conditional execution.

> 编译器作家使用术语 *if-conversion* 使用条件执行将 IF 语句转换为直线代码序列。

Using a vector-mask register does have overhead, however. With scalar architectures, conditionally executed instructions still require execution time when the condition is not satisfied. Nonetheless, the elimination of a branch and the associated control dependences can make a conditional instruction faster even if it sometimes does useless work. Similarly, vector instructions executed with a vector mask still take the same execution time, even for the elements where the mask is zero. Likewise, despite a significant number of zeros in the mask, using vector-mask control may still be significantly faster than using scalar mode.

> 但是，使用矢量面罩寄存器确实具有开销。使用标量体系结构，有条件执行的指令仍需要执行时间，当时不满足条件。尽管如此，即使有时从事无用的工作，消除分支机构和相关的控制依赖性也可以使有条件的指令更快。同样，使用向量蒙版执行的向量指令仍然需要相同的执行时间，即使对于掩码为零的元素也是如此。同样，尽管掩模中有大量的零，但使用矢量遮罩控制可能仍然比使用标量模式更快。

As we will see in [Section 4.4](#graphics-processing-units), one difference between vector processors and GPUs is the way they handle conditional statements. Vector processors make the predicate registers part of the architectural state and rely on compilers to manipulate mask registers explicitly. In contrast, GPUs get the same effect using hardware to manipulate internal mask registers that are invisible to GPU software. In both cases, the hardware spends the time to execute a vector element whether the corresponding mask bit is 0 or 1, so the GFLOPS rate drops when masks are used.

> 正如我们将在[第 4.4 节](＃Graphics Processing-Units)中看到的那样，向量处理器和 GPU 之间的一个区别是他们处理条件语句的方式。向量处理器使谓词登记处的一部分是建筑状态的一部分，并依靠编译器明确操纵掩模寄存器。相比之下，GPU 使用硬件来操纵 GPU 软件不可见的内部掩码寄存器。在这两种情况下，硬件都花时间执行矢量元素，无论相应的掩码位为 0 还是 1，因此使用掩码时 Gflops 速率会下降。

### Memory Banks: Supplying Bandwidth for Vector Load/Store Units

> ###内存库：为矢量加载/商店单位提供带宽

The behavior of the load/store vector unit is significantly more complicated than that of the arithmetic functional units. The start-up time for a load is the time to get the first word from memory into a register. If the rest of the vector can be supplied without stalling, then the vector initiation rate is equal to the rate at which new words are fetched or stored. Unlike simpler functional units, the initiation rate may not necessarily be 1 clock cycle because memory bank stalls can reduce effective throughput.

> 负载/存储矢量单位的行为比算术功能单元的行为要复杂得多。负载的启动时间是将第一个单词从内存中获取到寄存器的时候了。如果可以在不停滞的情况下提供其余的向量，则向量的启动速率等于获取或存储新单词的速率。与更简单的功能单元不同，启动率可能不一定是 1 个时钟周期，因为存储库摊位可以减少有效的吞吐量。

Typically, penalties for start-ups on load/store units are higher than those for arithmetic units—over 100 clock cycles on many processors. For RV64V, we assume a start-up time of 12 clock cycles, the same as the Cray-

> 通常，负载/商店单位的初创企业的处罚高于算术单元的罚款，许多处理器上的时钟周期为 100 个时钟周期。对于 RV64V，我们假设启动时间为 12 个时钟周期，与 Cray-相同

1\. (Recent vector computers use caches to bring down latency of vector loads and stores.)

> 1 \。(最近的矢量计算机使用缓存来降低向量负载和商店的延迟。)

To maintain an initiation rate of one word fetched or stored per clock cycle, the memory system must be capable of producing or accepting this much data. Spreading accesses across multiple independent memory banks usually delivers the desired rate. As we will soon see, having significant numbers of banks is useful for dealing with vector loads or stores that access rows or columns of data.

> 为了维持每个时钟周期获取或存储一个单词的启动率，内存系统必须能够产生或接受这一数据。在多个独立的内存库中传播访问通常会提供所需的费率。正如我们将很快看到的那样，拥有大量银行对于处理访问行或数据列的向量负载或商店很有用。

Most vector processors use memory banks, which allow several independent accesses rather than simple memory interleaving for three reasons:

> 大多数向量处理器都使用内存库，这些内存库允许多个独立访问而不是简单的内存交织，原因有三个：

1. Many vector computers support many loads or stores per clock cycle, and the memory bank cycle time is usually several times larger than the processor cycle time. To support simultaneous accesses from multiple loads or stores, the memory system needs multiple banks and needs to be able to control the addresses to the banks independently.

> 1.许多矢量计算机每个时钟周期都支持许多负载或存储，并且内存库周期时间通常比处理器周期时间大几倍。为了支持来自多个负载或商店的同时访问，内存系统需要多个银行，并且需要能够独立控制银行的地址。

2. Most vector processors support the ability to load or store data words that are not sequential. In such cases, independent bank addressing, rather than interleaving, is required.

> 2.大多数矢量处理器都支持加载或存储非顺序的数据单词的能力。在这种情况下，需要独立的银行处理而不是交织。

3. Most vector computers support multiple processors sharing the same memory system, so each processor will be generating its own separate stream of addresses.

> 3.大多数矢量计算机都支持共享相同内存系统的多个处理器，因此每个处理器将生成自己的单独的地址流。

In combination, these features lead to the desire for a large number of independent memory banks, as the following example shows.

> 结合起来，这些功能导致人们渴望大量独立的内存库，如以下示例所示。

Example The largest configuration of a Cray T90 (Cray T932) has 32 processors, each capable of generating 4 loads and 2 stores per clock cycle. The processor clock cycle is 2.167 ns, while the cycle time of the SRAMs used for the memory system is 15 ns. Calculate the minimum number of memory banks required to allow all processors to run at the full memory bandwidth.

> 示例 Cray T90(Cray T932)的最大配置具有 32 个处理器，每个处理器能够每一个时钟周期生成 4 个负载和 2 个商店。处理器时钟周期为 2.167 ns，而用于存储系统的 SRAM 的周期时间为 15 ns。计算允许所有处理器以完整内存带宽运行所需的最小内存库数。

_Answer_ The maximum number of memory references each cycle is 192: 32 processors times 6 references per processor. Each SRAM bank is busy for 15/2.167 6.92 clock cycles, which we round up to 7 processor clock cycles. Therefore we require a minimum of 192 7 1344 memory banks!

> *answer *每个周期的最大内存参考数量为 192：32 处理器时间 6 每个处理器。每个 SRAM 银行都忙于 15/2.167 6.92 时钟周期，我们最多可以汇总 7 个处理器时钟周期。因此，我们至少需要 192 7 1344 内存库！

The Cray T932 actually has 1024 memory banks, so the early models could not sustain the full bandwidth to all processors simultaneously. A subsequent memory upgrade replaced the 15 ns asynchronous SRAMs with pipelined synchronous SRAMs that more than halved the memory cycle time, thereby providing sufficient bandwidth.

> Cray T932 实际上有 1024 个内存库，因此早期模型无法同时维持所有处理器的完整带宽。随后的存储器升级将 15 ns 异步 SRAM 替换为管道同步 SRAM，这些 SRAM 将记忆周期时间缩短了一半，从而提供了足够的带宽。

Taking a higher-level perspective, vector load/store units play a similar role to prefetch units in scalar processors in that both try to deliver data bandwidth by supplying processors with streams of data.

> 从较高的角度来看，向量负载/商店单元与标量处理器中的预取单元起着相似的作用，因为两者都试图通过向处理器提供数据流来提供数据带宽。

### Stride: Handling Multidimensional Arrays in Vector Architectures

> ###大步：处理矢量体系结构中的多维阵列

The position in memory of adjacent elements in a vector may not be sequential. Consider this straightforward code for matrix multiply in C:

> 记忆中相邻元素中矢量中的位置可能不是顺序的。考虑在 C 中使用的此简单的矩阵代码：

We could vectorize the multiplication of each row of B with each column of D and strip-mine the inner loop with k as the index variable.

> 我们可以将 B 的每一行乘法用 D 的每一列的乘积乘法，并以 K 为索引变量将内部循环划带。

To do so, we must consider how to address adjacent elements in B and adjacent elements in D. When an array is allocated memory, it is linearized and must be laid out in either row-major order (as in C) or column-major order (as in Fortran). This linearization means that either the elements in the row or the elements in the column are not adjacent in memory. For example, the preceding C code allocates in row-major order, so the elements of D that are accessed by iterations in the inner loop are separated by the row size times 8 (the number of bytes per entry) for a total of 800 bytes. In [Chapter 2](#_bookmark46), we saw that blocking could improve locality in cachebased systems. For vector processors without caches, we need another technique to fetch elements of a vector that are not adjacent in memory.

> 为此，我们必须考虑如何解决 B 中的相邻元素和 D 中的相邻元素。当阵列分配内存时，它是线性化的，必须以行式订单(如 C)或列 - Major 进行线性化。订单(如 fortran 中)。这种线性化意味着行中的元素或列中的元素在内存中不相邻。例如，前面的 C 代码按行分配顺序分配，因此内部循环中迭代访问的 D 元素由行尺寸尺寸时间 8(每个条目的字节数)分开，总计为 800 个字节。在[第 2 章](#\_ bookmark46)中，我们看到阻止可以改善基于 CacheBase 的系统中的位置。对于没有缓存的矢量处理器，我们需要另一种技术来获取在内存中不相邻的向量的元素。

This distance separating elements to be gathered into a single vector register is called the _stride_. In this example, matrix D has a stride of 100 double words (800 bytes), and matrix B would have a stride of 1 double word (8 bytes). For columnmajor order, which is used by Fortran, the strides would be reversed. Matrix D would have a stride of 1, or 1 double word (8 bytes), separating successive elements, while matrix B would have a stride of 100, or 100 double words (800 bytes). Thus, without reordering the loops, the compiler can’t hide the long distances between successive elements for both B and D.

> 将要收集到单个向量寄存器中的距离分离元素称为 *stride*。在此示例中，矩阵 D 的大步是 100 个双词(800 个字节)，并且矩阵 B 的大步为 1 个双词(8 个字节)。对于 Fortran 使用的 Columnmajor 订单，将逆转步幅。矩阵 D 的大步为 1 或 1 个双词(8 个字节)，将连续的元素分开，而矩阵 B 的步幅为 100 或 100 个双词(800 个字节)。因此，在不重新排序循环的情况下，编译器无法隐藏 B 和 D 的连续元素之间的长距离。

Once a vector is loaded into a vector register, it acts as if it had logically adjacent elements. Thus a vector processor can handle strides greater than one, called _nonunit strides_, using only vector load and vector store operations with stride capability. This ability to access nonsequential memory locations and to reshape them into a dense structure is one of the major advantages of a vector architecture.

> 将向量加载到向量寄存器中后，它就会像具有逻辑相邻元素一样起作用。因此，矢量处理器只能使用具有步速能力的向量载荷和矢量存储操作来处理大于一个的步幅，称为 *nonunit 步骤*。这种能够访问非序列内存位置并将其重塑为密集结构的能力是向量体系结构的主要优势之一。

Caches inherently deal with unit-stride data; increasing block size can help reduce miss rates for large scientific datasets with unit stride, but increasing block size can even have a negative effect for data that are accessed with nonunit strides. While blocking techniques can solve some of these problems (see [Chapter 2](#_bookmark46)), the ability to access noncontiguous data efficiently remains an advantage for vector processors on certain problems, as we will see in [Section 4.7](#_bookmark198).

> Caches 固有地处理单元式数据；增加的块大小可以帮助降低单位步伐的大型科学数据集的错过率，但是增加的块大小甚至可能对通过非单元前进访问的数据产生负面影响。虽然阻止技术可以解决其中一些问题(请参阅[第 2 章](#\_ bookmark46))，但正如我们将在[4.7]中看到的那样，有效访问非连续数据的能力仍然是矢量处理器上的优势。)。

On RV64V, where the addressable unit is a byte, the stride for our example would be 800. The value must be computed dynamically because the size of the matrix may not be known at compile time or—just like vector length—may change for different executions of the same statement. The vector stride, like the vector starting address, can be put in a general-purpose register. Then the RV64V instruction VLDS (load vector with stride) fetches the vector into a vector register. Likewise, when storing a nonunit stride vector, use the instruction VSTS (store vector with stride).

> 在 RV64V 上，可寻址单元是一个字节，我们的示例的大步是 800。必须动态计算该值，因为矩阵的大小可能在编译时不知道，或者像矢量长度一样 - 可能会更改不同的变化。执行同一语句。矢量大步像向量的起始地址一样，可以放入通用寄存器中。然后，RV64V 指令 VLDS(大步载载体)将向量获取到向量寄存器中。同样，在存储非单元步数矢量时，请使用指令 VSTS(步迈的存储矢量)。

Supporting strides greater than one complicates the memory system. Once we introduce nonunit strides, it becomes possible to request accesses from the same bank frequently. When multiple accesses contend for a bank, a memory bank conflict occurs, thereby stalling one access. A bank conflict and thus a stall will occur if 6.1 clock cycles per element, slowing it down by a factor of 5!

> 支撑大步超过一个使记忆系统复杂化。一旦我们引入了非单元的进步，就有可能经常从同一银行请求访问。当多个访问权限争夺银行时，会发生内存银行冲突，从而停滞一个访问权限。如果每个元素的 6.1 时钟循环，将其减慢 5 倍！

Example Suppose we have 8 memory banks with a bank busy time of 6 clocks and a total memory latency of 12 cycles. How long will it take to complete a 64-element vector load with a stride of 1? With a stride of 32?

> 示例假设我们有 8 个内存库，银行繁忙时间为 6 个时钟，总存储延迟为 12 个周期。以 1 的步幅完成 64 个元素矢量负载需要多长时间？大步 32？

_Answer_ Because the number of banks is larger than the bank busy time, for a stride of 1, the load will take 12 + 64 76 clock cycles, or 1.2 clock cycles per element. The worst possible stride is a value that is a multiple of the number of memory banks, as in this case with a stride of 32 and 8 memory banks. Every access to memory (after the first one) will collide with the previous access and will have to wait for the 6-clockcycle bank busy time. The total time will be 12 + 1 + 6 \* 63 391 clock cycles, or

> _answer_，因为银行的数量大于银行的繁忙时间，因此，对于 1 的大步，负载将需要 12 + 64 76 时钟周期，或每个元素的 1.2 时钟周期。最糟糕的大步是一个值，它是内存库数量的倍数，在这种情况下，步幅为 32 和 8 内存库。每次进入内存(在第一个之后)都会与先前的访问相撞，并且必须等待 6-锁定银行的忙碌时间。总时间为 12 + 1 + 6 \* 63 391 时钟周期，或

### Gather-Scatter: Handling Sparse Matrices in Vector Architectures

> ###聚集 - 分数：处理矢量体系结构中的稀疏矩阵

As previously mentioned, sparse matrices are commonplace, so it is important to have techniques to allow programs with sparse matrices to execute in vector mode. In a sparse matrix, the elements of a vector are usually stored in some compacted form and then accessed indirectly. Assuming a simplified sparse structure, we might see code that looks like this:

> 如前所述，稀疏矩阵很普遍，因此重要的是要有允许稀疏矩阵的程序以向量模式执行的技术很重要。在稀疏矩阵中，矢量的元素通常以某种压实的形式存储，然后间接访问。假设简化的稀疏结构，我们可能会看到看起来像这样的代码：

This code implements a sparse vector sum on the arrays A and C, using index vectors K and M to designate the nonzero elements of A and C. (A and C must have the same number of nonzero elements—n of them—so K and M are the same size.)

> 该代码使用索引向量 k 和 m 在数组 a 和 c 上实现了稀疏的向量总和来指定 A 和 C 的非零元素(A 和 C 必须具有相同数量的非零元素的数量 - 其中的 N -n -s -so K 和 k 和 k 和 cm 的大小相同。)

The primary mechanism for supporting sparse matrices is _gather-scatter oper-_

> 支持稀疏矩阵的主要机制是 *gather-Scatter oper-*

_ations_ using index vectors. The goal of such operations is to support moving between a compressed representation (i.e., zeros are not included) and normal representation (i.e., the zeros are included) of a sparse matrix. A _gather_ operation takes an _index vector_ and fetches the vector whose elements are at the addresses given by adding a base address to the offsets given in the index vector. The result is a dense vector in a vector register. After these elements are operated on in a dense form, the sparse vector can be stored in an expanded form by a _scatter_ store, using the same index vector. Hardware support for such operations is called _gather-scatter_, and it appears on nearly all modern vector processors. The RV64V instructions are vldi (load vector indexed or gather) and vsti (store vector indexed or scatter). For example, if x5, x6, x7, and x28 contain the starting addresses of the vectors in the previous sequence, we can code the inner loop with vector instructions such as:

> *ates* 使用索引向量。此类操作的目的是支持在压缩表示形式(即不包括零)之间移动和稀疏矩阵的正常表示(即包括零)。*gather* 操作采用 *index vector*，并获取了通过在索引向量中给出的偏移量中添加基本地址来给出的元素在给定的地址的向量。结果是向量寄存器中的密集矢量。在以致密形式操作这些元素后，稀疏向量可以使用相同的索引向量以 *scatter* 商店的扩展形式存储。对此类操作的硬件支持称为 *gather-Scatter*，它几乎在所有现代矢量处理器上出现。RV64V 指令是 VLDI(负载向量索引或收集)和 VSTI(存储向量索引或散射)。例如，如果 x5，x6，x7 和 x28 包含上一个序列中向量的起始地址，则我们可以使用：

This technique allows code with sparse matrices to run in vector mode. A simple vectorizing compiler could not automatically vectorize the preceding source code because the compiler would not know that the elements of K are distinct values, and thus that no dependences exist. Instead, a programmer directive would tell the compiler that it was safe to run the loop in vector mode.

> 该技术允许具有稀疏矩阵的代码在向量模式下运行。一个简单的矢量化编译器无法自动矢量化前面的源代码，因为编译器不知道 K 的元素是不同的值，因此不存在依赖性。取而代之的是，程序员指令将告诉编译器在向量模式下运行循环是安全的。

Although indexed loads and stores (gather and scatter) can be pipelined, they typically run much more slowly than nonindexed loads or stores, because the memory banks are not known from the start of the instruction. The register file must also provide communication between the lanes of a vector unit to support gather and scatter.

> 尽管可以将索引负载和商店(收集和散布)进行管道，但它们的运行速度通常比非索引负载或商店慢得多，因为从说明开始时，内存库是不知道的。寄存器文件还必须提供向量单元的车道之间的通信，以支持收集和分散。

Each element of a gather or scatter has an individual address, so they can’t be handled in groups, and there can be conflicts at many places throughout the memory system. Thus each individual access incurs significant latency even on cachebased systems. However, as [Section 4.7](#_bookmark198) shows, a memory system can deliver better performance by designing for this case and by using more hardware resources versus when architects have a laissez-faire attitude toward such unpredictable accesses.

> 聚集或分散的每个元素都有一个单独的地址，因此不能分组处理，并且整个内存系统中的许多地方都可能存在冲突。因此，即使在基于高速缓存的系统上，每个单独的访问也会产生明显的延迟。但是，正如[4.7](#\_ bookmark198)所示，内存系统可以通过为这种情况设计和使用更多的硬件资源来提供更好的性能，而当架构师对这种不可预测的访问方面的 Laissez-faire 态度时，则可以通过使用更多的硬件资源来提供更好的性能。

As we will see in [Section 4.4](#graphics-processing-units), all loads are gathers and all stores are scatters in GPUs in that no separate instructions restrict addresses to be sequential. To turn the potentially slow gathers and scatters into the more efficient unit-stride accesses to memory, the GPU hardware must recognize the sequential addresses during execution and the GPU programmer to ensure that all the addresses in a gather or scatter are to adjacent locations.

> 正如我们将在[第 4.4 节](＃图形处理 - 单元)中看到的那样，所有负载均为收集器，所有商店均为 gpus 中的散布，因为没有单独的指令限制地址是顺序的。为了将潜在的缓慢收集器和分散到更有效的单位轨道访问内存，GPU 硬件必须在执行过程中识别顺序地址和 GPU 程序员，以确保聚集或分散中的所有地址都属于相邻位置。

### Programming Vector Architectures

> ###编程矢量体系结构

An advantage of vector architectures is that compilers can tell programmers at compile time whether a section of code will vectorize or not, often giving hints as to why it did not vectorize the code. This straightforward execution model allows experts in other domains to learn how to improve performance by revising their code or by giving hints to the compiler when it’s okay to assume independence between operations, such as for gather-scatter data transfers. It is this dialogue between the compiler and the programmer, with each side giving hints to the other on how to improve performance, that simplifies programming of vector computers.

> 矢量体系结构的一个优点是，编译器可以在编译时间告诉程序员是否将矢量化的一部分矢量化，经常给出有关为什么不将代码矢量化的提示。这种直接的执行模型允许其他域中的专家学习如何通过修改代码或在可以在操作之间实现独立性的编译器(例如集会片段数据传输)时向编译器提供提示。正是编译器和程序员之间的对话，双方都暗示了对方如何提高性能，这简化了向量计算机的编程。

Figure 4.7 Level of vectorization among the Perfect Club benchmarks when executed on the Cray Y-MP (Vajapeyam, 1991). The first column shows the vectorization level obtained with the compiler without hints, and the second column shows the results after the codes have been improved with hints from a team of Cray Research programmers.

> 图 4.7 在 Cray Y-MP 执行时，完美的俱乐部基准中的矢量化水平(Vajapeyam，1991)。第一列显示了没有提示的编译器获得的矢量化水平，第二列显示了通过 Cray 研究程序员团队提示的代码改进后的结果。

Today, the main factor that affects the success with which a program runs in vector mode is the structure of the program itself: Do the loops have true data dependences (see [Section 4.5](#detecting-and-enhancing-loop-level-parallelism)), or can they be restructured so as not to have such dependences? This factor is influenced by the algorithms chosen and, to some extent, by how they are coded.

> 如今，影响程序在向量模式下运行的成功的主要因素是程序本身的结构：循环是否具有真实的数据依赖性(请参阅[4.5](＃检测和 Enhancing-eNhancing-loop-level-))，或者可以进行重组以免具有这种依赖性？该因素受到所选算法的影响，并在某种程度上受到编码的方式。

As an indication of the level of vectorization achievable in scientific programs, let’s look at the vectorization levels observed for the Perfect Club benchmarks. [Figure 4.7](#_bookmark175) shows the percentage of operations executed in vector mode for two versions of the code running on the Cray Y-MP. The first version is that obtained with just compiler optimization on the original code, while the second version uses extensive hints from a team of Cray Research programmers. Several studies of the performance of applications on vector processors show a wide variation in the level of compiler vectorization.

> 为了表明在科学计划中可以达到的矢量化水平，让我们看一下观察到的理想俱乐部基准测试的矢量化水平。[图 4.7](#\_ bookmark175)显示了在 Cray Y-MP 上运行的两个版本的向量模式下执行的操作百分比。第一个版本是仅在原始代码上进行编译器优化获得的版本，而第二版则使用了 Cray 研究程序员团队的广泛提示。关于矢量处理器应用的性能的几项研究表明，编译器矢量化水平的差异很大。

The hint-rich versions show significant gains in vectorization level for codes that the compiler could not vectorize well by itself, with all codes now above 50% vectorization. The median vectorization improved from about 70% to about 90%.

> 富含提示的版本显示了编译器本身无法很好地矢量化的代码矢量化水平的显着提高，所有代码现在都高于 50％的矢量化。中值矢量化从约 70％提高到约 90％。
