## Enhancing Vector Performance

> ##增强向量性能

In this section, we present techniques for improving the performance of a vector processor in more depth than we did in [Chapter 4](#_bookmark165).

> 在本节中，我们介绍了比[第 4 章]（#_ bookmark165）更深入地提高矢量处理器性能的技术。

### Chaining in More Depth

> ###更深入的链接

Early implementations of chaining worked like forwarding, but this restricted the timing of the source and destination instructions in the chain. Recent implementa- tions use _flexible chaining_, which allows a vector instruction to chain to essentially any other active vector instruction, assuming that no structural hazard is generated. Flexible chaining requires simultaneous access to the same vector register by dif- ferent vector instructions, which can be implemented either by adding more read and write ports or by organizing the vector-register file storage into interleaved banks in a similar way to the memory system. We assume this type of chaining throughout the rest of this appendix.

> 链接的早期实现就像转发一样工作，但这限制了链中源和目的地指示的时间。最新的实施使用_FLEXIBLE CHANED_，该链条允许向量指令链，以便在没有产生结构性危害的情况下，从而实现任何其他活动矢量指令。灵活的链接需要通过不同的向量指令同时访问同一向量寄存器，可以通过与内存系统相似的方式将矢量注册文件存储添加到交织的银行中，可以通过添加更多的读取和写入端口来实现。我们假设在本附录的其余部分中假设这种链接。

Even though a pair of operations depends on one another, chaining allows the operations to proceed in parallel on separate elements of the vector. This permits the operations to be scheduled in the same convoy and reduces the number of chimes required. For the previous sequence, a sustained rate (ignoring start-up) of two floating-point operations per clock cycle, or one chime, can be achieved, even though the operations are dependent! The total running time for the above sequence becomes:

> 即使一对操作相互取决于彼此，链接也可以使操作在向量的单独元素上并行进行。这允许操作安排在相同的车队中，并减少所需的铃声数。对于先前的序列，即使操作取决于操作，也可以实现每个时钟周期两个浮点操作的持续率（忽略启动），或者可以实现一个循环。上述顺序的总运行时间变为：

[Figure G.8](#_bookmark693) shows the timing of a chained and an unchained version of the above pair of vector instructions with a vector length of 64. This convoy requires one chime; however, because it uses chaining, the start-up overhead will be seen in the actual timing of the convoy. In [Figure G.8](#_bookmark693), the total time for chained operation is 77 clock cycles, or 1.2 cycles per result. With 128 floating-point operations done in that time, 1.7 FLOPS per clock cycle are obtained. For the unchained version, there are 141 clock cycles, or 0.9 FLOPS per clock cycle.

> [图 G.8]（#_ bookmark693）显示了上述对向量长度为 64 的链式和未链接版本的时间安排。该车队需要一个钟声；但是，由于它使用链接，因此在车队的实际时机中将看到启动开销。在[图 G.8]（#_ bookmark693）中，链式操作的总时间为 77 个时钟周期，或每个结果的 1.2 个周期。在那个时候完成了 128 次浮点操作，获得了每个时钟周期的 1.7 拖失 lop。对于不链接的版本，有 141 个时钟周期，或每个时钟周期 0.9 拖鞋。

Figure G.8 Timings for a sequence of dependent vector operations ADDV and MULV, both unchained and chained. The 6- and 7-clock-cycle delays are the latency of the adder and multiplier.

> 图 G.8 未链接和链接的一系列依赖矢量操作 ADDV 和 MULV 的时间安排。6 和 7 循环循环延迟是加法器和乘数的延迟。

Although chaining allows us to reduce the chime component of the execution time by putting two dependent instructions in the same convoy, it does not eliminate the start-up overhead. If we want an accurate running time estimate, we must count the start-up time both within and across convoys. With chaining, the number of chimes for a sequence is determined by the number of different vector functional units available in the processor and the number required by the application. In particular, no convoy can contain a structural hazard. This means, for example, that a sequence containing two vector memory instructions must take at least two convoys, and hence two chimes, on a processor like VMIPS with only one vector load-store unit.

> 尽管链条使我们能够通过将两个因指令放入同一车队来减少执行时间的核电组成部分，但它不会消除启动开销。如果我们想要准确的运行时间估算，我们必须计算车队内部和整个车队的启动时间。通过链接，序列的铃声数取决于处理器中可用的不同矢量功能单元的数量和应用程序所需的数量。特别是，没有车队可以包含结构性危害。例如，这意味着一个包含两个矢量内存指令的序列必须至少在一个只有一个矢量负载储物单元的 VMIP 上，在像 VMIP 这样的处理器上占至少两个车队。

Chaining is so important that every modern vector processor supports flexible chaining.

> 链接是如此重要，以至于每个现代矢量处理器都支持灵活的链接。

### Sparse Matrices in More Depth

> ###稀疏矩阵更深入

[Chapter 4](#_bookmark165) shows techniques to allow programs with sparse matrices to execute in vector mode. Let’s start with a quick review. In a sparse matrix, the elements of a vector are usually stored in some compacted form and then accessed indirectly. Assuming a simplified sparse structure, we might see code that looks like this:

> [第 4 章]（#_ bookmark165）显示了允许具有稀疏矩阵的程序以向量模式执行的技术。让我们从快速审查开始。在稀疏矩阵中，矢量的元素通常以某种压实的形式存储，然后间接访问。假设简化的稀疏结构，我们可能会看到看起来像这样的代码：

This code implements a sparse vector sum on the arrays A and C, using index vectors K and M to designate the nonzero elements of A and C. (A and C must have the same number of nonzero elements—n of them.) Another common representa- tion for sparse matrices uses a bit vector to show which elements exist and a dense vector for the nonzero elements. Often both representations exist in the same pro- gram. Sparse matrices are found in many codes, and there are many ways to imple- ment them, depending on the data structure used in the program.

> 该代码使用索引向量 k 和 m 在数组 a 和 c 上实现稀疏的矢量总和来指定 A 和 C 的非零元素（A 和 C 必须具有相同数量的非零元素，其中是其中的另一种常见。）稀疏矩阵的代表使用了一个位向量来显示存在哪些元素以及非零元素的密集矢量。通常两种表示都存在于同一计划中。在许多代码中都发现了稀疏的矩阵，并且有许多方法可以根据程序中使用的数据结构进行操作。

A simple vectorizing compiler could not automatically vectorize the source code above because the compiler would not know that the elements of K are distinct values and thus that no dependences exist. Instead, a programmer directive would tell the compiler that it could run the loop in vector mode.

> 一个简单的矢量化编译器无法自动矢量化上面的源代码，因为编译器不知道 K 的元素是不同的值，因此不存在依赖性。取而代之的是，程序员指令将告诉编译器它可以在向量模式下运行循环。

More sophisticated vectorizing compilers can vectorize the loop automatically without programmer annotations by inserting run time checks for data

> 更复杂的矢量化编译器可以通过插入运行时间检查数据来自动对循环自动矢量化循环

dependences. These run time checks are implemented with a vectorized software version of the advanced load address table (ALAT) hardware described in Appen- dix H for the Itanium processor. The associative ALAT hardware is replaced with a software hash table that detects if two element accesses within the same stripmine iteration are to the same address. If no dependences are detected, the stripmine iter- ation can complete using the maximum vector length. If a dependence is detected, the vector length is reset to a smaller value that avoids all dependency violations, leaving the remaining elements to be handled on the next iteration of the strip- mined loop. Although this scheme adds considerable software overhead to the loop, the overhead is mostly vectorized for the common case where there are no dependences; as a result, the loop still runs considerably faster than scalar code (although much slower than if a programmer directive was provided).

> 依赖。这些运行时间检查是使用 Appen-Dix H 中的高级负载地址表（ALAT）硬件的矢量化软件版本实现的，用于 ITANIUM 处理器。关联 ALAT 硬件被软件哈希表替换，该软件表检测同一条纹迭代中是否访问两个元素的访问是相同的地址。如果未检测到依赖性，则可以使用最大矢量长度来完成条纹迭代。如果检测到依赖性，则将矢量长度重置为避免所有依赖性违规的较小值，而将其余的元素处理在带状循环的下一次迭代中。尽管该方案在循环中增加了大量的软件，但对于没有依赖性的常见情况，开销主要是矢量化的。结果，该循环的运行速度仍然比标量代码快得多（尽管提供了程序员指令的速度要慢得多）。

A scatter-gather capability is included on many of the recent supercomputers. These operations often run more slowly than strided accesses because they are more complex to implement and are more susceptible to bank conflicts, but they are still much faster than the alternative, which may be a scalar loop. If the sparsity properties of a matrix change, a new index vector must be computed. Many pro- cessors provide support for computing the index vector quickly. The CVI (create vector index) instruction in VMIPS creates an index vector given a stride (_m_), where the values in the index vector are 0, _m,_ 2 _m,_ …, 63 _m_. Some processors provide an instruction to create a compressed index vector whose entries corre- spond to the positions with a one in the mask register. Other vector architectures provide a method to compress a vector. In VMIPS, we define the CVI instruction to always create a compressed index vector using the vector mask. When the vector mask is all ones, a standard index vector will be created.

> 许多最近的超级计算机都包含散点机的能力。这些操作的运行通常比跨界的访问更慢，因为它们更复杂，并且更容易受到银行冲突的影响，但是它们仍然比替代方案快得多，替代方案可能是标量循环。如果矩阵变化的稀疏性属性，则必须计算新的索引向量。许多专员为快速计算索引向量提供了支持。VMIPS 中的 CVI（创建向量索引）指令创建了一个索引向量，给定了一个步幅（_M_），其中索引向量中的值为 0，_M，_ 2 _M，_…，_…，63 _m_。一些处理器提供了一项指令，以创建一个压缩索引向量，其条目在蒙版寄存器中使用一个位置的条目。其他向量体系结构提供了一种压缩向量的方法。在 VMIP 中，我们定义了 CVI 指令，以始终使用向量蒙版创建压缩索引向量。当矢量掩码都是所有的时，将创建一个标准索引向量。

The indexed loads-stores and the CVI instruction provide an alternative method to support conditional vector execution. Let us first recall code from [Chapter 4](#_bookmark165):

> 索引负载商店和 CVI 指令提供了支持条件矢量执行的替代方法。让我们首先从[第 4 章]（#_ bookmark165）中召回代码：

Whether the implementation using scatter-gather is better than the condition- ally executed version depends on the frequency with which the condition holds and the cost of the operations. Ignoring chaining, the running time of the original ver- sion is 5*n* + _c_<sub>1</sub>. The running time of the second version, using indexed loads and stores with a running time of one element per clock, is 4*n* + 4*fn* + _c_<sub>2</sub>, where _f_ is the fraction of elements for which the condition is true (i.e., A(i) ¦ 0). If we assume that the values of _c_<sub>1</sub> and _c_<sub>2</sub> are comparable, or that they are much smaller than _n_, we can find when this second technique is better.

> 使用散点收集的实施是否优于条件执行版本，取决于条件所保持的频率和操作的成本。忽略链条，原始范围的运行时间为 5* n* + _c_ <ub> 1 </sub>。第二版的运行时间，使用索引负载和商店，每个时钟的运行时间为一个元素，为 4* n* + 4* fn* + _c_ <sub> 2 </sub>，其中_f_是_f_的分数条件为真的元素（即 a（i）0）。如果我们假设_c_ <sub> 1 </sub>和_c_ <sub> 2 </sub>的值是可比的，或者它们比_n_小得多，那么当第二种技术更好时，我们可以找到。

That is, the second method is faster if less than one-quarter of the elements are non- zero. In many cases, the frequency of execution is much lower. If the index vector can be reused, or if the number of vector statements within the if statement grows, the advantage of the scatter-gather approach will increase sharply.

> 也就是说，如果元素的四分之一不零，则第二种方法更快。在许多情况下，执行频率要低得多。如果可以重复使用索引向量，或者 if 语句中的向量语句的数量增长，则散点聚集方法的优势将急剧增加。
