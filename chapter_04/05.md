## Detecting and Enhancing Loop-Level Parallelism

> ##检测和增强循环级并行性

Loops in programs are the fountainhead of many of the types of parallelism we previously discussed here and in [Chapter 5](#_bookmark213). In this section, we discuss compiler technology used for discovering the amount of parallelism that we can exploit in a program as well as hardware support for these compiler techniques. We define precisely when a loop is parallel (or vectorizable), how a dependence can prevent a loop from being parallel, and techniques for eliminating some types of depen- dences. Finding and manipulating loop-level parallelism is critical to exploiting both DLP and TLP, as well as the more aggressive static ILP approaches (e.g., VLIW) that we examine in Appendix H.

> 程序中的循环是我们以前在此处和[第 5 章]中讨论过的许多平行性类型的源泉（#\_ bookmark213）。在本节中，我们讨论用于发现我们可以在程序中利用的并行性的编译器技术以及对这些编译器技术的硬件支持。我们精确地定义了循环平行（或可矢量化）时，依赖性如何防止循环平行，以及消除某些类型的依赖性的技术。发现和操纵环路级并行性对于利用 DLP 和 TLP 以及我们在附录 H 中检查的更具侵略性的静态 ILP 方法（例如 VLIW）至关重要。

Figure 4.24 Conversion from terms used in this chapter to official NVIDIA/CUDA and AMD jargon. OpenCL names are given in the book’s definitions.

> 图 4.24 从本章中使用的术语转换为官方 NVIDIA/CUDA 和 AMD 术语。本书的定义中给出了 opencl 名称。

Loop-level parallelism is normally investigated at the source level or close to it, while most analysis of ILP is done once instructions have been generated by the compiler. Loop-level analysis involves determining what dependences exist among the operands in a loop across the iterations of that loop. For now, we will consider only data dependences, which arise when an operand is written at some point and read at a later point. Name dependences also exist and may be removed by the renaming techniques discussed in [Chapter 3](#_bookmark93).

> 通常在源级别或接近循环级的并行性研究，而一旦编译器生成了指令，大多数 ILP 的分析都是进行的。循环级别的分析涉及确定操作数之间在该循环的迭代中的操作数中存在的依赖。就目前而言，我们将仅考虑数据依赖性，这是在某个时候写入操作数并在以后阅读时会产生的。名称依赖也存在，可以通过[第 3 章]（#\_ bookmark93）中讨论的重命名技术来删除。

The analysis of loop-level parallelism focuses on determining whether data accesses in later iterations are dependent on data values produced in earlier itera- tions; such dependence is called a _loop-carried dependence_. Most of the examples

> 循环级并行性的分析重点是确定以后迭代中的数据访问是否取决于早期迭代中产生的数据值。这种依赖性称为 *loop 婚姻依赖*。大多数示例

Figure 4.25 Conversion from terms used in this chapter to official NVIDIA/CUDA and AMD jargon. Note that our descriptive terms “local memory” and “private memory” use the OpenCL terminology. NVIDIA uses SIMT (single- instruction multiple-thread) rather than SIMD to describe a streaming multiprocessor. SIMT is preferred over SIMD because the per-thread branching and control flow are unlike any SIMD machine.

> 图 4.25 从本章中使用的术语转换为官方 NVIDIA/CUDA 和 AMD 术语。请注意，我们的描述性术语“本地记忆”和“私人记忆”使用 OpenCL 术语。NVIDIA 使用 SIMT（单个指令多线程），而不是 SIMD 来描述流多处理器。SIMT 优先于 SIMD，因为每线程分支和控制流与任何 SIMD 机器不同。

we considered in Chapters [2](#_bookmark46) and [3](#_bookmark93) had no loop-carried dependences and thus are loop-level parallel. To see that a loop is parallel, let us first look at the source representation:

> 我们在章节[2]（#_ bookmark46）中考虑了[3]（#_ bookmark93）没有循环依赖性，因此是循环级别的平行。要看到循环是平行的，请首先看一下源代表：

In this loop, the two uses of x\[i\] are dependent, but this dependence is within a single iteration and is not loop-carried. There is a loop-carried dependence between successive uses of i in different iterations, but this dependence involves an induc- tion variable that can be easily recognized and eliminated. We saw examples of how to eliminate dependences involving induction variables during loop unrolling in Section 2.2 of [Chapter 2](#_bookmark46), and we will look at additional examples later in this section.

> 在此循环中，x \ [i \]的两种用途是依赖的，但是这种依赖性在单个迭代范围内，并且没有循环。在不同的迭代中，I 的连续用途之间存在循环的依赖性，但是这种依赖性涉及一个可以轻松识别和消除的诱导变量。我们看到了如何消除[第 2 章]（#\_ bookmark46）第 2.2 节中循环展开期间涉及归纳变量的依赖的示例，我们将在本节稍后研究其他示例。

Because finding loop-level parallelism involves recognizing structures such as loops, array references, and induction variable computations, a com- piler can do this analysis more easily at or near the source level, in contrast to the machine-code level. Let’s look at a more complex example.

> 因为查找环路级并行性涉及识别诸如循环，数组参考和归纳变量计算之类的结构，因此与机器代码级别相比，协商器可以更轻松地在源级别或接近源级别进行此分析。让我们看一个更复杂的例子。

Example Consider a loop like this one:

> 示例考虑这样的循环：

Assume that A, B, and C are distinct, nonoverlapping arrays. (In practice, the arrays may sometimes be the same or may overlap. Because the arrays may be passed as parameters to a procedure that includes this loop, determining whether arrays over- lap or are identical often requires sophisticated, interprocedural analysis of the pro- gram.) What are the data dependences among the statements S1 and S2 in the loop?

> 假设 A，B 和 C 是不同的非重叠数组。（实际上，阵列有时可能是相同的或可能重叠的。因为阵列可以作为参数传递给包含此循环的过程，确定阵列是否过度或相同，通常需要进行复杂的概解分析，以概解分析。克。）循环中的语句 S1 和 S2 之间的数据依赖性是什么？

_Answer_ There are two different dependences:

> 回答有两种不同的依赖性：

1. S1 uses a value computed by S1 in an earlier iteration, because iteration i com- putes A\[i+ 1\], which is read in iteration i+ 1. The same is true of S2 for B\[i\] and B\[i+ 1\].

> 1. S1 使用 S1 在较早迭代中计算的值，因为迭代 i comput a \ [i+ 1 \]，在迭代 i+ 1 中读取。b \ [i+ 1 \]。

2. S2 uses the value A\[i+ 1\] computed by S1 in the same iteration.

> 2. S2 使用 S1 在相同的迭代中计算的值 A \ [I+ 1 \]。

These two dependences are distinct and have different effects. To see how they differ, let’s assume that only one of these dependences exists at a time. Because the dependence of statement S1 is on an earlier iteration of S1, this dependence is loop-carried. This dependence forces successive iterations of this loop to execute in series.

> 这两个依赖性是不同的，并且具有不同的影响。要查看它们的不同之处，让我们假设一次只存在其中一种。由于语句 S1 的依赖性是 S1 的较早迭代，因此该依赖性是循环的。这种依赖性迫使该循环的连续迭代串联执行。

The second dependence (S2 depending on S1) is within an iteration and is not loop-carried. Thus, if this were the only dependence, multiple iter- ations of the loop would execute in parallel, as long as each pair of state- ments in an iteration were kept in order. We saw this type of dependence in an example in Section 2.2, where unrolling could expose the parallelism. These intra-loop dependences are common; for example, a sequence of vector instructions that uses chaining exhibits exactly this sort of dependence.

> 第二个依赖性（S2 取决于 S1）在迭代范围内，并且没有循环。因此，如果这是唯一的依赖性，则循环的多个迭代将平行执行，只要将迭代中的每对状态保持顺序。我们在第 2.2 节中的一个示例中看到了这种依赖性，在该示例中，展开可以暴露出并行性。这些环内依赖性很常见。例如，使用链接的一系列矢量指令完全表现出这种依赖性。

It is also possible to have a loop-carried dependence that does not prevent parallelism, as the next example shows.

> 如下一个示例所示，也可以具有不会阻止并行性的循环依赖性。

Example Consider a loop like this one:

> 示例考虑这样的循环：

What are the dependences between S1 and S2? Is this loop parallel? If not, show how to make it parallel.

> S1 和 S2 之间的依赖性是什么？这个循环是平行的吗？如果没有，请显示如何并行。

_Answer_ Statement S1 uses the value assigned in the previous iteration by statement S2, so there is a loop-carried dependence between S2 and S1. Despite this loop-carried dependence, this loop can be made parallel. Unlike the earlier loop, this depen- dence is not circular; neither statement depends on itself, and although S1 depends on S2, S2 does not depend on S1. A loop is parallel if it can be written without a cycle in the dependences because the absence of a cycle means that the depen- dences give a partial ordering on the statements.

> *answer* 语句 S1 使用上一个迭代中分配的值按语句 S2 分配的值，因此 S2 和 S1 之间存在循环依赖性。尽管这种循环依赖性，但可以平行这个循环。与早期的循环不同，这种依赖性不是圆形的。陈述都不取决于自身，尽管 S1 取决于 S2，但 S2 不取决于 S1。如果循环可以在依赖关系中没有周期的情况下编写，则循环是平行的，因为没有循环意味着依赖性对陈述进行部分顺序。

Although there are no circular dependences in the preceding loop, it must be transformed to conform to the partial ordering and expose the parallelism. Two observations are critical to this transformation:

> 尽管前面循环中没有圆形依赖性，但必须将其转换以符合部分顺序并揭示并行性。两个观察对于这种转变至关重要：

1. There is no dependence from S1 to S2. If there were, then there would be a cycle in the dependences and the loop would not be parallel. Because this other dependence is absent, interchanging the two statements will not affect the exe- cution of S2.

> 1.从 S1 到 S2 没有依赖性。如果有的话，那么依赖性将有一个周期，并且循环不会平行。由于缺乏这种其他依赖性，因此互换这两个陈述不会影响 S2 的研究。

2. On the first iteration of the loop, statement S2 depends on the value of B\[0\] computed _prior_ to initiating the loop.

> 2.在循环的第一次迭代中，语句 S2 取决于 b \ [0 \]计算的 *prior* 的值来启动循环。

These two observations allow us to replace the preceding loop with the following code sequence:

> 这两个观察结果使我们能够用以下代码序列替换前面的循环：

The dependence between the two statements is no longer loop-carried so that iterations of the loop may be overlapped, provided the statements in each iteration are kept in order.

> 两个语句之间的依赖性不再被循环结婚，因此循环的迭代可能会重叠，前提是每次迭代中的语句都按顺序保留。

Our analysis needs to begin by finding all loop-carried dependences. This depen- dence information is _inexact_, in the sense that it tells us that such dependence _may_ exist. Consider the following example:

> 我们的分析需要首先找到所有循环的依赖。从某种意义上说，此依赖性信息是 *inexact*，它告诉我们存在这种依赖性 *may* 存在。考虑以下示例：

The second reference to A in this example need not be translated to a load instruction because we know that the value is computed and stored by the previous statement. Thus the second reference to A can simply be a reference to the register into which A was computed. Performing this optimization requires knowing that the two references are _always_ to the same memory address and that there is no intervening access to the same location. Normally, data dependence analysis tells that only one reference _may_ depend on another; a more complex analysis is required to determine that two references _must be_ to the exact same address. In the preceding example, a simple version of this analysis suffices because the two references are in the same basic block.

> 此示例中对 A 的第二个引用不必翻译成负载指令，因为我们知道该值是由上一个语句计算和存储的。因此，对 A 的第二个引用可以简单地引用计算 A 的寄存器。执行此优化需要知道这两个引用是 *Always* 到同一内存地址，并且没有中间访问相同位置的访问。通常，数据依赖性分析说，只有一个参考 *may* 取决于另一个参考。需要进行更复杂的分析以确定两个参考*可以*与完全相同的地址。在前面的示例中，此分析的一个简单版本足够了，因为两个引用在同一基本块中。

Often loop-carried dependences are in the form of a _recurrence_. A recurrence occurs when a variable is defined based on the value of that variable in an earlier iteration, usually the one immediately preceding, as in the following code fragment:

> 通常，循环依赖性为 *recurrence* 的形式。当根据早期迭代中该变量的值定义变量时（通常是在以下代码片段中）定义变量的值时，会发生复发。

Detecting a recurrence can be important for two reasons: some architectures (especially vector computers) have special support for executing recurrences, and in an ILP context, it may still be possible to exploit a fair amount of parallelism.

> 检测复发可能很重要，原因有两个：某些架构（尤其是向量计算机）对执行复发有特殊的支持，并且在 ILP 上下文中，仍然可以利用相当多的并行性。

### Finding Dependences

> ###查找依赖项

Clearly, finding the dependences in a program is important both to determine which loops might contain parallelism and to eliminate name dependences. Thnalysis arises also because of the presence of arrays and pointers in languages such as C or C++, or pass-by-reference parameter passing in Fortran. Because scalar variable references explicitly refer to a name, they can usually be analyzed quite easily with aliasing because of pointers and reference parameters causing some complications and uncertainty in the analysis.

> 显然，找到程序中的依赖性对于确定哪些循环可能包含并行性并消除名称依赖性很重要。由于语言中存在阵列和指针，例如 C 或 C ++ 或通过 Fortran 传递的传递参数。由于标量变量引用明确指的是名称，因此通常可以通过混叠来分析它们，因为指示器和参考参数导致分析中引起一些并发症和不确定性。

How does the compiler detect dependences in general? Nearly all dependence analysis algorithms work on the assumption that array indices are _affine_. In simplest terms, a one-dimensional array index is affine if it can be written in the form _a i_ + _b_, where _a_ and _b_ are constants and _i_ is the loop index variable. The index of a multidimensional array is affine if the index in each dimension is affine. Sparse array accesses, which typically have the form x\[y\[i\]\], are one of the major examples of nonaffine accesses.

> 编译器一般如何检测依赖性？几乎所有的依赖分析算法都在数组索引为 *Affine* 的假设上起作用。用最简单的话来说，如果可以用 *a i* + *b* 形式编写一维数组索引，则是仿射，其中 *a* 和 *b* 是常数，而 *i* 是循环索引变量。如果每个维度中的索引是仿射的，则多维阵列的索引是仿射。稀疏的数组访问通常具有 X \ [y \ [i \] \]的形式，是非携带访问的主要示例之一。

Determining whether there is a dependence between two references to the same array in a loop is thus equivalent to determining whether two affine functions can have the identical value for different indices between the bounds of the loop. For example, suppose we have stored to an array element with index value _a i_ + _b_ and loaded from the same array with index value _c i_ + _d_, where _i_ is the for-loop index variable that runs from _m_ to _n_. A dependence exists if two conditions hold:

> 因此，确定在循环中对同一数组之间的两个引用之间是否存在依赖性，这等同于确定两个仿射函数是否可以在环路边界之间具有相同的值。例如，假设我们已将索引值 *a i* + *b* 的数组元素存储到带有索引值 *c i* + *d* 的同一数组中，其中 *i* 是从 *m* 到 *n* 运行的前循环索引变量。如果有两个条件，存在依赖性：

1. There are two iteration indices, _j_ and _k_, that are both within the limits of the forloop. That is, _m_ ≤ _j_ ≤ _n_, _m_ ≤ _k_ ≤ _n_.

> 1.有两个迭代索引 *j* 和 *k*，它们都在陆上的范围内。也就是说，*m*≤*j*≤*n*，*m*≤*k*≤*n*。

2. The loop stores into an array element indexed by _a_ × _j_ + _b_ and later fetches from that _same_ array element when it is indexed by _c_ × _k_ + _d_, that is, _a_ × _j_ + _b_ = _c_ × _k_ + _d_.

> 2. The loop stores into an array element indexed by _a_ × _j_ + _b_ and later fetches from that _same_ array element when it is indexed by _c_ × _k_ + _d_, that is, _a_ × _j_ + _b_ = _c_ × _k_ + _d_.

In general, we cannot determine whether dependence exists at compile time. For example, the values of _a_, _b_, _c_, and _d_ may not be known (they could be values in other arrays), making it impossible to tell if a dependence exists. In other cases, the dependence testing may be very expensive but decidable at compile time; for example, the accesses may depend on the iteration indices of multiple nested loops. Many programs, however, contain primarily simple indices where _a_, _b_, _c_, and _d_ are all constants. For these cases, it is possible to devise reasonable compile time tests for dependence.

> 通常，我们无法确定在编译时是否存在依赖性。例如，_a_，_b_，*c* 和 *d* 的值可能不知道（它们可能是其他数组中的值），因此无法分辨是否存在依赖性。在其他情况下，依赖性测试可能非常昂贵，但在编译时可以决定。例如，访问可能取决于多个嵌套循环的迭代索引。但是，许多程序主要包含 *a*，_b_，*c* 和 *d* 的简单索引，都是常数。对于这些情况，可以设计合理的编译时间测试以依赖。

As an example, a simple and sufficient test for the absence of a dependence is the _greatest common divisor_ (GCD) test. It is based on the observation that if a loop-carried dependence exists, then GCD (_c_, _a_) must divide (_d_ – _b_). (Recall that an integer, _x_, _divides_ another integer, _y_, if we get an integer quotient when we do the division _y_/_x_ and there is no remainder.)

> 例如，对于缺乏依赖性的简单和充分的测试是*最 greateat common Divisor*（GCD）测试。这是基于这样的观察结果：如果存在循环依赖性，则 GCD（_c_，_a_）必须分开（_d_ - _b_）。（回想一下一个整数，_x_，*divides* 另一个整数，_y_，如果我们在做 dise 当 *y */* x*时获得整数商，则没有剩余的。）

Example Use the GCD test to determine whether dependences exist in the following loop:

> 示例使用 GCD 测试来确定以下循环中是否存在依赖性：

_Answer_ Given the values _a_ = 2, _b_ = 3, _c_ = 2, and _d_ = 0, then GCD(_a_, _c_) = 2, and _d_ — _b_ =— 3. <u>Because 2 does not divide —3, no dependence is possible.</u>

> *answer* 给定值 *a* = 2，_b_ = 3，_c_ = 2，_d_ = 0，然后 gcd（_a_，_c_）= 2，_d_ -_b_ = - 3. <u> 3. <u>没有依赖性。</u>

The GCD test is sufficient to guarantee that no dependence exists; however, there are cases where the GCD test succeeds but no dependence exists. This can arise, for example, because the GCD test does not consider the loop bounds.

> GCD 测试足以保证不存在依赖性；但是，在某些情况下，GCD 测试成功，但不存在依赖性。例如，这可能会出现，因为 GCD 测试不考虑循环界限。

In general, determining whether a dependence actually exists is NP-complete. In practice, however, many common cases can be analyzed precisely at low cost. Recently, approaches using a hierarchy of exact tests increasing in generality and cost have been shown to be both accurate and efficient. (A test is _exact_ if it precisely determines whether a dependence exists. Although the general case is NP-complete, there exist exact tests for restricted situations that are much cheaper.) In addition to detecting the presence of a dependence, a compiler wants to classify the type of dependence. This classification allows a compiler to recognize name dependences and eliminate them at compile time by renaming and copying.

> 通常，确定依赖性是否实际存在是 NP 完整的。但是，实际上，可以以低成本精确地分析许多常见案例。最近，使用精确测试的层次结构的方法增加了一般性和成本的方法既准确又有效。（如果确切地确定是否存在依赖性，则测试是 *exact*。尽管一般情况是 NP 完整的，但对于限制性情况来说，还有精确的测试。）除了检测依赖性的存在外，编译器还希望对依赖的类型进行分类。此分类使编译器可以通过重命名和复制在编译时间识别名称依赖性并消除它们。

Example The following loop has multiple types of dependences. Find all the true dependences, output dependences, and antidependences, and eliminate the output dependences and antidependences by renaming.

> 示例以下循环具有多种类型的依赖性。找到所有真实的依赖性，输出依赖性和抗抑郁症，并通过重命名消除输出依赖和抗抑郁。

_Answer_ The following dependences exist among the four statements:

> *answer* 在四个语句中存在以下依赖性：

1. There are true dependences from S1 to S3 and from S1 to S4 because of Y\[i\]. These are not loop-carried, so they do not prevent the loop from being considered parallel. These dependences will force S3 and S4 to wait for S1 to complete.

> 1.由于 y \ [i \]，从 S1 到 S3 以及从 S1 到 S4 的真实依赖性。这些不是循环的，因此它们不会阻止循环被视为平行。这些依赖性将迫使 S3 和 S4 等待 S1 完成。

2. There is an antidependence from S1 to S2, based on X\[i\].

> 2.基于 x \ [i \]，S1 到 S2 有抗抑郁。

3. There is an antidependence from S3 to S4 for Y\[i\].

> 3. y \ [i \]有从 S3 到 S4 的抗抑郁。

4. There is an output dependence from S1 to S4, based on Y\[i\].

> 4.基于 y \ [i \]，从 S1 到 S4 的输出依赖性。

The following version of the loop eliminates these false (or pseudo) dependences.

> 循环的以下版本消除了这些错误（或伪）依赖性。

After the loop, the variable X has been renamed X1. In code that follows the loop, the compiler can simply replace the name X by X1. In this case, renaming does not require an actual copy operation, as it can be done by substituting names or by register allocation. In other cases, however, renaming will require copying.

> 循环后，变量 X 已更名为 X1。在循环之后的代码中，编译器可以简单地用 x1 替换名称 x。在这种情况下，重命名不需要实际的复制操作，因为可以通过替换名称或登记处分配来完成。但是，在其他情况下，重命名将需要复制。

Dependence analysis is a critical technology for exploiting parallelism, as well as for the transformation-like blocking that [Chapter 2](#_bookmark46) covers. For detecting loop-level parallelism, dependence analysis is the basic tool. Effectively compiling programs for vector computers, SIMD computers, or multiprocessors depends critically on this analysis. The major drawback of dependence analysis is that it applies only under a limited set of circumstances, namely, among references within a single loop nest and using affine index functions. Thus there are many situations where array-oriented dependence analysis _cannot_ tell us what we want to know; for example, analyzing accesses done with pointers, rather than with array indices can be much harder. (This is one reason why Fortran is still preferred over C and C++ for many scientific applications designed for parallel computers.) Similarly, analyzing references across procedure calls is extremely difficult. Thus, while analysis of code written in sequential languages remains important, we also need approaches such as OpenMP and CUDA that write explicitly parallel loops.

> 依赖分析是利用并行性的关键技术，以及[2 章]（#* bookmark46）涵盖的类似转换的阻塞。对于检测循环级并行性，依赖分析是基本工具。有效地为矢量计算机，SIMD 计算机或多处理器编译程序取决于此分析。依赖分析的主要缺点是它仅在一组有限的情况下应用，即在单个环巢中的参考和使用仿射索引函数中。因此，在许多情况下，以数组为导向的依赖分析\_Cannot*告诉我们我们想知道什么；例如，分析用指针完成的访问，而不是与数组索引进行的访问可能更加困难。（这就是为什么对于平行计算机设计的许多科学应用程序仍然优先于 C 和 C ++，这就是为什么 fortran 的原因。）类似地，在过程调用中分析参考非常困难。因此，尽管对以顺序语言编写的代码进行分析仍然很重要，但我们还需要诸如 OpenMP 和 CUDA 之类的方法，这些方法是明确并行循环编写的。

### Eliminating Dependent Computations

> ###消除依赖计算

As previously mentioned, one of the most important forms of dependent computations is a recurrence. A dot product is a perfect example of a recurrence:

> 如前所述，依赖计算的最重要形式之一是复发。点产品是复发的一个完美例子：

This loop is not parallel because it has a loop-carried dependence on the variable sum. We can, however, transform it to a set of loops, one of which is completely parallel and the other partly parallel. The first loop will execute the completely parallel portion of this loop. It looks like this:

> 该循环不平行，因为它对变量总和具有循环婚姻的依赖性。但是，我们可以将其转换为一组循环，其中一个是完全平行的，另一个是部分平行的。第一个循环将执行此循环的完全并行部分。看起来像这样：

Notice that sum has been expanded from a scalar into a vector quantity (a transformation called _scalar expansion_) and that this transformation makes this new loop completely parallel. When we are done, however, we need to do the reduce step, which sums up the elements of the vector. It looks like this:

> 请注意，总和已从标量扩展为向量数量（称为 *SCALAR 扩展*）的矢量数量，并且此转换使此新循环完全平行。但是，当我们完成时，我们需要执行减少步骤，这总结了向量的元素。看起来像这样：

Although this loop is not parallel, it has a very specific structure called a _reduction_. Reductions are common in linear algebra, and as we will see in [Chapter 6](#_bookmark268),

> 尽管此循环不平行，但它具有一个非常特异性的结构，称为 *reduction*。减少在线性代数中很常见，正如我们将在[第 6 章]（#\_ bookmark268）中看到的那样，

they are also a key part of the primary parallelism primitive MapReduce used in warehouse-scale computers. In general, any function can be used as a reduction operator, and common cases include operators such as max and min.

> 它们也是仓库规模计算机中使用的主要平行性原始地图的关键部分。通常，任何功能都可以用作还原操作员，常见案例包括运算符，例如 Max 和 Min。

Reductions are sometimes handled by special hardware in a vector and SIMD architecture that allows the reduce step to be done much faster than it could be done in scalar mode. These work by implementing a technique similar to what can be done in a multiprocessor environment. While the general transformation works with any number of processors, suppose for simplicity we have 10 processors. In the first step of reducing the sum, each processor executes the following (with p as the processor number ranging from 0 to 9):

> 减少有时会通过向量和 SIMD 体系结构中的特殊硬件来处理，该硬件允许减少步骤的完成速度要比在标量模式下完成的速度要快得多。这些工作通过实施类似于在多处理器环境中可以完成的技术。尽管一般转换与任何数量的处理器一起使用，但假设为简单起见，我们有 10 个处理器。在减少总和的第一步中，每个处理器执行以下操作（P 作为处理器编号为 0 到 9）：

This loop, which sums up 1000 elements on each of the 10 processors, is completely parallel. A simple scalar loop can then complete the summation of the last 10 sums. Similar approaches are used in vector processors and SIMD Processors.

> 该循环完全平行于 10 个处理器上的每个处理器中的每个元素。然后，一个简单的标量循环可以完成最后 10 和的总和。向量处理器和 SIMD 处理器中使用了类似的方法。

It is important to observe that the preceding transformation relies on associativity of addition. Although arithmetic with unlimited range and precision is associative, computer arithmetic is not associative, for either integer arithmetic, because of limited range, or floating-point arithmetic, because of both range and precision. Thus using these restructuring techniques can sometimes lead to erroneous behavior, although such occurrences are rare. For this reason, most compilers require that optimizations that rely on associativity be explicitly enabled.

> 重要的是要观察到前面的转换取决于加法的关联性。尽管具有无限范围和精度的算术是关联的，但计算机算术不是关联的，对于整数算术而言，由于范围有限或浮点算术，由于范围和精度既有范围。因此，使用这些重组技术有时会导致错误的行为，尽管这种情况很少见。因此，大多数编译器要求明确启用依赖关联性的优化。
