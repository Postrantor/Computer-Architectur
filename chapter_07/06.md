## Intel Crest, a Data Center Accelerator for Training

The quotation by the Intel CEO that opens [Section 7.3](#example-domain-deep-neural-networks) came from the press release announcing that Intel was going to start shipping DSAs ( "accelerants" ) for DNN. The first example was Crest, which was announced while we were writing this edition. Despite the limited details, we include it here because of the significance of a traditional microprocessor manufacturer like Intel taking this bold step of embracing DSAs.

> 英特尔首席执行官在 [第 7.3 节](#example-domain-deep-neural-networks) 开头的引述来自宣布英特尔将开始为 DNN 提供 DSA( "加速器" )的新闻稿。第一个示例是 Crest，它是在我们编写此版本时宣布的。尽管细节有限，但我们还是将其包含在此处，因为像英特尔这样的传统微处理器制造商采取这一拥抱 DSA 的大胆步骤具有重要意义。

Crest is aimed at DNN training. The Intel CEO said the goal is to accelerate DNN training a hundredfold over the next three years. [Figure 7.6](#_bookmark332) shows that train- ing can take a month. There is likely to be a demand to decrease the DNN training to just eight hours, which would be 100 times quicker than the CEO predicted. DNNs will surely become even more complex over the next 3 years, which will require a much greater training effort. Thus there seems little danger that a 100 improvement in training is overkill.

> Crest 是针对 DNN 训练的。这位英特尔首席执行官表示，目标是在未来三年内将 DNN 培训速度提高一百倍。[图 7.6](#_bookmark332) 显示训练可能需要一个月的时间。可能需要将 DNN 培训减少到仅八小时，这比 CEO 预测的要快 100 倍。DNN 在未来 3 年内肯定会变得更加复杂，这将需要更多的培训工作。因此，培训提高 100 分是矫枉过正的危险似乎不大。

Crest instructions operate on blocks of 32 32 matrices. Crest uses a number format called _flex point_, which is a scaled fixed-point representation: 32 32 matri- ces of 16-bit data share a single 5-bit exponent that is provided as part of the instruction set.

> Crest 指令对 32 32 矩阵块进行操作。Crest 使用一种称为 _flex point_ 的数字格式，这是一种定标定点表示法：16 位数据的 32 32 个矩阵共享一个作为指令集的一部分提供的 5 位指数。

[Figure 7.28](#_bookmark359) shows the block diagram of the Lake Crest chip. To compute on these matrices, Crest uses the12 processing clusters of [Figure 7.28](#_bookmark359). Each cluster includes a large SRAM, a big linear algebra processing unit, and a small amount of logic for on- and off-chip routing. The four 8 GiB HBM2 DRAM modules offer 1 TB/s of memory bandwidth, which should lead to an attractive Roofline model for the Crest chip. In addition to high-bandwidth paths to main memory, Lake Crest supports high band- width interconnects directly between compute cores inside the processing clusters, which facilitates quick core-to-core communication without passing through shared memory. Lake Crest’s goal is a factor of 10 improvement in training over GPUs.

> [图 7.28](#_bookmark359) 显示了 Lake Crest 芯片的框图。为了计算这些矩阵，Crest 使用 [图 7.28](#_bookmark359) 的 12 个处理集群。每个集群包括一个大型 SRAM、一个大型线性代数处理单元和少量用于片上和片外路由的逻辑。四个 8 GiB HBM2 DRAM 模块提供 1 TB/s 的内存带宽，这应该会为 Crest 芯片带来一个有吸引力的 Roofline 模型。除了通往主内存的高带宽路径之外，Lake Crest 还支持处理集群内计算核心之间的直接高带宽互连，这有助于快速实现核心到核心的通信，而无需通过共享内存。Lake Crest 的目标是将 GPU 的训练提高 10 倍。

[Figure 7.28](#_bookmark359) shows 12 Inter-Chip Links (ICLs) and 2 Inter-Chip Controllers (ICCs), so Crest is clearly designed to allow many Crest chips to collaborate, sim- ilar in spirit to the dedicated network connecting the 48 FPGAs in Catapult. It’s likely that the 100 improvement in training will require ganging together several Crest chips.

> [图 7.28](#_bookmark359) 显示了 12 个芯片间链路 (ICL) 和 2 个芯片间控制器 (ICC)，因此 Crest 显然设计为允许多个 Crest 芯片协作，其精神类似于专用网络连接 Catapult 中的 48 个 FPGA。训练的 100 改进很可能需要将多个 Crest 芯片组合在一起。
