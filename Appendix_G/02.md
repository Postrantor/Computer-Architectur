## Vector Performance in More Depth

The chime approximation is reasonably accurate for long vectors. Another source of overhead is far more significant than the issue limitation.

> 对于长向量，编钟近似是相当准确的。 另一个开销来源比问题限制重要得多。

The most important source of overhead ignored by the chime model is vector _start-up time_. The start-up time comes from the pipelining latency of the vector operation and is principally determined by how deep the pipeline is for the func- tional unit used. The start-up time increases the effective time to execute a convoy to more than one chime. Because of our assumption that convoys do not overlap in time, the start-up time delays the execution of subsequent convoys. Of course, the instructions in successive convoys either have structural conflicts for some functional unit or are data dependent, so the assumption of no overlap is reason- able. The actual time to complete a convoy is determined by the sum of the vector length and the start-up time. If vector lengths were infinite, this start-up overhead would be amortized, but finite vector lengths expose it, as the following example shows.

> 被 chime 模型忽略的最重要的开销来源是向量*启动时间*。 启动时间来自矢量操作的流水线延迟，主要取决于所用功能单元的流水线深度。 启动时间增加了执行车队到多个提示音的有效时间。 由于我们假设车队不会在时间上重叠，因此启动时间会延迟后续车队的执行。 当然，连续车队中的指令要么与某些功能单元存在结构冲突，要么与数据相关，因此没有重叠的假设是合理的。 完成车队的实际时间由向量长度和启动时间之和决定。 如果向量长度是无限的，这个启动开销将被分摊，但有限的向量长度暴露它，如下例所示。

Example Assume that the start-up overhead for functional units is shown in Figure G.2.

> 示例假设功能单元的启动开销如图 G.2 所示。

Show the time that each convoy can begin and the total number of cycles needed. How does the time compare to the chime approximation for a vector of length 64?

> 显示每个车队可以开始的时间以及所需的循环总数。时间与长度为 64 的向量相比，时间如何？

_Answer_ Figure G.3 provides the answer in convoys, assuming that the vector length is `n.` One tricky question is when we assume the vector sequence is done; this deter- mines whether the start-up time of the SV is visible or not. We assume that the instructions following cannot fit in the same convoy, and we have already assumed that convoys do not overlap. Thus, the total time is given by the time until the last vector instruction in the last convoy completes. This is an approximation, and the start-up time of the last vector instruction may be seen in some sequences and not in others. For simplicity, we always include it.

> _answer_ 图 G.3 在车队中提供了答案，假设向量长度为*n.*一个棘手的问题是，当我们假设向量序列完成时；这确定了 SV 的启动时间是否可见。我们假设以下说明不能适合同一车队，并且我们已经假设车队不会重叠。因此，总时间是由时间给出的，直到最后一个车队的最后一个向量指令完成为止。这是一个近似值，最后一个向量指令的启动时间可以在某些序列中而不是在其他序列中看到。为简单起见，我们始终包括它。

The time per result for a vector of length 64 is 4 +(42/64) 4.65 clock cycles, while the chime approximation would be 4. The execution time with startup overhead is 1.16 times higher.

> 长度为 64 的矢量的每个结果的时间为 4 +(42/64)4.65 时钟循环，而循环近似值为 4。启动开销的执行时间高 1.16 倍。

Figure G.1 Characteristics of several vector-register architectures. If the machine is a multiprocessor, the entries correspond to the characteristics of one processor. Several of the machines have different clock rates in the vector and scalar units; the clock rates shown are for the vector units. The Fujitsu machines’ vector registers are configurable: The size and count of the 8K 64-bit entries may be varied inversely to one another (e.g., on the VP200, from eight registers each 1K elements long to 256 registers each 32 elements long). The NEC machines have eight foreground vector registers connected to the arithmetic units plus 32 to 64 background vector registers connected between the memory system and the foreground vector registers. Add pipelines perform add and subtract. The multiply/divide- add unit on the Hitachi S810/820 performs an FP multiply or divide followed by an add or subtract (while the multiply- add unit performs a multiply followed by an add or subtract). Note that most processors use the vector FP multiply and divide units for vector integer multiply and divide, and several of the processors use the same units for FP scalar and FP vector operations. Each vector load-store unit represents the ability to do an independent, overlapped transfer to or from the vector registers. The number of lanes is the number of parallel pipelines in each of the functional units as described in [Section G.4](#enhancing-vector-performance). For example, the NEC SX/5 can complete 16 multiplies per cycle in the multiply functional unit. Several machines can split a 64-bit lane into two 32-bit lanes to increase performance for applications that require only reduced precision. The Cray SV1 and Cray X1 can group four CPUs with two lanes each to act in unison as a single larger CPU with eight lanes, which Cray calls a Multi-Streaming Processor (MSP).

> 图 G.1 几种向量寄存器架构的特征。 如果机器是多处理器，则条目对应于一个处理器的特性。 一些机器在矢量和标量单元中具有不同的时钟速率； 显示的时钟速率适用于矢量单元。  Fujitsu 机器的矢量寄存器是可配置的：8K 64 位条目的大小和数量可以彼此相反地变化（例如，在 VP200 上，从 8 个寄存器每个 1K 元素长到 256 个寄存器每个 32 个元素长）。  NEC 机器有 8 个连接到算术单元的前景向量寄存器以及连接在内存系统和前景向量寄存器之间的 32 到 64 个背景向量寄存器。 添加管道执行加法和减法。  Hitachi S810/820 上的乘/除-加单元执行 FP 乘法或除法，然后执行加法或减法（而乘法-加法单元执行乘法，然后执行加法或减法）。 请注意，大多数处理器使用向量 FP 乘法和除法单元进行向量整数乘法和除法，并且一些处理器使用相同的单元进行 FP 标量和 FP 向量运算。 每个向量加载-存储单元都代表执行独立的、重叠传输到向量寄存器或从向量寄存器进行传输的能力。 通道数是每个功能单元中并行流水线的数量，如 [Section G.4](#enhancing-vector-performance) 中所述。 例如，NEC SX/5 在乘法功能单元中每个周期可以完成 16 次乘法运算。 多台机器可以将一个 64 位通道分成两个 32 位通道，以提高只需要降低精度的应用程序的性能。  Cray SV1 和 Cray X1 可以将四个 CPU 分组，每个 CPU 有两条通道，作为一个更大的 CPU 协同工作，有八条通道，Cray 称之为多流处理器 (MSP)。

For simplicity, we will use the chime approximation for running time, incorporat- ing start-up time effects only when we want performance that is more detailed or to illustrate the benefits of some enhancement. For long vectors, a typical situation, the overhead effect is not that large. Later in the appendix, we will explore ways to reduce start-up overhead.

> 为了简单起见，我们将使用循环近似来进行运行时间，仅当我们想要更详细的性能或以说明某些增强功能的好处时，才能合并启动时间效果。对于长矢量，典型的情况，间接费用并不大。在附录的稍后，我们将探索减少启动开销的方法。

Start-up time for an instruction comes from the pipeline depth for the functional unit implementing that instruction. If the initiation rate is to be kept at 1 clock cycle per result, then

> 指令的启动时间来自实现该指令的功能单元的管道深度。如果要将启动率保持在每个结果的 1 个时钟周期，则

For example, if an operation takes 10 clock cycles, it must be pipelined 10 deep to achieve an initiation rate of one per clock cycle. Pipeline depth, then, is deter- mined by the complexity of the operation and the clock cycle time of the proces- sor. The pipeline depths of functional units vary widely—2 to 20 stages are common—although the most heavily used units have pipeline depths of 4 to 8 clock cycles.

> 例如，如果操作采用 10 个时钟循环，则必须将其管道上的 10 个深度启动才能达到每个时钟周期的启动率。然后，管道深度可以通过操作的复杂性和过程的时钟周期时间来确定。功能单元的管道深度差异很大(2 至 20 个阶段很常见)，尽管最严重的单元的管道深度为 4 至 8 个时钟周期。

For VMIPS, we will use the same pipeline depths as the Cray-1, although laten- cies in more modern processors have tended to increase, especially for loads. All functional units are fully pipelined. From [Chapter 4](#_bookmark165), pipeline depths are 6 clock cycles for floating-point add and 7 clock cycles for floating-point multiply. On VMIPS, as on most vector processors, independent vector operations using different functional units can issue in the same convoy.

> 对于 VMIP，我们将使用与 Cray-1 相同的管道深度，尽管更现代的处理器中的拉登却倾向于增加，尤其是用于负载。所有功能单元均已完全管道。从[第 4 章](#_bookmark165)中，管道深度为 6 个时钟周期，用于浮点添加和 7 个时钟周期，用于浮点倍数。在 VMIP 上，与大多数矢量处理器一样，使用不同功能单元的独立向量操作可以在同一车队中发出。

In addition to the start-up overhead, we need to account for the overhead of executing the strip-mined loop. This strip-mining overhead, which arises from the need to reinitiate the vector sequence and set the Vector Length Register (VLR) effectively adds to the vector start-up time, assuming that a convoy does not over- lap with other instructions. If that overhead for a convoy is 10 cycles, then the effective overhead per 64 elements increases by 10 cycles, or 0.15 cycles per element.

> 除了启动开销外，我们还需要说明执行条纹循环的开销。这种脱衣开采开销是源于重新启动矢量序列并设置向量长度寄存器(VLR)的需要，可以有效地增加矢量启动时间，前提是车队不会与其他指示相比。如果车队的开销是 10 个循环，则每 64 个元素的有效开销增加 10 个循环，或每个元素的 0.15 个循环。

Figure G.4 Start-up penalties on VMIPS. These are the start-up penalties in clock cycles for VMIPS vector operations.

> 图 G.4 对 VMIP 的启动处罚。这些是 VMIP 矢量操作的时钟周期中的启动处罚。

Two key factors contribute to the running time of a strip-mined loop consisting of a sequence of convoys:

> 有两个关键因素有助于由一系列车队组成的带状循环的运行时间：

1. The number of convoys in the loop, which determines the number of chimes. We use the notation T_chime for the execution time in chimes.

> 1.循环中的车队数量确定了铃声的数量。我们使用符号的符号_ chime 在 Chimes 中执行时间。

2. The overhead for each strip-mined sequence of convoys. This overhead consists of the cost of executing the scalar code for strip-mining each block, T_loop, plus the vector start-up cost for each convoy, T_start.

> 2.每个车队序列序列的开销。该间接费用包括执行标量代码的成本，用于剥离每个块，T _ loop ，以及每个车队的矢量启动成本，t _ start 。

There may also be a fixed overhead associated with setting up the vector sequence the first time. In recent vector processors, this overhead has become quite small, so we ignore it.

> 也可能有一个与第一次设置向量序列相关的固定开销。在最近的矢量处理器中，这个间接费用变得很小，因此我们忽略了它。

The components can be used to state the total running time for a vector sequence operating on a vector of length _n_, which we will call T*_n*:

> 该组件可用于陈述在长度 _n_ 的向量上操作的向量序列的总运行时间，我们将其称为 T*<ub> n *：

The values of T_start, T_loop, and T_chime are compiler and processor dependent. The register allocation and scheduling of the instructions affect both what goes in a con- voy and the start-up overhead of each convoy.

> T _ start ，t _循环和 t _ chime 的值是编译器和处理器依赖性。指令的登记册分配和调度会影响每个车队的企业和启动开销。

For simplicity, we will use a constant value for T_loop on VMIPS. Based on a variety of measurements of Cray-1 vector execution, the value chosen is 15 for T_loop. At first glance, you might think that this value is too small. The overhead in each loop requires setting up the vector starting addresses and the strides, incre- menting counters, and executing a loop branch. In practice, these scalar instruc- tions can be totally or partially overlapped with the vector instructions, minimizing the time spent on these overhead functions. The value of T_loop of course depends on the loop structure, but the dependence is slight compared with the connection between the vector code and the values of T_chime and T_start.

> 为简单起见，我们将使用 VMIP 上的 t _ loop 使用常数值。基于 Cray-1 矢量执行的各种测量值，对于 T _ loop ，所选的值为 15。乍一看，您可能会认为这个值太小。每个循环中的开销需要设置向量启动地址和步幅，分解计数器并执行循环分支。在实践中，这些标量指示可以完全或部分与矢量说明重叠，从而最大程度地减少了这些间接费用函数所花费的时间。t _循环的值当然取决于循环结构，但是与向量代码和 t _ chime 和 t <sub 之间的连接相比，依赖性很小 > 开始。

Example What is the execution time on VMIPS for the vector operation `A B s,` where `s` is a scalar and the length of the vectors `A` and `B` is 200?

> 示例 vmips 在 vector 操作 _a b s，_ _s_ 的执行时间是多少，_s_ 是标量，vectors _a_ 和 _b_ 的长度是 200？

_Answer_ Assume that the addresses of A and B are initially in Ra and Rb, s is in Fs, and recall that for MIPS (and VMIPS) R0 always holds 0. Since (200 mod 64) 8, the first iteration of the strip-mined loop will execute for a vector length of 8 elements, and the following iterations will execute for a vector length of 64 elements. The starting byte addresses of the next segment of each vector is eight times the vector length. Since the vector length is either 8 or 64, we increment the address registers by 8 8 64 after the first segment and 8 64 512 for later segments. The total number of bytes in the vector is 8 200 1600, and we test for completion by comparing the address of the next vector segment to the initial address plus 1600. Here is the actual code:

> _answer_ 假设 A 和 B 的地址最初在 RA 和 RB 中，S 在 FS 中，并回想起 MIPS(和 VMIPS)R0 始终保持 0。挖掘循环将执行 8 个元素的向量长度，以下迭代将执行 64 个元素的矢量长度。每个向量的下一个段的启动字节地址是向量长度的八倍。由于矢量长度为 8 或 64，因此我们将地址寄存器递增了第一个段之后的 8 8 64，而后来的段为 8 64 512。向量中的字节总数为 8 200 1600，我们通过将下一个矢量段的地址与初始地址加上 1600 进行比较来测试完成。这是实际代码：

Figure G.5 The total execution time per element and the total overhead time per element versus the vector length for the example on page F-6. For short vectors, the total start-up time is more than one-half of the total time, while for long vectors it reduces to about one-third of the total time. The sudden jumps occur when the vector length crosses a multiple of 64, forcing another iteration of the strip-mining code and execution of a set of vector instructions. These operations increase T*_n* by T_loop +T_start.

> 图 G.5 每个元素的总执行时间和每个元素的总间接费用时间与第 6 页上的示例的向量长度。对于简短的矢量，总启动时间超过总时间的一半以上，而对于长量矢量，它减少到总时间的三分之一。当矢量长度越过 64 的倍数时，突然的跳跃发生，迫使剥离代码的另一个迭代和一组向量指令的执行。这些操作通过 T _ loop  +t _开始增加了 T* _ n *。

The execution time per element with all start-up costs is then 784/200 3.9, compared with a chime approximation of three. In [Section G.4](#enhancing-vector-performance), we will be more ambitious—allowing overlapping of separate convoys.

> 所有启动成本的每个元素的执行时间为 784/200 3.9，相比之下三个。在[G.4 节](＃增强 - 矢量性能)中，我们将更加雄心勃勃 - 允许单独的车队重叠。

[Figure G.5](#_bookmark689) shows the overhead and effective rates per element for the previous example (_A B s_) with various vector lengths. A chime-counting model would lead to 3 clock cycles per element, while the two sources of overhead add 0.9 clock cycles per element in the limit.

> [图 G.5](#_bookmark689) 显示了上一个示例(_a b s_)的每个元素的开销和有效率，具有各种矢量长度。计数计数模型将导致每个元素的 3 个时钟周期，而高空的两个来源在限制中添加了 0.9 个时钟周期。

### Pipelined Instruction Start-Up and Multiple Lanes

Adding multiple lanes increases peak performance but does not change start-up latency, and so it becomes critical to reduce start-up overhead by allowing the start of one vector instruction to be overlapped with the completion of preceding vector instructions. The simplest case to consider is when two vector instructions access a different set of vector registers. For example, in the code sequence

> 添加多个车道会增加峰值性能，但不会改变启动延迟，因此，通过允许一个向量指令的启动来减少启动开销变得至关重要。最简单的情况是，当两个向量指令访问另一组向量寄存器时。例如，在代码序列中

An implementation can allow the first element of the second vector instruction to follow immediately the last element of the first vector instruction down the FP adder pipeline. To reduce the complexity of control logic, some vector machines require some `recovery time` or `dead time` in between two vector instructions dis- patched to the same vector unit. [Figure G.6](#_bookmark690) is a pipeline diagram that shows both start-up latency and dead time for a single vector pipeline.

> 实现可以允许第二个向量指令的第一个元素立即遵循 FP 加法管线下的第一个向量指令的最后一个元素。为了降低控制逻辑的复杂性，一些向量机需要一些 _recovery Time_ 或 _dead Time_ 在两个向量指令之间分配给同一向量单元的两个向量指令。[图 G.6](#_bookmark690) 是一个管道图，它显示了单个矢量管道的启动延迟和死时间。

The following example illustrates the impact of this dead time on achievable vector performance.

> 以下示例说明了这段时间对可实现的向量性能的影响。

Example The Cray C90 has two lanes but requires 4 clock cycles of dead time between any two vector instructions to the same functional unit, even if they have no data depen- dences. For the maximum vector length of 128 elements, what is the reduction in achievable peak performance caused by the dead time? What would be the reduc- tion if the number of lanes were increased to 16?

> 示例 Cray C90 有两条车道，但在任何两个向量指令之间都需要 4 个时钟循环到同一功能单元，即使它们没有数据依据。对于 128 个元素的最大矢量长度，死亡时间导致可实现的峰值性能的减少是多少？如果车道数量增加到 16，则减少了什么？

_Answer_ A maximum length vector of 128 elements is divided over the two lanes and occupies a vector functional unit for 64 clock cycles. The dead time adds another 4 cycles of occupancy, reducing the peak performance to 64/(64 + 4) 94.1% of the value with- out dead time. If the number of lanes is increased to 16, maximum length vector instructions will occupy a functional unit for only 128/16 8 cycles, and the dead time will reduce peak performance to 8/(8 + 4) 66.6% of the value without dead time. In this second case, the vector units can never be more than 2/3 busy!

> *answer *将 128 个元素的最大长度向量分配在两个车道上，并占据了 64 个时钟周期的向量功能单元。死时间增加了 4 个占用率的周期，将峰值性能降低至 64/(64 + 4)，占价值的 94.1％，随着时间的流逝。如果车道数量增加到 16，则最大长度向量说明将仅以 128/16 8 循环占用功能单位，而死亡时间将使峰值性能降低到 8/(8 + 4)66.6％，没有死亡。时间。在第二种情况下，矢量单元永远不会超过 2/3！

<img src="../media/image733.png" style="width:4.34062in;height:2.605in" />

Figure G.6 Start-up latency and dead time for a single vector pipeline. Each element has a 5-cycle latency: 1 cycle to read the vector-register file, 3 cycles in execution, then 1 cycle to write the vector-register file. Elements from the same vector instruction can follow each other down the pipeline, but this machine inserts 4 cycles of dead time between two different vector instructions. The dead time can be eliminated with more complex control logic. (Reproduced with permission from [Asanovic \[1998]](#\_bookmark701).)

> 图 G.6 单个矢量管道的启动延迟和停止时间。每个元素都有一个 5 周期的延迟：1 个周期来读取矢量注册文件，执行中的 3 个周期，然后 1 个周期来编写矢量注册文件。来自同一矢量指令的元素可以互相跟随管道，但是该机器在两个不同的矢量指令之间插入了 4 个死时间。可以通过更复杂的控制逻辑消除死时间。(经[Asanovic \ [1998 ]]的许可重现(#\_bookmark701)。)。

Pipelining instruction start-up becomes more complicated when multiple instruc- tions can be reading and writing the same vector register and when some instructions may stall unpredictably—for example, a vector load encountering memory bank conflicts. However, as both the number of lanes and pipeline latencies increase, it becomes increasingly important to allow fully pipelined instruction start-up.

> 当多次指导可以读取和编写相同的向量寄存器，以及某些指令可能无法预测时(例如，遇到内存库冲突的向量负载)时，管道指令启动的启动变得更加复杂。但是，随着车道的数量和管道潜伏期的增加，允许完全管道的指令启动变得越来越重要。
