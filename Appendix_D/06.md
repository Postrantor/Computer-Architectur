## Crosscutting Issues

### Point-to-Point Links and Switches Replacing Buses

Point-to-point links and switches are increasing in popularity as Moore’s law con- tinues to reduce the cost of components. Combined with the higher I/O bandwidth demands from faster processors, faster disks, and faster local area networks, the decreasing cost advantage of buses means the days of buses in desktop and server computers are numbered. This trend started in high-performance computers in the last edition of the book, and by 2011 has spread itself throughout storage. Figure D.18 shows the old bus-based standards and their replacements.

> 随着摩尔的法律连续降低组件成本，点对点链接和开关的流行程度正在增加。结合更快的处理器，更快的磁盘和更快的局部网络的较高的 I/O 带宽需求，总线的成本优势降低意味着台式机和服务器计算机中的总线日期已编号。这一趋势始于本书的最后一版，从高性能计算机开始，到 2011 年，在整个存储中已经传播了自己。图 D.18 显示了旧的基于公共汽车的标准及其替代品。

The number of bits and bandwidth for the new generation is per direction, so they double for both directions. Since these new designs use many fewer wires, a common way to increase bandwidth is to offer versions with several times the num- ber of wires and bandwidth.

> 新一代的位和带宽的数量是每个方向，因此两个方向都会加倍。由于这些新设计使用的电线较少，因此增加带宽的一种常见方法是提供几倍的电线和带宽。

### Block Servers versus Filers

Thus far, we have largely ignored the role of the operating system in storage. In a manner analogous to the way compilers use an instruction set, operating systems determine what I/O techniques implemented by the hardware will actually be used. The operating system typically provides the file abstraction on top of blocks stored on the disk. The terms _logical units_, _logical volumes_, and _physical volumes_ are related terms used in Microsoft and UNIX systems to refer to subset collections of disk blocks.

> 到目前为止，我们在很大程度上忽略了操作系统在存储中的作用。以类似于编译器使用指令集的方式的方式，操作系统确定了实际使用硬件的 I/O 技术。操作系统通常在存储在磁盘上的块顶上的文件抽象。术语* logical 单位*，* logical 卷*和\_ physical 卷是 Microsoft 和 unix 系统中使用的相关术语，用于参考磁盘块的子集集合。

Figure D.18 Parallel I/O buses and their point-to-point replacements. Note the bandwidth and wires are per direction, so bandwidth doubles when sending both directions.

> 图 D.18 平行 I/O 总线及其点对点更换。注意带宽和电线是每个方向的，因此在发送两个方向时，带宽会倍增。

A logical unit is the element of storage exported from a disk array, usually con- structed from a subset of the array’s disks. A logical unit appears to the server as a single virtual “disk.” In a RAID disk array, the logical unit is configured as a par- ticular RAID layout, such as RAID 5. A physical volume is the device file used by the file system to access a logical unit. A logical volume provides a level of vir- tualization that enables the file system to split the physical volume across multiple pieces or to stripe data across multiple physical volumes. A logical unit is an abstraction of a disk array that presents a virtual disk to the operating system, while physical and logical volumes are abstractions used by the operating system to divide these virtual disks into smaller, independent file systems.

> 逻辑单元是从磁盘阵列导出的存储元素，通常是从数组磁盘的子集构造的。服务器以单个虚拟“磁盘”的形式出现逻辑单元。在 RAID 磁盘阵列中，逻辑单元被配置为典型的 RAID 布局，例如 RAID5。物理卷是文件系统用于访问逻辑单元的设备文件。逻辑卷提供了一个级别的级别，使文件系统能够将物理卷分成多个零件或跨多个物理卷的条纹数据。逻辑单元是向操作系统提供虚拟磁盘的磁盘阵列的抽象，而物理和逻辑卷是操作系统用于将这些虚拟磁盘划分为较小的独立文件系统的抽象。

Having covered some of the terms for collections of blocks, we must now ask: Where should the file illusion be maintained: in the server or at the other end of the storage area network?

> 涵盖了一些块收集的术语后，我们现在必须问：在哪里应保持文件错觉：在服务器或存储区域网络的另一端？

The traditional answer is the server. It accesses storage as disk blocks and maintains the metadata. Most file systems use a file cache, so the server must main- tain consistency of file accesses. The disks may be _direct attached_—found inside a server connected to an I/O bus—or attached over a storage area network, but the server transmits data blocks to the storage subsystem.

> 传统的答案是服务器。它可以作为磁盘块访问存储并维护元数据。大多数文件系统都使用文件缓存，因此服务器必须是文件访问的一致性。磁盘可以是* Direct 附加*(在连接到 I/O 总线的服务器内的发现，也可以在存储区域网络上附加，但服务器将数据块传输到存储子系统。

The alternative answer is that the disk subsystem itself maintains the file abstraction, and the server uses a file system protocol to communicate with storage. Example protocols are Network File System (NFS) for UNIX systems and Common Internet File System (CIFS) for Windows systems. Such devices are called _network attached storage_ (NAS) devices since it makes no sense for storage to be directly attached to the server. The name is something of a misnomer because a storage area network like FC-AL can also be used to connect to block servers. The term _filer_ is often used for NAS devices that only provide file service and file storage. Network Appliance was one of the first companies to make filers.

> 另一种答案是，磁盘子系统本身维护文件抽象，并且服务器使用文件系统协议与存储进行通信。示例协议是 Windows 系统的 UNIX 系统和通用 Internet 文件系统(CIFS)的网络文件系统(NFS)。此类设备称为 *network 附加的存储*(NAS)设备，因为将存储直接连接到服务器没有任何意义。该名称是错误的，因为也可以使用 FC-AL 等存储区域网络连接以阻止服务器。术语 *filer* 通常用于仅提供文件服务和文件存储的 NAS 设备。网络设备是最早制作申报人的公司之一。

The driving force behind placing storage on the network is to make it easier for many computers to share information and for operators to maintain the shared system.

> 将存储放在网络上的推动力是使许多计算机更容易共享信息和操作员维护共享系统。

### Asynchronous I/O and Operating Systems

> ###异步 I/O 和操作系统

Disks typically spend much more time in mechanical delays than in transferring data. Thus, a natural path to higher I/O performance is parallelism, trying to get many disks to simultaneously access data for a program.

> 磁盘通常在机械延迟上花费更多的时间，而不是传输数据。因此，通往较高 I/O 性能的自然途径是并行性，试图使许多磁盘同时访问程序的数据。

The straightforward approach to I/O is to request data and then start using it. The operating system then switches to another process until the desired data arrive, and then the operating system switches back to the requesting process. Such a style is called _synchronous I/O_—the process waits until the data have been read from disk.

> I/O 的直接方法是请求数据，然后开始使用它。然后，操作系统切换到另一个过程，直到所需的数据到达，然后操作系统切换回请求过程。这样的样式称为 *synchronous I/o*-该过程等待直到从磁盘读取数据为止。

The alternative model is for the process to continue after making a request, and it is not blocked until it tries to read the requested data. Such _asynchronous I/O_

> 替代模型是要在提出请求后继续进行该过程，并且直到试图读取请求的数据才被阻止。这样的 *asynchronous i/o*

allows the process to continue making requests so that many I/O requests can be operating simultaneously. Asynchronous I/O shares the same philosophy as caches in out-of-order CPUs, which achieve greater bandwidth by having multiple out- standing events.

> 允许该过程继续提出请求，以便许多 I/O 请求可以同时运行。异步 I/O 具有与级别 CPU 中的缓存相同的哲学，通过多次淘汰事件，可以实现更大的带宽。
